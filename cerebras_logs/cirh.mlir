#loc0 = loc(unknown)
module  {
  func @graph(%arg0: tensor<768xf32> {tf.aliasing_output = 819 : i64, tf.resource_name = "state.model.ln_f.bias"} loc(unknown), %arg1: tensor<768xf32> {tf.aliasing_output = 814 : i64, tf.resource_name = "state.model.ln_f.weight"} loc(unknown), %arg2: tensor<768x3072xf32> {tf.aliasing_output = 309 : i64, tf.resource_name = "state.model.decoder.9.ffn.proj.weight"} loc(unknown), %arg3: tensor<3072x768xf32> {tf.aliasing_output = 304 : i64, tf.resource_name = "state.model.decoder.9.ffn.fc.weight"} loc(unknown), %arg4: tensor<768xf32> {tf.aliasing_output = 799 : i64, tf.resource_name = "state.model.decoder.9.ln_2.bias"} loc(unknown), %arg5: tensor<768xf32> {tf.aliasing_output = 794 : i64, tf.resource_name = "state.model.decoder.9.ln_2.weight"} loc(unknown), %arg6: tensor<768x768xf32> {tf.aliasing_output = 299 : i64, tf.resource_name = "state.model.decoder.9.attn.proj_output.weight"} loc(unknown), %arg7: tensor<768x768xf32> {tf.aliasing_output = 294 : i64, tf.resource_name = "state.model.decoder.9.attn.proj_v.weight"} loc(unknown), %arg8: tensor<768xf32> {tf.aliasing_output = 789 : i64, tf.resource_name = "state.model.decoder.9.ln_1.bias"} loc(unknown), %arg9: tensor<768xf32> {tf.aliasing_output = 784 : i64, tf.resource_name = "state.model.decoder.9.ln_1.weight"} loc(unknown), %arg10: tensor<768x3072xf32> {tf.aliasing_output = 279 : i64, tf.resource_name = "state.model.decoder.8.ffn.proj.weight"} loc(unknown), %arg11: tensor<3072x768xf32> {tf.aliasing_output = 274 : i64, tf.resource_name = "state.model.decoder.8.ffn.fc.weight"} loc(unknown), %arg12: tensor<768xf32> {tf.aliasing_output = 749 : i64, tf.resource_name = "state.model.decoder.8.ln_2.bias"} loc(unknown), %arg13: tensor<768xf32> {tf.aliasing_output = 744 : i64, tf.resource_name = "state.model.decoder.8.ln_2.weight"} loc(unknown), %arg14: tensor<768x768xf32> {tf.aliasing_output = 269 : i64, tf.resource_name = "state.model.decoder.8.attn.proj_output.weight"} loc(unknown), %arg15: tensor<768x768xf32> {tf.aliasing_output = 264 : i64, tf.resource_name = "state.model.decoder.8.attn.proj_v.weight"} loc(unknown), %arg16: tensor<768xf32> {tf.aliasing_output = 739 : i64, tf.resource_name = "state.model.decoder.8.ln_1.bias"} loc(unknown), %arg17: tensor<768xf32> {tf.aliasing_output = 734 : i64, tf.resource_name = "state.model.decoder.8.ln_1.weight"} loc(unknown), %arg18: tensor<768x3072xf32> {tf.aliasing_output = 249 : i64, tf.resource_name = "state.model.decoder.7.ffn.proj.weight"} loc(unknown), %arg19: tensor<3072x768xf32> {tf.aliasing_output = 244 : i64, tf.resource_name = "state.model.decoder.7.ffn.fc.weight"} loc(unknown), %arg20: tensor<768xf32> {tf.aliasing_output = 699 : i64, tf.resource_name = "state.model.decoder.7.ln_2.bias"} loc(unknown), %arg21: tensor<768xf32> {tf.aliasing_output = 694 : i64, tf.resource_name = "state.model.decoder.7.ln_2.weight"} loc(unknown), %arg22: tensor<768x768xf32> {tf.aliasing_output = 239 : i64, tf.resource_name = "state.model.decoder.7.attn.proj_output.weight"} loc(unknown), %arg23: tensor<768x768xf32> {tf.aliasing_output = 234 : i64, tf.resource_name = "state.model.decoder.7.attn.proj_v.weight"} loc(unknown), %arg24: tensor<768xf32> {tf.aliasing_output = 689 : i64, tf.resource_name = "state.model.decoder.7.ln_1.bias"} loc(unknown), %arg25: tensor<768xf32> {tf.aliasing_output = 684 : i64, tf.resource_name = "state.model.decoder.7.ln_1.weight"} loc(unknown), %arg26: tensor<768x3072xf32> {tf.aliasing_output = 219 : i64, tf.resource_name = "state.model.decoder.6.ffn.proj.weight"} loc(unknown), %arg27: tensor<3072x768xf32> {tf.aliasing_output = 214 : i64, tf.resource_name = "state.model.decoder.6.ffn.fc.weight"} loc(unknown), %arg28: tensor<768xf32> {tf.aliasing_output = 649 : i64, tf.resource_name = "state.model.decoder.6.ln_2.bias"} loc(unknown), %arg29: tensor<768xf32> {tf.aliasing_output = 644 : i64, tf.resource_name = "state.model.decoder.6.ln_2.weight"} loc(unknown), %arg30: tensor<768x768xf32> {tf.aliasing_output = 209 : i64, tf.resource_name = "state.model.decoder.6.attn.proj_output.weight"} loc(unknown), %arg31: tensor<768x768xf32> {tf.aliasing_output = 204 : i64, tf.resource_name = "state.model.decoder.6.attn.proj_v.weight"} loc(unknown), %arg32: tensor<768xf32> {tf.aliasing_output = 639 : i64, tf.resource_name = "state.model.decoder.6.ln_1.bias"} loc(unknown), %arg33: tensor<768xf32> {tf.aliasing_output = 634 : i64, tf.resource_name = "state.model.decoder.6.ln_1.weight"} loc(unknown), %arg34: tensor<768x3072xf32> {tf.aliasing_output = 189 : i64, tf.resource_name = "state.model.decoder.5.ffn.proj.weight"} loc(unknown), %arg35: tensor<3072x768xf32> {tf.aliasing_output = 184 : i64, tf.resource_name = "state.model.decoder.5.ffn.fc.weight"} loc(unknown), %arg36: tensor<768xf32> {tf.aliasing_output = 599 : i64, tf.resource_name = "state.model.decoder.5.ln_2.bias"} loc(unknown), %arg37: tensor<768xf32> {tf.aliasing_output = 594 : i64, tf.resource_name = "state.model.decoder.5.ln_2.weight"} loc(unknown), %arg38: tensor<768x768xf32> {tf.aliasing_output = 179 : i64, tf.resource_name = "state.model.decoder.5.attn.proj_output.weight"} loc(unknown), %arg39: tensor<768x768xf32> {tf.aliasing_output = 174 : i64, tf.resource_name = "state.model.decoder.5.attn.proj_v.weight"} loc(unknown), %arg40: tensor<768xf32> {tf.aliasing_output = 589 : i64, tf.resource_name = "state.model.decoder.5.ln_1.bias"} loc(unknown), %arg41: tensor<768xf32> {tf.aliasing_output = 584 : i64, tf.resource_name = "state.model.decoder.5.ln_1.weight"} loc(unknown), %arg42: tensor<768x3072xf32> {tf.aliasing_output = 159 : i64, tf.resource_name = "state.model.decoder.4.ffn.proj.weight"} loc(unknown), %arg43: tensor<3072x768xf32> {tf.aliasing_output = 154 : i64, tf.resource_name = "state.model.decoder.4.ffn.fc.weight"} loc(unknown), %arg44: tensor<768xf32> {tf.aliasing_output = 549 : i64, tf.resource_name = "state.model.decoder.4.ln_2.bias"} loc(unknown), %arg45: tensor<768xf32> {tf.aliasing_output = 544 : i64, tf.resource_name = "state.model.decoder.4.ln_2.weight"} loc(unknown), %arg46: tensor<768x768xf32> {tf.aliasing_output = 149 : i64, tf.resource_name = "state.model.decoder.4.attn.proj_output.weight"} loc(unknown), %arg47: tensor<768x768xf32> {tf.aliasing_output = 144 : i64, tf.resource_name = "state.model.decoder.4.attn.proj_v.weight"} loc(unknown), %arg48: tensor<768xf32> {tf.aliasing_output = 539 : i64, tf.resource_name = "state.model.decoder.4.ln_1.bias"} loc(unknown), %arg49: tensor<768xf32> {tf.aliasing_output = 534 : i64, tf.resource_name = "state.model.decoder.4.ln_1.weight"} loc(unknown), %arg50: tensor<768x3072xf32> {tf.aliasing_output = 129 : i64, tf.resource_name = "state.model.decoder.3.ffn.proj.weight"} loc(unknown), %arg51: tensor<3072x768xf32> {tf.aliasing_output = 124 : i64, tf.resource_name = "state.model.decoder.3.ffn.fc.weight"} loc(unknown), %arg52: tensor<768xf32> {tf.aliasing_output = 499 : i64, tf.resource_name = "state.model.decoder.3.ln_2.bias"} loc(unknown), %arg53: tensor<768xf32> {tf.aliasing_output = 494 : i64, tf.resource_name = "state.model.decoder.3.ln_2.weight"} loc(unknown), %arg54: tensor<768x768xf32> {tf.aliasing_output = 119 : i64, tf.resource_name = "state.model.decoder.3.attn.proj_output.weight"} loc(unknown), %arg55: tensor<768x768xf32> {tf.aliasing_output = 114 : i64, tf.resource_name = "state.model.decoder.3.attn.proj_v.weight"} loc(unknown), %arg56: tensor<768xf32> {tf.aliasing_output = 489 : i64, tf.resource_name = "state.model.decoder.3.ln_1.bias"} loc(unknown), %arg57: tensor<768xf32> {tf.aliasing_output = 484 : i64, tf.resource_name = "state.model.decoder.3.ln_1.weight"} loc(unknown), %arg58: tensor<768x3072xf32> {tf.aliasing_output = 99 : i64, tf.resource_name = "state.model.decoder.2.ffn.proj.weight"} loc(unknown), %arg59: tensor<3072x768xf32> {tf.aliasing_output = 94 : i64, tf.resource_name = "state.model.decoder.2.ffn.fc.weight"} loc(unknown), %arg60: tensor<768xf32> {tf.aliasing_output = 449 : i64, tf.resource_name = "state.model.decoder.2.ln_2.bias"} loc(unknown), %arg61: tensor<768xf32> {tf.aliasing_output = 444 : i64, tf.resource_name = "state.model.decoder.2.ln_2.weight"} loc(unknown), %arg62: tensor<768x768xf32> {tf.aliasing_output = 89 : i64, tf.resource_name = "state.model.decoder.2.attn.proj_output.weight"} loc(unknown), %arg63: tensor<768x768xf32> {tf.aliasing_output = 84 : i64, tf.resource_name = "state.model.decoder.2.attn.proj_v.weight"} loc(unknown), %arg64: tensor<768xf32> {tf.aliasing_output = 439 : i64, tf.resource_name = "state.model.decoder.2.ln_1.bias"} loc(unknown), %arg65: tensor<768xf32> {tf.aliasing_output = 434 : i64, tf.resource_name = "state.model.decoder.2.ln_1.weight"} loc(unknown), %arg66: tensor<768x3072xf32> {tf.aliasing_output = 69 : i64, tf.resource_name = "state.model.decoder.1.ffn.proj.weight"} loc(unknown), %arg67: tensor<3072x768xf32> {tf.aliasing_output = 64 : i64, tf.resource_name = "state.model.decoder.1.ffn.fc.weight"} loc(unknown), %arg68: tensor<768xf32> {tf.aliasing_output = 399 : i64, tf.resource_name = "state.model.decoder.1.ln_2.bias"} loc(unknown), %arg69: tensor<768xf32> {tf.aliasing_output = 394 : i64, tf.resource_name = "state.model.decoder.1.ln_2.weight"} loc(unknown), %arg70: tensor<768x768xf32> {tf.aliasing_output = 59 : i64, tf.resource_name = "state.model.decoder.1.attn.proj_output.weight"} loc(unknown), %arg71: tensor<768x768xf32> {tf.aliasing_output = 54 : i64, tf.resource_name = "state.model.decoder.1.attn.proj_v.weight"} loc(unknown), %arg72: tensor<768xf32> {tf.aliasing_output = 389 : i64, tf.resource_name = "state.model.decoder.1.ln_1.bias"} loc(unknown), %arg73: tensor<768xf32> {tf.aliasing_output = 384 : i64, tf.resource_name = "state.model.decoder.1.ln_1.weight"} loc(unknown), %arg74: tensor<768x3072xf32> {tf.aliasing_output = 39 : i64, tf.resource_name = "state.model.decoder.0.ffn.proj.weight"} loc(unknown), %arg75: tensor<3072x768xf32> {tf.aliasing_output = 34 : i64, tf.resource_name = "state.model.decoder.0.ffn.fc.weight"} loc(unknown), %arg76: tensor<768xf32> {tf.aliasing_output = 349 : i64, tf.resource_name = "state.model.decoder.0.ln_2.bias"} loc(unknown), %arg77: tensor<768xf32> {tf.aliasing_output = 344 : i64, tf.resource_name = "state.model.decoder.0.ln_2.weight"} loc(unknown), %arg78: tensor<768x768xf32> {tf.aliasing_output = 29 : i64, tf.resource_name = "state.model.decoder.0.attn.proj_output.weight"} loc(unknown), %arg79: tensor<768x768xf32> {tf.aliasing_output = 24 : i64, tf.resource_name = "state.model.decoder.0.attn.proj_v.weight"} loc(unknown), %arg80: tensor<768xf32> {tf.aliasing_output = 339 : i64, tf.resource_name = "state.model.decoder.0.ln_1.bias"} loc(unknown), %arg81: tensor<768xf32> {tf.aliasing_output = 334 : i64, tf.resource_name = "state.model.decoder.0.ln_1.weight"} loc(unknown), %arg82: tensor<2048x768xf32> {tf.aliasing_output = 9 : i64, tf.resource_name = "state.model.wpe.weight"} loc(unknown), %arg83: tensor<120x2048xi32> {cs.input_name = "input_0"} loc(unknown), %arg84: tensor<50257x768xf32> {tf.aliasing_output = 4 : i64, tf.resource_name = "state.model.lm_head.weight"} loc(unknown), %arg85: tensor<768xf32> {tf.aliasing_output = 324 : i64, tf.resource_name = "state.model.decoder.0.attn.proj_v.bias"} loc(unknown), %arg86: tensor<768x768xf32> {tf.aliasing_output = 19 : i64, tf.resource_name = "state.model.decoder.0.attn.proj_k.weight"} loc(unknown), %arg87: tensor<768xf32> {tf.aliasing_output = 319 : i64, tf.resource_name = "state.model.decoder.0.attn.proj_k.bias"} loc(unknown), %arg88: tensor<768x768xf32> {tf.aliasing_output = 14 : i64, tf.resource_name = "state.model.decoder.0.attn.proj_q.weight"} loc(unknown), %arg89: tensor<768xf32> {tf.aliasing_output = 314 : i64, tf.resource_name = "state.model.decoder.0.attn.proj_q.bias"} loc(unknown), %arg90: tensor<768xf32> {tf.aliasing_output = 329 : i64, tf.resource_name = "state.model.decoder.0.attn.proj_output.bias"} loc(unknown), %arg91: tensor<3072xf32> {tf.aliasing_output = 354 : i64, tf.resource_name = "state.model.decoder.0.ffn.fc.bias"} loc(unknown), %arg92: tensor<768xf32> {tf.aliasing_output = 359 : i64, tf.resource_name = "state.model.decoder.0.ffn.proj.bias"} loc(unknown), %arg93: tensor<768xf32> {tf.aliasing_output = 374 : i64, tf.resource_name = "state.model.decoder.1.attn.proj_v.bias"} loc(unknown), %arg94: tensor<768x768xf32> {tf.aliasing_output = 49 : i64, tf.resource_name = "state.model.decoder.1.attn.proj_k.weight"} loc(unknown), %arg95: tensor<768xf32> {tf.aliasing_output = 369 : i64, tf.resource_name = "state.model.decoder.1.attn.proj_k.bias"} loc(unknown), %arg96: tensor<768x768xf32> {tf.aliasing_output = 44 : i64, tf.resource_name = "state.model.decoder.1.attn.proj_q.weight"} loc(unknown), %arg97: tensor<768xf32> {tf.aliasing_output = 364 : i64, tf.resource_name = "state.model.decoder.1.attn.proj_q.bias"} loc(unknown), %arg98: tensor<768xf32> {tf.aliasing_output = 379 : i64, tf.resource_name = "state.model.decoder.1.attn.proj_output.bias"} loc(unknown), %arg99: tensor<3072xf32> {tf.aliasing_output = 404 : i64, tf.resource_name = "state.model.decoder.1.ffn.fc.bias"} loc(unknown), %arg100: tensor<768xf32> {tf.aliasing_output = 409 : i64, tf.resource_name = "state.model.decoder.1.ffn.proj.bias"} loc(unknown), %arg101: tensor<768xf32> {tf.aliasing_output = 424 : i64, tf.resource_name = "state.model.decoder.2.attn.proj_v.bias"} loc(unknown), %arg102: tensor<768x768xf32> {tf.aliasing_output = 79 : i64, tf.resource_name = "state.model.decoder.2.attn.proj_k.weight"} loc(unknown), %arg103: tensor<768xf32> {tf.aliasing_output = 419 : i64, tf.resource_name = "state.model.decoder.2.attn.proj_k.bias"} loc(unknown), %arg104: tensor<768x768xf32> {tf.aliasing_output = 74 : i64, tf.resource_name = "state.model.decoder.2.attn.proj_q.weight"} loc(unknown), %arg105: tensor<768xf32> {tf.aliasing_output = 414 : i64, tf.resource_name = "state.model.decoder.2.attn.proj_q.bias"} loc(unknown), %arg106: tensor<768xf32> {tf.aliasing_output = 429 : i64, tf.resource_name = "state.model.decoder.2.attn.proj_output.bias"} loc(unknown), %arg107: tensor<3072xf32> {tf.aliasing_output = 454 : i64, tf.resource_name = "state.model.decoder.2.ffn.fc.bias"} loc(unknown), %arg108: tensor<768xf32> {tf.aliasing_output = 459 : i64, tf.resource_name = "state.model.decoder.2.ffn.proj.bias"} loc(unknown), %arg109: tensor<768xf32> {tf.aliasing_output = 474 : i64, tf.resource_name = "state.model.decoder.3.attn.proj_v.bias"} loc(unknown), %arg110: tensor<768x768xf32> {tf.aliasing_output = 109 : i64, tf.resource_name = "state.model.decoder.3.attn.proj_k.weight"} loc(unknown), %arg111: tensor<768xf32> {tf.aliasing_output = 469 : i64, tf.resource_name = "state.model.decoder.3.attn.proj_k.bias"} loc(unknown), %arg112: tensor<768x768xf32> {tf.aliasing_output = 104 : i64, tf.resource_name = "state.model.decoder.3.attn.proj_q.weight"} loc(unknown), %arg113: tensor<768xf32> {tf.aliasing_output = 464 : i64, tf.resource_name = "state.model.decoder.3.attn.proj_q.bias"} loc(unknown), %arg114: tensor<768xf32> {tf.aliasing_output = 479 : i64, tf.resource_name = "state.model.decoder.3.attn.proj_output.bias"} loc(unknown), %arg115: tensor<3072xf32> {tf.aliasing_output = 504 : i64, tf.resource_name = "state.model.decoder.3.ffn.fc.bias"} loc(unknown), %arg116: tensor<768xf32> {tf.aliasing_output = 509 : i64, tf.resource_name = "state.model.decoder.3.ffn.proj.bias"} loc(unknown), %arg117: tensor<768xf32> {tf.aliasing_output = 524 : i64, tf.resource_name = "state.model.decoder.4.attn.proj_v.bias"} loc(unknown), %arg118: tensor<768x768xf32> {tf.aliasing_output = 139 : i64, tf.resource_name = "state.model.decoder.4.attn.proj_k.weight"} loc(unknown), %arg119: tensor<768xf32> {tf.aliasing_output = 519 : i64, tf.resource_name = "state.model.decoder.4.attn.proj_k.bias"} loc(unknown), %arg120: tensor<768x768xf32> {tf.aliasing_output = 134 : i64, tf.resource_name = "state.model.decoder.4.attn.proj_q.weight"} loc(unknown), %arg121: tensor<768xf32> {tf.aliasing_output = 514 : i64, tf.resource_name = "state.model.decoder.4.attn.proj_q.bias"} loc(unknown), %arg122: tensor<768xf32> {tf.aliasing_output = 529 : i64, tf.resource_name = "state.model.decoder.4.attn.proj_output.bias"} loc(unknown), %arg123: tensor<3072xf32> {tf.aliasing_output = 554 : i64, tf.resource_name = "state.model.decoder.4.ffn.fc.bias"} loc(unknown), %arg124: tensor<768xf32> {tf.aliasing_output = 559 : i64, tf.resource_name = "state.model.decoder.4.ffn.proj.bias"} loc(unknown), %arg125: tensor<768xf32> {tf.aliasing_output = 574 : i64, tf.resource_name = "state.model.decoder.5.attn.proj_v.bias"} loc(unknown), %arg126: tensor<768x768xf32> {tf.aliasing_output = 169 : i64, tf.resource_name = "state.model.decoder.5.attn.proj_k.weight"} loc(unknown), %arg127: tensor<768xf32> {tf.aliasing_output = 569 : i64, tf.resource_name = "state.model.decoder.5.attn.proj_k.bias"} loc(unknown), %arg128: tensor<768x768xf32> {tf.aliasing_output = 164 : i64, tf.resource_name = "state.model.decoder.5.attn.proj_q.weight"} loc(unknown), %arg129: tensor<768xf32> {tf.aliasing_output = 564 : i64, tf.resource_name = "state.model.decoder.5.attn.proj_q.bias"} loc(unknown), %arg130: tensor<768xf32> {tf.aliasing_output = 579 : i64, tf.resource_name = "state.model.decoder.5.attn.proj_output.bias"} loc(unknown), %arg131: tensor<3072xf32> {tf.aliasing_output = 604 : i64, tf.resource_name = "state.model.decoder.5.ffn.fc.bias"} loc(unknown), %arg132: tensor<768xf32> {tf.aliasing_output = 609 : i64, tf.resource_name = "state.model.decoder.5.ffn.proj.bias"} loc(unknown), %arg133: tensor<768xf32> {tf.aliasing_output = 624 : i64, tf.resource_name = "state.model.decoder.6.attn.proj_v.bias"} loc(unknown), %arg134: tensor<768x768xf32> {tf.aliasing_output = 199 : i64, tf.resource_name = "state.model.decoder.6.attn.proj_k.weight"} loc(unknown), %arg135: tensor<768xf32> {tf.aliasing_output = 619 : i64, tf.resource_name = "state.model.decoder.6.attn.proj_k.bias"} loc(unknown), %arg136: tensor<768x768xf32> {tf.aliasing_output = 194 : i64, tf.resource_name = "state.model.decoder.6.attn.proj_q.weight"} loc(unknown), %arg137: tensor<768xf32> {tf.aliasing_output = 614 : i64, tf.resource_name = "state.model.decoder.6.attn.proj_q.bias"} loc(unknown), %arg138: tensor<768xf32> {tf.aliasing_output = 629 : i64, tf.resource_name = "state.model.decoder.6.attn.proj_output.bias"} loc(unknown), %arg139: tensor<3072xf32> {tf.aliasing_output = 654 : i64, tf.resource_name = "state.model.decoder.6.ffn.fc.bias"} loc(unknown), %arg140: tensor<768xf32> {tf.aliasing_output = 659 : i64, tf.resource_name = "state.model.decoder.6.ffn.proj.bias"} loc(unknown), %arg141: tensor<768xf32> {tf.aliasing_output = 674 : i64, tf.resource_name = "state.model.decoder.7.attn.proj_v.bias"} loc(unknown), %arg142: tensor<768x768xf32> {tf.aliasing_output = 229 : i64, tf.resource_name = "state.model.decoder.7.attn.proj_k.weight"} loc(unknown), %arg143: tensor<768xf32> {tf.aliasing_output = 669 : i64, tf.resource_name = "state.model.decoder.7.attn.proj_k.bias"} loc(unknown), %arg144: tensor<768x768xf32> {tf.aliasing_output = 224 : i64, tf.resource_name = "state.model.decoder.7.attn.proj_q.weight"} loc(unknown), %arg145: tensor<768xf32> {tf.aliasing_output = 664 : i64, tf.resource_name = "state.model.decoder.7.attn.proj_q.bias"} loc(unknown), %arg146: tensor<768xf32> {tf.aliasing_output = 679 : i64, tf.resource_name = "state.model.decoder.7.attn.proj_output.bias"} loc(unknown), %arg147: tensor<3072xf32> {tf.aliasing_output = 704 : i64, tf.resource_name = "state.model.decoder.7.ffn.fc.bias"} loc(unknown), %arg148: tensor<768xf32> {tf.aliasing_output = 709 : i64, tf.resource_name = "state.model.decoder.7.ffn.proj.bias"} loc(unknown), %arg149: tensor<768xf32> {tf.aliasing_output = 724 : i64, tf.resource_name = "state.model.decoder.8.attn.proj_v.bias"} loc(unknown), %arg150: tensor<768x768xf32> {tf.aliasing_output = 259 : i64, tf.resource_name = "state.model.decoder.8.attn.proj_k.weight"} loc(unknown), %arg151: tensor<768xf32> {tf.aliasing_output = 719 : i64, tf.resource_name = "state.model.decoder.8.attn.proj_k.bias"} loc(unknown), %arg152: tensor<768x768xf32> {tf.aliasing_output = 254 : i64, tf.resource_name = "state.model.decoder.8.attn.proj_q.weight"} loc(unknown), %arg153: tensor<768xf32> {tf.aliasing_output = 714 : i64, tf.resource_name = "state.model.decoder.8.attn.proj_q.bias"} loc(unknown), %arg154: tensor<768xf32> {tf.aliasing_output = 729 : i64, tf.resource_name = "state.model.decoder.8.attn.proj_output.bias"} loc(unknown), %arg155: tensor<3072xf32> {tf.aliasing_output = 754 : i64, tf.resource_name = "state.model.decoder.8.ffn.fc.bias"} loc(unknown), %arg156: tensor<768xf32> {tf.aliasing_output = 759 : i64, tf.resource_name = "state.model.decoder.8.ffn.proj.bias"} loc(unknown), %arg157: tensor<768xf32> {tf.aliasing_output = 774 : i64, tf.resource_name = "state.model.decoder.9.attn.proj_v.bias"} loc(unknown), %arg158: tensor<768x768xf32> {tf.aliasing_output = 289 : i64, tf.resource_name = "state.model.decoder.9.attn.proj_k.weight"} loc(unknown), %arg159: tensor<768xf32> {tf.aliasing_output = 769 : i64, tf.resource_name = "state.model.decoder.9.attn.proj_k.bias"} loc(unknown), %arg160: tensor<768x768xf32> {tf.aliasing_output = 284 : i64, tf.resource_name = "state.model.decoder.9.attn.proj_q.weight"} loc(unknown), %arg161: tensor<768xf32> {tf.aliasing_output = 764 : i64, tf.resource_name = "state.model.decoder.9.attn.proj_q.bias"} loc(unknown), %arg162: tensor<768xf32> {tf.aliasing_output = 779 : i64, tf.resource_name = "state.model.decoder.9.attn.proj_output.bias"} loc(unknown), %arg163: tensor<3072xf32> {tf.aliasing_output = 804 : i64, tf.resource_name = "state.model.decoder.9.ffn.fc.bias"} loc(unknown), %arg164: tensor<768xf32> {tf.aliasing_output = 809 : i64, tf.resource_name = "state.model.decoder.9.ffn.proj.bias"} loc(unknown), %arg165: tensor<120x2048xi32> {cs.input_name = "input_1"} loc(unknown), %arg166: tensor<50257x768xf32> {tf.aliasing_output = 0 : i64, tf.resource_name = "state.optimizer.state.0.exp_avg"} loc(unknown), %arg167: tensor<50257x768xf32> {tf.aliasing_output = 1 : i64, tf.resource_name = "state.optimizer.state.0.exp_avg_sq"} loc(unknown), %arg168: tensor<f32> {tf.aliasing_output = 2 : i64, tf.resource_name = "state.optimizer.state.0.beta1_power"} loc(unknown), %arg169: tensor<f32> {tf.aliasing_output = 3 : i64, tf.resource_name = "state.optimizer.state.0.beta2_power"} loc(unknown), %arg170: tensor<i64> {tf.aliasing_output = 822 : i64, tf.resource_name = "state.lr_scheduler.0._schedulers.1.last_epoch"} loc(unknown), %arg171: tensor<i64> {tf.aliasing_output = 821 : i64, tf.resource_name = "state.lr_scheduler.0._schedulers.0.last_epoch"} loc(unknown), %arg172: tensor<i64> {tf.aliasing_output = 820 : i64, tf.resource_name = "state.lr_scheduler.0.last_epoch"} loc(unknown), %arg173: tensor<2048x768xf32> {tf.aliasing_output = 5 : i64, tf.resource_name = "state.optimizer.state.1.exp_avg"} loc(unknown), %arg174: tensor<2048x768xf32> {tf.aliasing_output = 6 : i64, tf.resource_name = "state.optimizer.state.1.exp_avg_sq"} loc(unknown), %arg175: tensor<f32> {tf.aliasing_output = 7 : i64, tf.resource_name = "state.optimizer.state.1.beta1_power"} loc(unknown), %arg176: tensor<f32> {tf.aliasing_output = 8 : i64, tf.resource_name = "state.optimizer.state.1.beta2_power"} loc(unknown), %arg177: tensor<768x768xf32> {tf.aliasing_output = 10 : i64, tf.resource_name = "state.optimizer.state.2.exp_avg"} loc(unknown), %arg178: tensor<768x768xf32> {tf.aliasing_output = 11 : i64, tf.resource_name = "state.optimizer.state.2.exp_avg_sq"} loc(unknown), %arg179: tensor<f32> {tf.aliasing_output = 12 : i64, tf.resource_name = "state.optimizer.state.2.beta1_power"} loc(unknown), %arg180: tensor<f32> {tf.aliasing_output = 13 : i64, tf.resource_name = "state.optimizer.state.2.beta2_power"} loc(unknown), %arg181: tensor<768x768xf32> {tf.aliasing_output = 15 : i64, tf.resource_name = "state.optimizer.state.3.exp_avg"} loc(unknown), %arg182: tensor<768x768xf32> {tf.aliasing_output = 16 : i64, tf.resource_name = "state.optimizer.state.3.exp_avg_sq"} loc(unknown), %arg183: tensor<f32> {tf.aliasing_output = 17 : i64, tf.resource_name = "state.optimizer.state.3.beta1_power"} loc(unknown), %arg184: tensor<f32> {tf.aliasing_output = 18 : i64, tf.resource_name = "state.optimizer.state.3.beta2_power"} loc(unknown), %arg185: tensor<768x768xf32> {tf.aliasing_output = 20 : i64, tf.resource_name = "state.optimizer.state.4.exp_avg"} loc(unknown), %arg186: tensor<768x768xf32> {tf.aliasing_output = 21 : i64, tf.resource_name = "state.optimizer.state.4.exp_avg_sq"} loc(unknown), %arg187: tensor<f32> {tf.aliasing_output = 22 : i64, tf.resource_name = "state.optimizer.state.4.beta1_power"} loc(unknown), %arg188: tensor<f32> {tf.aliasing_output = 23 : i64, tf.resource_name = "state.optimizer.state.4.beta2_power"} loc(unknown), %arg189: tensor<768x768xf32> {tf.aliasing_output = 25 : i64, tf.resource_name = "state.optimizer.state.5.exp_avg"} loc(unknown), %arg190: tensor<768x768xf32> {tf.aliasing_output = 26 : i64, tf.resource_name = "state.optimizer.state.5.exp_avg_sq"} loc(unknown), %arg191: tensor<f32> {tf.aliasing_output = 27 : i64, tf.resource_name = "state.optimizer.state.5.beta1_power"} loc(unknown), %arg192: tensor<f32> {tf.aliasing_output = 28 : i64, tf.resource_name = "state.optimizer.state.5.beta2_power"} loc(unknown), %arg193: tensor<3072x768xf32> {tf.aliasing_output = 30 : i64, tf.resource_name = "state.optimizer.state.6.exp_avg"} loc(unknown), %arg194: tensor<3072x768xf32> {tf.aliasing_output = 31 : i64, tf.resource_name = "state.optimizer.state.6.exp_avg_sq"} loc(unknown), %arg195: tensor<f32> {tf.aliasing_output = 32 : i64, tf.resource_name = "state.optimizer.state.6.beta1_power"} loc(unknown), %arg196: tensor<f32> {tf.aliasing_output = 33 : i64, tf.resource_name = "state.optimizer.state.6.beta2_power"} loc(unknown), %arg197: tensor<768x3072xf32> {tf.aliasing_output = 35 : i64, tf.resource_name = "state.optimizer.state.7.exp_avg"} loc(unknown), %arg198: tensor<768x3072xf32> {tf.aliasing_output = 36 : i64, tf.resource_name = "state.optimizer.state.7.exp_avg_sq"} loc(unknown), %arg199: tensor<f32> {tf.aliasing_output = 37 : i64, tf.resource_name = "state.optimizer.state.7.beta1_power"} loc(unknown), %arg200: tensor<f32> {tf.aliasing_output = 38 : i64, tf.resource_name = "state.optimizer.state.7.beta2_power"} loc(unknown), %arg201: tensor<768x768xf32> {tf.aliasing_output = 40 : i64, tf.resource_name = "state.optimizer.state.8.exp_avg"} loc(unknown), %arg202: tensor<768x768xf32> {tf.aliasing_output = 41 : i64, tf.resource_name = "state.optimizer.state.8.exp_avg_sq"} loc(unknown), %arg203: tensor<f32> {tf.aliasing_output = 42 : i64, tf.resource_name = "state.optimizer.state.8.beta1_power"} loc(unknown), %arg204: tensor<f32> {tf.aliasing_output = 43 : i64, tf.resource_name = "state.optimizer.state.8.beta2_power"} loc(unknown), %arg205: tensor<768x768xf32> {tf.aliasing_output = 45 : i64, tf.resource_name = "state.optimizer.state.9.exp_avg"} loc(unknown), %arg206: tensor<768x768xf32> {tf.aliasing_output = 46 : i64, tf.resource_name = "state.optimizer.state.9.exp_avg_sq"} loc(unknown), %arg207: tensor<f32> {tf.aliasing_output = 47 : i64, tf.resource_name = "state.optimizer.state.9.beta1_power"} loc(unknown), %arg208: tensor<f32> {tf.aliasing_output = 48 : i64, tf.resource_name = "state.optimizer.state.9.beta2_power"} loc(unknown), %arg209: tensor<768x768xf32> {tf.aliasing_output = 50 : i64, tf.resource_name = "state.optimizer.state.10.exp_avg"} loc(unknown), %arg210: tensor<768x768xf32> {tf.aliasing_output = 51 : i64, tf.resource_name = "state.optimizer.state.10.exp_avg_sq"} loc(unknown), %arg211: tensor<f32> {tf.aliasing_output = 52 : i64, tf.resource_name = "state.optimizer.state.10.beta1_power"} loc(unknown), %arg212: tensor<f32> {tf.aliasing_output = 53 : i64, tf.resource_name = "state.optimizer.state.10.beta2_power"} loc(unknown), %arg213: tensor<768x768xf32> {tf.aliasing_output = 55 : i64, tf.resource_name = "state.optimizer.state.11.exp_avg"} loc(unknown), %arg214: tensor<768x768xf32> {tf.aliasing_output = 56 : i64, tf.resource_name = "state.optimizer.state.11.exp_avg_sq"} loc(unknown), %arg215: tensor<f32> {tf.aliasing_output = 57 : i64, tf.resource_name = "state.optimizer.state.11.beta1_power"} loc(unknown), %arg216: tensor<f32> {tf.aliasing_output = 58 : i64, tf.resource_name = "state.optimizer.state.11.beta2_power"} loc(unknown), %arg217: tensor<3072x768xf32> {tf.aliasing_output = 60 : i64, tf.resource_name = "state.optimizer.state.12.exp_avg"} loc(unknown), %arg218: tensor<3072x768xf32> {tf.aliasing_output = 61 : i64, tf.resource_name = "state.optimizer.state.12.exp_avg_sq"} loc(unknown), %arg219: tensor<f32> {tf.aliasing_output = 62 : i64, tf.resource_name = "state.optimizer.state.12.beta1_power"} loc(unknown), %arg220: tensor<f32> {tf.aliasing_output = 63 : i64, tf.resource_name = "state.optimizer.state.12.beta2_power"} loc(unknown), %arg221: tensor<768x3072xf32> {tf.aliasing_output = 65 : i64, tf.resource_name = "state.optimizer.state.13.exp_avg"} loc(unknown), %arg222: tensor<768x3072xf32> {tf.aliasing_output = 66 : i64, tf.resource_name = "state.optimizer.state.13.exp_avg_sq"} loc(unknown), %arg223: tensor<f32> {tf.aliasing_output = 67 : i64, tf.resource_name = "state.optimizer.state.13.beta1_power"} loc(unknown), %arg224: tensor<f32> {tf.aliasing_output = 68 : i64, tf.resource_name = "state.optimizer.state.13.beta2_power"} loc(unknown), %arg225: tensor<768x768xf32> {tf.aliasing_output = 70 : i64, tf.resource_name = "state.optimizer.state.14.exp_avg"} loc(unknown), %arg226: tensor<768x768xf32> {tf.aliasing_output = 71 : i64, tf.resource_name = "state.optimizer.state.14.exp_avg_sq"} loc(unknown), %arg227: tensor<f32> {tf.aliasing_output = 72 : i64, tf.resource_name = "state.optimizer.state.14.beta1_power"} loc(unknown), %arg228: tensor<f32> {tf.aliasing_output = 73 : i64, tf.resource_name = "state.optimizer.state.14.beta2_power"} loc(unknown), %arg229: tensor<768x768xf32> {tf.aliasing_output = 75 : i64, tf.resource_name = "state.optimizer.state.15.exp_avg"} loc(unknown), %arg230: tensor<768x768xf32> {tf.aliasing_output = 76 : i64, tf.resource_name = "state.optimizer.state.15.exp_avg_sq"} loc(unknown), %arg231: tensor<f32> {tf.aliasing_output = 77 : i64, tf.resource_name = "state.optimizer.state.15.beta1_power"} loc(unknown), %arg232: tensor<f32> {tf.aliasing_output = 78 : i64, tf.resource_name = "state.optimizer.state.15.beta2_power"} loc(unknown), %arg233: tensor<768x768xf32> {tf.aliasing_output = 80 : i64, tf.resource_name = "state.optimizer.state.16.exp_avg"} loc(unknown), %arg234: tensor<768x768xf32> {tf.aliasing_output = 81 : i64, tf.resource_name = "state.optimizer.state.16.exp_avg_sq"} loc(unknown), %arg235: tensor<f32> {tf.aliasing_output = 82 : i64, tf.resource_name = "state.optimizer.state.16.beta1_power"} loc(unknown), %arg236: tensor<f32> {tf.aliasing_output = 83 : i64, tf.resource_name = "state.optimizer.state.16.beta2_power"} loc(unknown), %arg237: tensor<768x768xf32> {tf.aliasing_output = 85 : i64, tf.resource_name = "state.optimizer.state.17.exp_avg"} loc(unknown), %arg238: tensor<768x768xf32> {tf.aliasing_output = 86 : i64, tf.resource_name = "state.optimizer.state.17.exp_avg_sq"} loc(unknown), %arg239: tensor<f32> {tf.aliasing_output = 87 : i64, tf.resource_name = "state.optimizer.state.17.beta1_power"} loc(unknown), %arg240: tensor<f32> {tf.aliasing_output = 88 : i64, tf.resource_name = "state.optimizer.state.17.beta2_power"} loc(unknown), %arg241: tensor<3072x768xf32> {tf.aliasing_output = 90 : i64, tf.resource_name = "state.optimizer.state.18.exp_avg"} loc(unknown), %arg242: tensor<3072x768xf32> {tf.aliasing_output = 91 : i64, tf.resource_name = "state.optimizer.state.18.exp_avg_sq"} loc(unknown), %arg243: tensor<f32> {tf.aliasing_output = 92 : i64, tf.resource_name = "state.optimizer.state.18.beta1_power"} loc(unknown), %arg244: tensor<f32> {tf.aliasing_output = 93 : i64, tf.resource_name = "state.optimizer.state.18.beta2_power"} loc(unknown), %arg245: tensor<768x3072xf32> {tf.aliasing_output = 95 : i64, tf.resource_name = "state.optimizer.state.19.exp_avg"} loc(unknown), %arg246: tensor<768x3072xf32> {tf.aliasing_output = 96 : i64, tf.resource_name = "state.optimizer.state.19.exp_avg_sq"} loc(unknown), %arg247: tensor<f32> {tf.aliasing_output = 97 : i64, tf.resource_name = "state.optimizer.state.19.beta1_power"} loc(unknown), %arg248: tensor<f32> {tf.aliasing_output = 98 : i64, tf.resource_name = "state.optimizer.state.19.beta2_power"} loc(unknown), %arg249: tensor<768x768xf32> {tf.aliasing_output = 100 : i64, tf.resource_name = "state.optimizer.state.20.exp_avg"} loc(unknown), %arg250: tensor<768x768xf32> {tf.aliasing_output = 101 : i64, tf.resource_name = "state.optimizer.state.20.exp_avg_sq"} loc(unknown), %arg251: tensor<f32> {tf.aliasing_output = 102 : i64, tf.resource_name = "state.optimizer.state.20.beta1_power"} loc(unknown), %arg252: tensor<f32> {tf.aliasing_output = 103 : i64, tf.resource_name = "state.optimizer.state.20.beta2_power"} loc(unknown), %arg253: tensor<768x768xf32> {tf.aliasing_output = 105 : i64, tf.resource_name = "state.optimizer.state.21.exp_avg"} loc(unknown), %arg254: tensor<768x768xf32> {tf.aliasing_output = 106 : i64, tf.resource_name = "state.optimizer.state.21.exp_avg_sq"} loc(unknown), %arg255: tensor<f32> {tf.aliasing_output = 107 : i64, tf.resource_name = "state.optimizer.state.21.beta1_power"} loc(unknown), %arg256: tensor<f32> {tf.aliasing_output = 108 : i64, tf.resource_name = "state.optimizer.state.21.beta2_power"} loc(unknown), %arg257: tensor<768x768xf32> {tf.aliasing_output = 110 : i64, tf.resource_name = "state.optimizer.state.22.exp_avg"} loc(unknown), %arg258: tensor<768x768xf32> {tf.aliasing_output = 111 : i64, tf.resource_name = "state.optimizer.state.22.exp_avg_sq"} loc(unknown), %arg259: tensor<f32> {tf.aliasing_output = 112 : i64, tf.resource_name = "state.optimizer.state.22.beta1_power"} loc(unknown), %arg260: tensor<f32> {tf.aliasing_output = 113 : i64, tf.resource_name = "state.optimizer.state.22.beta2_power"} loc(unknown), %arg261: tensor<768x768xf32> {tf.aliasing_output = 115 : i64, tf.resource_name = "state.optimizer.state.23.exp_avg"} loc(unknown), %arg262: tensor<768x768xf32> {tf.aliasing_output = 116 : i64, tf.resource_name = "state.optimizer.state.23.exp_avg_sq"} loc(unknown), %arg263: tensor<f32> {tf.aliasing_output = 117 : i64, tf.resource_name = "state.optimizer.state.23.beta1_power"} loc(unknown), %arg264: tensor<f32> {tf.aliasing_output = 118 : i64, tf.resource_name = "state.optimizer.state.23.beta2_power"} loc(unknown), %arg265: tensor<3072x768xf32> {tf.aliasing_output = 120 : i64, tf.resource_name = "state.optimizer.state.24.exp_avg"} loc(unknown), %arg266: tensor<3072x768xf32> {tf.aliasing_output = 121 : i64, tf.resource_name = "state.optimizer.state.24.exp_avg_sq"} loc(unknown), %arg267: tensor<f32> {tf.aliasing_output = 122 : i64, tf.resource_name = "state.optimizer.state.24.beta1_power"} loc(unknown), %arg268: tensor<f32> {tf.aliasing_output = 123 : i64, tf.resource_name = "state.optimizer.state.24.beta2_power"} loc(unknown), %arg269: tensor<768x3072xf32> {tf.aliasing_output = 125 : i64, tf.resource_name = "state.optimizer.state.25.exp_avg"} loc(unknown), %arg270: tensor<768x3072xf32> {tf.aliasing_output = 126 : i64, tf.resource_name = "state.optimizer.state.25.exp_avg_sq"} loc(unknown), %arg271: tensor<f32> {tf.aliasing_output = 127 : i64, tf.resource_name = "state.optimizer.state.25.beta1_power"} loc(unknown), %arg272: tensor<f32> {tf.aliasing_output = 128 : i64, tf.resource_name = "state.optimizer.state.25.beta2_power"} loc(unknown), %arg273: tensor<768x768xf32> {tf.aliasing_output = 130 : i64, tf.resource_name = "state.optimizer.state.26.exp_avg"} loc(unknown), %arg274: tensor<768x768xf32> {tf.aliasing_output = 131 : i64, tf.resource_name = "state.optimizer.state.26.exp_avg_sq"} loc(unknown), %arg275: tensor<f32> {tf.aliasing_output = 132 : i64, tf.resource_name = "state.optimizer.state.26.beta1_power"} loc(unknown), %arg276: tensor<f32> {tf.aliasing_output = 133 : i64, tf.resource_name = "state.optimizer.state.26.beta2_power"} loc(unknown), %arg277: tensor<768x768xf32> {tf.aliasing_output = 135 : i64, tf.resource_name = "state.optimizer.state.27.exp_avg"} loc(unknown), %arg278: tensor<768x768xf32> {tf.aliasing_output = 136 : i64, tf.resource_name = "state.optimizer.state.27.exp_avg_sq"} loc(unknown), %arg279: tensor<f32> {tf.aliasing_output = 137 : i64, tf.resource_name = "state.optimizer.state.27.beta1_power"} loc(unknown), %arg280: tensor<f32> {tf.aliasing_output = 138 : i64, tf.resource_name = "state.optimizer.state.27.beta2_power"} loc(unknown), %arg281: tensor<768x768xf32> {tf.aliasing_output = 140 : i64, tf.resource_name = "state.optimizer.state.28.exp_avg"} loc(unknown), %arg282: tensor<768x768xf32> {tf.aliasing_output = 141 : i64, tf.resource_name = "state.optimizer.state.28.exp_avg_sq"} loc(unknown), %arg283: tensor<f32> {tf.aliasing_output = 142 : i64, tf.resource_name = "state.optimizer.state.28.beta1_power"} loc(unknown), %arg284: tensor<f32> {tf.aliasing_output = 143 : i64, tf.resource_name = "state.optimizer.state.28.beta2_power"} loc(unknown), %arg285: tensor<768x768xf32> {tf.aliasing_output = 145 : i64, tf.resource_name = "state.optimizer.state.29.exp_avg"} loc(unknown), %arg286: tensor<768x768xf32> {tf.aliasing_output = 146 : i64, tf.resource_name = "state.optimizer.state.29.exp_avg_sq"} loc(unknown), %arg287: tensor<f32> {tf.aliasing_output = 147 : i64, tf.resource_name = "state.optimizer.state.29.beta1_power"} loc(unknown), %arg288: tensor<f32> {tf.aliasing_output = 148 : i64, tf.resource_name = "state.optimizer.state.29.beta2_power"} loc(unknown), %arg289: tensor<3072x768xf32> {tf.aliasing_output = 150 : i64, tf.resource_name = "state.optimizer.state.30.exp_avg"} loc(unknown), %arg290: tensor<3072x768xf32> {tf.aliasing_output = 151 : i64, tf.resource_name = "state.optimizer.state.30.exp_avg_sq"} loc(unknown), %arg291: tensor<f32> {tf.aliasing_output = 152 : i64, tf.resource_name = "state.optimizer.state.30.beta1_power"} loc(unknown), %arg292: tensor<f32> {tf.aliasing_output = 153 : i64, tf.resource_name = "state.optimizer.state.30.beta2_power"} loc(unknown), %arg293: tensor<768x3072xf32> {tf.aliasing_output = 155 : i64, tf.resource_name = "state.optimizer.state.31.exp_avg"} loc(unknown), %arg294: tensor<768x3072xf32> {tf.aliasing_output = 156 : i64, tf.resource_name = "state.optimizer.state.31.exp_avg_sq"} loc(unknown), %arg295: tensor<f32> {tf.aliasing_output = 157 : i64, tf.resource_name = "state.optimizer.state.31.beta1_power"} loc(unknown), %arg296: tensor<f32> {tf.aliasing_output = 158 : i64, tf.resource_name = "state.optimizer.state.31.beta2_power"} loc(unknown), %arg297: tensor<768x768xf32> {tf.aliasing_output = 160 : i64, tf.resource_name = "state.optimizer.state.32.exp_avg"} loc(unknown), %arg298: tensor<768x768xf32> {tf.aliasing_output = 161 : i64, tf.resource_name = "state.optimizer.state.32.exp_avg_sq"} loc(unknown), %arg299: tensor<f32> {tf.aliasing_output = 162 : i64, tf.resource_name = "state.optimizer.state.32.beta1_power"} loc(unknown), %arg300: tensor<f32> {tf.aliasing_output = 163 : i64, tf.resource_name = "state.optimizer.state.32.beta2_power"} loc(unknown), %arg301: tensor<768x768xf32> {tf.aliasing_output = 165 : i64, tf.resource_name = "state.optimizer.state.33.exp_avg"} loc(unknown), %arg302: tensor<768x768xf32> {tf.aliasing_output = 166 : i64, tf.resource_name = "state.optimizer.state.33.exp_avg_sq"} loc(unknown), %arg303: tensor<f32> {tf.aliasing_output = 167 : i64, tf.resource_name = "state.optimizer.state.33.beta1_power"} loc(unknown), %arg304: tensor<f32> {tf.aliasing_output = 168 : i64, tf.resource_name = "state.optimizer.state.33.beta2_power"} loc(unknown), %arg305: tensor<768x768xf32> {tf.aliasing_output = 170 : i64, tf.resource_name = "state.optimizer.state.34.exp_avg"} loc(unknown), %arg306: tensor<768x768xf32> {tf.aliasing_output = 171 : i64, tf.resource_name = "state.optimizer.state.34.exp_avg_sq"} loc(unknown), %arg307: tensor<f32> {tf.aliasing_output = 172 : i64, tf.resource_name = "state.optimizer.state.34.beta1_power"} loc(unknown), %arg308: tensor<f32> {tf.aliasing_output = 173 : i64, tf.resource_name = "state.optimizer.state.34.beta2_power"} loc(unknown), %arg309: tensor<768x768xf32> {tf.aliasing_output = 175 : i64, tf.resource_name = "state.optimizer.state.35.exp_avg"} loc(unknown), %arg310: tensor<768x768xf32> {tf.aliasing_output = 176 : i64, tf.resource_name = "state.optimizer.state.35.exp_avg_sq"} loc(unknown), %arg311: tensor<f32> {tf.aliasing_output = 177 : i64, tf.resource_name = "state.optimizer.state.35.beta1_power"} loc(unknown), %arg312: tensor<f32> {tf.aliasing_output = 178 : i64, tf.resource_name = "state.optimizer.state.35.beta2_power"} loc(unknown), %arg313: tensor<3072x768xf32> {tf.aliasing_output = 180 : i64, tf.resource_name = "state.optimizer.state.36.exp_avg"} loc(unknown), %arg314: tensor<3072x768xf32> {tf.aliasing_output = 181 : i64, tf.resource_name = "state.optimizer.state.36.exp_avg_sq"} loc(unknown), %arg315: tensor<f32> {tf.aliasing_output = 182 : i64, tf.resource_name = "state.optimizer.state.36.beta1_power"} loc(unknown), %arg316: tensor<f32> {tf.aliasing_output = 183 : i64, tf.resource_name = "state.optimizer.state.36.beta2_power"} loc(unknown), %arg317: tensor<768x3072xf32> {tf.aliasing_output = 185 : i64, tf.resource_name = "state.optimizer.state.37.exp_avg"} loc(unknown), %arg318: tensor<768x3072xf32> {tf.aliasing_output = 186 : i64, tf.resource_name = "state.optimizer.state.37.exp_avg_sq"} loc(unknown), %arg319: tensor<f32> {tf.aliasing_output = 187 : i64, tf.resource_name = "state.optimizer.state.37.beta1_power"} loc(unknown), %arg320: tensor<f32> {tf.aliasing_output = 188 : i64, tf.resource_name = "state.optimizer.state.37.beta2_power"} loc(unknown), %arg321: tensor<768x768xf32> {tf.aliasing_output = 190 : i64, tf.resource_name = "state.optimizer.state.38.exp_avg"} loc(unknown), %arg322: tensor<768x768xf32> {tf.aliasing_output = 191 : i64, tf.resource_name = "state.optimizer.state.38.exp_avg_sq"} loc(unknown), %arg323: tensor<f32> {tf.aliasing_output = 192 : i64, tf.resource_name = "state.optimizer.state.38.beta1_power"} loc(unknown), %arg324: tensor<f32> {tf.aliasing_output = 193 : i64, tf.resource_name = "state.optimizer.state.38.beta2_power"} loc(unknown), %arg325: tensor<768x768xf32> {tf.aliasing_output = 195 : i64, tf.resource_name = "state.optimizer.state.39.exp_avg"} loc(unknown), %arg326: tensor<768x768xf32> {tf.aliasing_output = 196 : i64, tf.resource_name = "state.optimizer.state.39.exp_avg_sq"} loc(unknown), %arg327: tensor<f32> {tf.aliasing_output = 197 : i64, tf.resource_name = "state.optimizer.state.39.beta1_power"} loc(unknown), %arg328: tensor<f32> {tf.aliasing_output = 198 : i64, tf.resource_name = "state.optimizer.state.39.beta2_power"} loc(unknown), %arg329: tensor<768x768xf32> {tf.aliasing_output = 200 : i64, tf.resource_name = "state.optimizer.state.40.exp_avg"} loc(unknown), %arg330: tensor<768x768xf32> {tf.aliasing_output = 201 : i64, tf.resource_name = "state.optimizer.state.40.exp_avg_sq"} loc(unknown), %arg331: tensor<f32> {tf.aliasing_output = 202 : i64, tf.resource_name = "state.optimizer.state.40.beta1_power"} loc(unknown), %arg332: tensor<f32> {tf.aliasing_output = 203 : i64, tf.resource_name = "state.optimizer.state.40.beta2_power"} loc(unknown), %arg333: tensor<768x768xf32> {tf.aliasing_output = 205 : i64, tf.resource_name = "state.optimizer.state.41.exp_avg"} loc(unknown), %arg334: tensor<768x768xf32> {tf.aliasing_output = 206 : i64, tf.resource_name = "state.optimizer.state.41.exp_avg_sq"} loc(unknown), %arg335: tensor<f32> {tf.aliasing_output = 207 : i64, tf.resource_name = "state.optimizer.state.41.beta1_power"} loc(unknown), %arg336: tensor<f32> {tf.aliasing_output = 208 : i64, tf.resource_name = "state.optimizer.state.41.beta2_power"} loc(unknown), %arg337: tensor<3072x768xf32> {tf.aliasing_output = 210 : i64, tf.resource_name = "state.optimizer.state.42.exp_avg"} loc(unknown), %arg338: tensor<3072x768xf32> {tf.aliasing_output = 211 : i64, tf.resource_name = "state.optimizer.state.42.exp_avg_sq"} loc(unknown), %arg339: tensor<f32> {tf.aliasing_output = 212 : i64, tf.resource_name = "state.optimizer.state.42.beta1_power"} loc(unknown), %arg340: tensor<f32> {tf.aliasing_output = 213 : i64, tf.resource_name = "state.optimizer.state.42.beta2_power"} loc(unknown), %arg341: tensor<768x3072xf32> {tf.aliasing_output = 215 : i64, tf.resource_name = "state.optimizer.state.43.exp_avg"} loc(unknown), %arg342: tensor<768x3072xf32> {tf.aliasing_output = 216 : i64, tf.resource_name = "state.optimizer.state.43.exp_avg_sq"} loc(unknown), %arg343: tensor<f32> {tf.aliasing_output = 217 : i64, tf.resource_name = "state.optimizer.state.43.beta1_power"} loc(unknown), %arg344: tensor<f32> {tf.aliasing_output = 218 : i64, tf.resource_name = "state.optimizer.state.43.beta2_power"} loc(unknown), %arg345: tensor<768x768xf32> {tf.aliasing_output = 220 : i64, tf.resource_name = "state.optimizer.state.44.exp_avg"} loc(unknown), %arg346: tensor<768x768xf32> {tf.aliasing_output = 221 : i64, tf.resource_name = "state.optimizer.state.44.exp_avg_sq"} loc(unknown), %arg347: tensor<f32> {tf.aliasing_output = 222 : i64, tf.resource_name = "state.optimizer.state.44.beta1_power"} loc(unknown), %arg348: tensor<f32> {tf.aliasing_output = 223 : i64, tf.resource_name = "state.optimizer.state.44.beta2_power"} loc(unknown), %arg349: tensor<768x768xf32> {tf.aliasing_output = 225 : i64, tf.resource_name = "state.optimizer.state.45.exp_avg"} loc(unknown), %arg350: tensor<768x768xf32> {tf.aliasing_output = 226 : i64, tf.resource_name = "state.optimizer.state.45.exp_avg_sq"} loc(unknown), %arg351: tensor<f32> {tf.aliasing_output = 227 : i64, tf.resource_name = "state.optimizer.state.45.beta1_power"} loc(unknown), %arg352: tensor<f32> {tf.aliasing_output = 228 : i64, tf.resource_name = "state.optimizer.state.45.beta2_power"} loc(unknown), %arg353: tensor<768x768xf32> {tf.aliasing_output = 230 : i64, tf.resource_name = "state.optimizer.state.46.exp_avg"} loc(unknown), %arg354: tensor<768x768xf32> {tf.aliasing_output = 231 : i64, tf.resource_name = "state.optimizer.state.46.exp_avg_sq"} loc(unknown), %arg355: tensor<f32> {tf.aliasing_output = 232 : i64, tf.resource_name = "state.optimizer.state.46.beta1_power"} loc(unknown), %arg356: tensor<f32> {tf.aliasing_output = 233 : i64, tf.resource_name = "state.optimizer.state.46.beta2_power"} loc(unknown), %arg357: tensor<768x768xf32> {tf.aliasing_output = 235 : i64, tf.resource_name = "state.optimizer.state.47.exp_avg"} loc(unknown), %arg358: tensor<768x768xf32> {tf.aliasing_output = 236 : i64, tf.resource_name = "state.optimizer.state.47.exp_avg_sq"} loc(unknown), %arg359: tensor<f32> {tf.aliasing_output = 237 : i64, tf.resource_name = "state.optimizer.state.47.beta1_power"} loc(unknown), %arg360: tensor<f32> {tf.aliasing_output = 238 : i64, tf.resource_name = "state.optimizer.state.47.beta2_power"} loc(unknown), %arg361: tensor<3072x768xf32> {tf.aliasing_output = 240 : i64, tf.resource_name = "state.optimizer.state.48.exp_avg"} loc(unknown), %arg362: tensor<3072x768xf32> {tf.aliasing_output = 241 : i64, tf.resource_name = "state.optimizer.state.48.exp_avg_sq"} loc(unknown), %arg363: tensor<f32> {tf.aliasing_output = 242 : i64, tf.resource_name = "state.optimizer.state.48.beta1_power"} loc(unknown), %arg364: tensor<f32> {tf.aliasing_output = 243 : i64, tf.resource_name = "state.optimizer.state.48.beta2_power"} loc(unknown), %arg365: tensor<768x3072xf32> {tf.aliasing_output = 245 : i64, tf.resource_name = "state.optimizer.state.49.exp_avg"} loc(unknown), %arg366: tensor<768x3072xf32> {tf.aliasing_output = 246 : i64, tf.resource_name = "state.optimizer.state.49.exp_avg_sq"} loc(unknown), %arg367: tensor<f32> {tf.aliasing_output = 247 : i64, tf.resource_name = "state.optimizer.state.49.beta1_power"} loc(unknown), %arg368: tensor<f32> {tf.aliasing_output = 248 : i64, tf.resource_name = "state.optimizer.state.49.beta2_power"} loc(unknown), %arg369: tensor<768x768xf32> {tf.aliasing_output = 250 : i64, tf.resource_name = "state.optimizer.state.50.exp_avg"} loc(unknown), %arg370: tensor<768x768xf32> {tf.aliasing_output = 251 : i64, tf.resource_name = "state.optimizer.state.50.exp_avg_sq"} loc(unknown), %arg371: tensor<f32> {tf.aliasing_output = 252 : i64, tf.resource_name = "state.optimizer.state.50.beta1_power"} loc(unknown), %arg372: tensor<f32> {tf.aliasing_output = 253 : i64, tf.resource_name = "state.optimizer.state.50.beta2_power"} loc(unknown), %arg373: tensor<768x768xf32> {tf.aliasing_output = 255 : i64, tf.resource_name = "state.optimizer.state.51.exp_avg"} loc(unknown), %arg374: tensor<768x768xf32> {tf.aliasing_output = 256 : i64, tf.resource_name = "state.optimizer.state.51.exp_avg_sq"} loc(unknown), %arg375: tensor<f32> {tf.aliasing_output = 257 : i64, tf.resource_name = "state.optimizer.state.51.beta1_power"} loc(unknown), %arg376: tensor<f32> {tf.aliasing_output = 258 : i64, tf.resource_name = "state.optimizer.state.51.beta2_power"} loc(unknown), %arg377: tensor<768x768xf32> {tf.aliasing_output = 260 : i64, tf.resource_name = "state.optimizer.state.52.exp_avg"} loc(unknown), %arg378: tensor<768x768xf32> {tf.aliasing_output = 261 : i64, tf.resource_name = "state.optimizer.state.52.exp_avg_sq"} loc(unknown), %arg379: tensor<f32> {tf.aliasing_output = 262 : i64, tf.resource_name = "state.optimizer.state.52.beta1_power"} loc(unknown), %arg380: tensor<f32> {tf.aliasing_output = 263 : i64, tf.resource_name = "state.optimizer.state.52.beta2_power"} loc(unknown), %arg381: tensor<768x768xf32> {tf.aliasing_output = 265 : i64, tf.resource_name = "state.optimizer.state.53.exp_avg"} loc(unknown), %arg382: tensor<768x768xf32> {tf.aliasing_output = 266 : i64, tf.resource_name = "state.optimizer.state.53.exp_avg_sq"} loc(unknown), %arg383: tensor<f32> {tf.aliasing_output = 267 : i64, tf.resource_name = "state.optimizer.state.53.beta1_power"} loc(unknown), %arg384: tensor<f32> {tf.aliasing_output = 268 : i64, tf.resource_name = "state.optimizer.state.53.beta2_power"} loc(unknown), %arg385: tensor<3072x768xf32> {tf.aliasing_output = 270 : i64, tf.resource_name = "state.optimizer.state.54.exp_avg"} loc(unknown), %arg386: tensor<3072x768xf32> {tf.aliasing_output = 271 : i64, tf.resource_name = "state.optimizer.state.54.exp_avg_sq"} loc(unknown), %arg387: tensor<f32> {tf.aliasing_output = 272 : i64, tf.resource_name = "state.optimizer.state.54.beta1_power"} loc(unknown), %arg388: tensor<f32> {tf.aliasing_output = 273 : i64, tf.resource_name = "state.optimizer.state.54.beta2_power"} loc(unknown), %arg389: tensor<768x3072xf32> {tf.aliasing_output = 275 : i64, tf.resource_name = "state.optimizer.state.55.exp_avg"} loc(unknown), %arg390: tensor<768x3072xf32> {tf.aliasing_output = 276 : i64, tf.resource_name = "state.optimizer.state.55.exp_avg_sq"} loc(unknown), %arg391: tensor<f32> {tf.aliasing_output = 277 : i64, tf.resource_name = "state.optimizer.state.55.beta1_power"} loc(unknown), %arg392: tensor<f32> {tf.aliasing_output = 278 : i64, tf.resource_name = "state.optimizer.state.55.beta2_power"} loc(unknown), %arg393: tensor<768x768xf32> {tf.aliasing_output = 280 : i64, tf.resource_name = "state.optimizer.state.56.exp_avg"} loc(unknown), %arg394: tensor<768x768xf32> {tf.aliasing_output = 281 : i64, tf.resource_name = "state.optimizer.state.56.exp_avg_sq"} loc(unknown), %arg395: tensor<f32> {tf.aliasing_output = 282 : i64, tf.resource_name = "state.optimizer.state.56.beta1_power"} loc(unknown), %arg396: tensor<f32> {tf.aliasing_output = 283 : i64, tf.resource_name = "state.optimizer.state.56.beta2_power"} loc(unknown), %arg397: tensor<768x768xf32> {tf.aliasing_output = 285 : i64, tf.resource_name = "state.optimizer.state.57.exp_avg"} loc(unknown), %arg398: tensor<768x768xf32> {tf.aliasing_output = 286 : i64, tf.resource_name = "state.optimizer.state.57.exp_avg_sq"} loc(unknown), %arg399: tensor<f32> {tf.aliasing_output = 287 : i64, tf.resource_name = "state.optimizer.state.57.beta1_power"} loc(unknown), %arg400: tensor<f32> {tf.aliasing_output = 288 : i64, tf.resource_name = "state.optimizer.state.57.beta2_power"} loc(unknown), %arg401: tensor<768x768xf32> {tf.aliasing_output = 290 : i64, tf.resource_name = "state.optimizer.state.58.exp_avg"} loc(unknown), %arg402: tensor<768x768xf32> {tf.aliasing_output = 291 : i64, tf.resource_name = "state.optimizer.state.58.exp_avg_sq"} loc(unknown), %arg403: tensor<f32> {tf.aliasing_output = 292 : i64, tf.resource_name = "state.optimizer.state.58.beta1_power"} loc(unknown), %arg404: tensor<f32> {tf.aliasing_output = 293 : i64, tf.resource_name = "state.optimizer.state.58.beta2_power"} loc(unknown), %arg405: tensor<768x768xf32> {tf.aliasing_output = 295 : i64, tf.resource_name = "state.optimizer.state.59.exp_avg"} loc(unknown), %arg406: tensor<768x768xf32> {tf.aliasing_output = 296 : i64, tf.resource_name = "state.optimizer.state.59.exp_avg_sq"} loc(unknown), %arg407: tensor<f32> {tf.aliasing_output = 297 : i64, tf.resource_name = "state.optimizer.state.59.beta1_power"} loc(unknown), %arg408: tensor<f32> {tf.aliasing_output = 298 : i64, tf.resource_name = "state.optimizer.state.59.beta2_power"} loc(unknown), %arg409: tensor<3072x768xf32> {tf.aliasing_output = 300 : i64, tf.resource_name = "state.optimizer.state.60.exp_avg"} loc(unknown), %arg410: tensor<3072x768xf32> {tf.aliasing_output = 301 : i64, tf.resource_name = "state.optimizer.state.60.exp_avg_sq"} loc(unknown), %arg411: tensor<f32> {tf.aliasing_output = 302 : i64, tf.resource_name = "state.optimizer.state.60.beta1_power"} loc(unknown), %arg412: tensor<f32> {tf.aliasing_output = 303 : i64, tf.resource_name = "state.optimizer.state.60.beta2_power"} loc(unknown), %arg413: tensor<768x3072xf32> {tf.aliasing_output = 305 : i64, tf.resource_name = "state.optimizer.state.61.exp_avg"} loc(unknown), %arg414: tensor<768x3072xf32> {tf.aliasing_output = 306 : i64, tf.resource_name = "state.optimizer.state.61.exp_avg_sq"} loc(unknown), %arg415: tensor<f32> {tf.aliasing_output = 307 : i64, tf.resource_name = "state.optimizer.state.61.beta1_power"} loc(unknown), %arg416: tensor<f32> {tf.aliasing_output = 308 : i64, tf.resource_name = "state.optimizer.state.61.beta2_power"} loc(unknown), %arg417: tensor<768xf32> {tf.aliasing_output = 310 : i64, tf.resource_name = "state.optimizer.state.62.exp_avg"} loc(unknown), %arg418: tensor<768xf32> {tf.aliasing_output = 311 : i64, tf.resource_name = "state.optimizer.state.62.exp_avg_sq"} loc(unknown), %arg419: tensor<f32> {tf.aliasing_output = 312 : i64, tf.resource_name = "state.optimizer.state.62.beta1_power"} loc(unknown), %arg420: tensor<f32> {tf.aliasing_output = 313 : i64, tf.resource_name = "state.optimizer.state.62.beta2_power"} loc(unknown), %arg421: tensor<768xf32> {tf.aliasing_output = 315 : i64, tf.resource_name = "state.optimizer.state.63.exp_avg"} loc(unknown), %arg422: tensor<768xf32> {tf.aliasing_output = 316 : i64, tf.resource_name = "state.optimizer.state.63.exp_avg_sq"} loc(unknown), %arg423: tensor<f32> {tf.aliasing_output = 317 : i64, tf.resource_name = "state.optimizer.state.63.beta1_power"} loc(unknown), %arg424: tensor<f32> {tf.aliasing_output = 318 : i64, tf.resource_name = "state.optimizer.state.63.beta2_power"} loc(unknown), %arg425: tensor<768xf32> {tf.aliasing_output = 320 : i64, tf.resource_name = "state.optimizer.state.64.exp_avg"} loc(unknown), %arg426: tensor<768xf32> {tf.aliasing_output = 321 : i64, tf.resource_name = "state.optimizer.state.64.exp_avg_sq"} loc(unknown), %arg427: tensor<f32> {tf.aliasing_output = 322 : i64, tf.resource_name = "state.optimizer.state.64.beta1_power"} loc(unknown), %arg428: tensor<f32> {tf.aliasing_output = 323 : i64, tf.resource_name = "state.optimizer.state.64.beta2_power"} loc(unknown), %arg429: tensor<768xf32> {tf.aliasing_output = 325 : i64, tf.resource_name = "state.optimizer.state.65.exp_avg"} loc(unknown), %arg430: tensor<768xf32> {tf.aliasing_output = 326 : i64, tf.resource_name = "state.optimizer.state.65.exp_avg_sq"} loc(unknown), %arg431: tensor<f32> {tf.aliasing_output = 327 : i64, tf.resource_name = "state.optimizer.state.65.beta1_power"} loc(unknown), %arg432: tensor<f32> {tf.aliasing_output = 328 : i64, tf.resource_name = "state.optimizer.state.65.beta2_power"} loc(unknown), %arg433: tensor<768xf32> {tf.aliasing_output = 330 : i64, tf.resource_name = "state.optimizer.state.66.exp_avg"} loc(unknown), %arg434: tensor<768xf32> {tf.aliasing_output = 331 : i64, tf.resource_name = "state.optimizer.state.66.exp_avg_sq"} loc(unknown), %arg435: tensor<f32> {tf.aliasing_output = 332 : i64, tf.resource_name = "state.optimizer.state.66.beta1_power"} loc(unknown), %arg436: tensor<f32> {tf.aliasing_output = 333 : i64, tf.resource_name = "state.optimizer.state.66.beta2_power"} loc(unknown), %arg437: tensor<768xf32> {tf.aliasing_output = 335 : i64, tf.resource_name = "state.optimizer.state.67.exp_avg"} loc(unknown), %arg438: tensor<768xf32> {tf.aliasing_output = 336 : i64, tf.resource_name = "state.optimizer.state.67.exp_avg_sq"} loc(unknown), %arg439: tensor<f32> {tf.aliasing_output = 337 : i64, tf.resource_name = "state.optimizer.state.67.beta1_power"} loc(unknown), %arg440: tensor<f32> {tf.aliasing_output = 338 : i64, tf.resource_name = "state.optimizer.state.67.beta2_power"} loc(unknown), %arg441: tensor<768xf32> {tf.aliasing_output = 340 : i64, tf.resource_name = "state.optimizer.state.68.exp_avg"} loc(unknown), %arg442: tensor<768xf32> {tf.aliasing_output = 341 : i64, tf.resource_name = "state.optimizer.state.68.exp_avg_sq"} loc(unknown), %arg443: tensor<f32> {tf.aliasing_output = 342 : i64, tf.resource_name = "state.optimizer.state.68.beta1_power"} loc(unknown), %arg444: tensor<f32> {tf.aliasing_output = 343 : i64, tf.resource_name = "state.optimizer.state.68.beta2_power"} loc(unknown), %arg445: tensor<768xf32> {tf.aliasing_output = 345 : i64, tf.resource_name = "state.optimizer.state.69.exp_avg"} loc(unknown), %arg446: tensor<768xf32> {tf.aliasing_output = 346 : i64, tf.resource_name = "state.optimizer.state.69.exp_avg_sq"} loc(unknown), %arg447: tensor<f32> {tf.aliasing_output = 347 : i64, tf.resource_name = "state.optimizer.state.69.beta1_power"} loc(unknown), %arg448: tensor<f32> {tf.aliasing_output = 348 : i64, tf.resource_name = "state.optimizer.state.69.beta2_power"} loc(unknown), %arg449: tensor<3072xf32> {tf.aliasing_output = 350 : i64, tf.resource_name = "state.optimizer.state.70.exp_avg"} loc(unknown), %arg450: tensor<3072xf32> {tf.aliasing_output = 351 : i64, tf.resource_name = "state.optimizer.state.70.exp_avg_sq"} loc(unknown), %arg451: tensor<f32> {tf.aliasing_output = 352 : i64, tf.resource_name = "state.optimizer.state.70.beta1_power"} loc(unknown), %arg452: tensor<f32> {tf.aliasing_output = 353 : i64, tf.resource_name = "state.optimizer.state.70.beta2_power"} loc(unknown), %arg453: tensor<768xf32> {tf.aliasing_output = 355 : i64, tf.resource_name = "state.optimizer.state.71.exp_avg"} loc(unknown), %arg454: tensor<768xf32> {tf.aliasing_output = 356 : i64, tf.resource_name = "state.optimizer.state.71.exp_avg_sq"} loc(unknown), %arg455: tensor<f32> {tf.aliasing_output = 357 : i64, tf.resource_name = "state.optimizer.state.71.beta1_power"} loc(unknown), %arg456: tensor<f32> {tf.aliasing_output = 358 : i64, tf.resource_name = "state.optimizer.state.71.beta2_power"} loc(unknown), %arg457: tensor<768xf32> {tf.aliasing_output = 360 : i64, tf.resource_name = "state.optimizer.state.72.exp_avg"} loc(unknown), %arg458: tensor<768xf32> {tf.aliasing_output = 361 : i64, tf.resource_name = "state.optimizer.state.72.exp_avg_sq"} loc(unknown), %arg459: tensor<f32> {tf.aliasing_output = 362 : i64, tf.resource_name = "state.optimizer.state.72.beta1_power"} loc(unknown), %arg460: tensor<f32> {tf.aliasing_output = 363 : i64, tf.resource_name = "state.optimizer.state.72.beta2_power"} loc(unknown), %arg461: tensor<768xf32> {tf.aliasing_output = 365 : i64, tf.resource_name = "state.optimizer.state.73.exp_avg"} loc(unknown), %arg462: tensor<768xf32> {tf.aliasing_output = 366 : i64, tf.resource_name = "state.optimizer.state.73.exp_avg_sq"} loc(unknown), %arg463: tensor<f32> {tf.aliasing_output = 367 : i64, tf.resource_name = "state.optimizer.state.73.beta1_power"} loc(unknown), %arg464: tensor<f32> {tf.aliasing_output = 368 : i64, tf.resource_name = "state.optimizer.state.73.beta2_power"} loc(unknown), %arg465: tensor<768xf32> {tf.aliasing_output = 370 : i64, tf.resource_name = "state.optimizer.state.74.exp_avg"} loc(unknown), %arg466: tensor<768xf32> {tf.aliasing_output = 371 : i64, tf.resource_name = "state.optimizer.state.74.exp_avg_sq"} loc(unknown), %arg467: tensor<f32> {tf.aliasing_output = 372 : i64, tf.resource_name = "state.optimizer.state.74.beta1_power"} loc(unknown), %arg468: tensor<f32> {tf.aliasing_output = 373 : i64, tf.resource_name = "state.optimizer.state.74.beta2_power"} loc(unknown), %arg469: tensor<768xf32> {tf.aliasing_output = 375 : i64, tf.resource_name = "state.optimizer.state.75.exp_avg"} loc(unknown), %arg470: tensor<768xf32> {tf.aliasing_output = 376 : i64, tf.resource_name = "state.optimizer.state.75.exp_avg_sq"} loc(unknown), %arg471: tensor<f32> {tf.aliasing_output = 377 : i64, tf.resource_name = "state.optimizer.state.75.beta1_power"} loc(unknown), %arg472: tensor<f32> {tf.aliasing_output = 378 : i64, tf.resource_name = "state.optimizer.state.75.beta2_power"} loc(unknown), %arg473: tensor<768xf32> {tf.aliasing_output = 380 : i64, tf.resource_name = "state.optimizer.state.76.exp_avg"} loc(unknown), %arg474: tensor<768xf32> {tf.aliasing_output = 381 : i64, tf.resource_name = "state.optimizer.state.76.exp_avg_sq"} loc(unknown), %arg475: tensor<f32> {tf.aliasing_output = 382 : i64, tf.resource_name = "state.optimizer.state.76.beta1_power"} loc(unknown), %arg476: tensor<f32> {tf.aliasing_output = 383 : i64, tf.resource_name = "state.optimizer.state.76.beta2_power"} loc(unknown), %arg477: tensor<768xf32> {tf.aliasing_output = 385 : i64, tf.resource_name = "state.optimizer.state.77.exp_avg"} loc(unknown), %arg478: tensor<768xf32> {tf.aliasing_output = 386 : i64, tf.resource_name = "state.optimizer.state.77.exp_avg_sq"} loc(unknown), %arg479: tensor<f32> {tf.aliasing_output = 387 : i64, tf.resource_name = "state.optimizer.state.77.beta1_power"} loc(unknown), %arg480: tensor<f32> {tf.aliasing_output = 388 : i64, tf.resource_name = "state.optimizer.state.77.beta2_power"} loc(unknown), %arg481: tensor<768xf32> {tf.aliasing_output = 390 : i64, tf.resource_name = "state.optimizer.state.78.exp_avg"} loc(unknown), %arg482: tensor<768xf32> {tf.aliasing_output = 391 : i64, tf.resource_name = "state.optimizer.state.78.exp_avg_sq"} loc(unknown), %arg483: tensor<f32> {tf.aliasing_output = 392 : i64, tf.resource_name = "state.optimizer.state.78.beta1_power"} loc(unknown), %arg484: tensor<f32> {tf.aliasing_output = 393 : i64, tf.resource_name = "state.optimizer.state.78.beta2_power"} loc(unknown), %arg485: tensor<768xf32> {tf.aliasing_output = 395 : i64, tf.resource_name = "state.optimizer.state.79.exp_avg"} loc(unknown), %arg486: tensor<768xf32> {tf.aliasing_output = 396 : i64, tf.resource_name = "state.optimizer.state.79.exp_avg_sq"} loc(unknown), %arg487: tensor<f32> {tf.aliasing_output = 397 : i64, tf.resource_name = "state.optimizer.state.79.beta1_power"} loc(unknown), %arg488: tensor<f32> {tf.aliasing_output = 398 : i64, tf.resource_name = "state.optimizer.state.79.beta2_power"} loc(unknown), %arg489: tensor<3072xf32> {tf.aliasing_output = 400 : i64, tf.resource_name = "state.optimizer.state.80.exp_avg"} loc(unknown), %arg490: tensor<3072xf32> {tf.aliasing_output = 401 : i64, tf.resource_name = "state.optimizer.state.80.exp_avg_sq"} loc(unknown), %arg491: tensor<f32> {tf.aliasing_output = 402 : i64, tf.resource_name = "state.optimizer.state.80.beta1_power"} loc(unknown), %arg492: tensor<f32> {tf.aliasing_output = 403 : i64, tf.resource_name = "state.optimizer.state.80.beta2_power"} loc(unknown), %arg493: tensor<768xf32> {tf.aliasing_output = 405 : i64, tf.resource_name = "state.optimizer.state.81.exp_avg"} loc(unknown), %arg494: tensor<768xf32> {tf.aliasing_output = 406 : i64, tf.resource_name = "state.optimizer.state.81.exp_avg_sq"} loc(unknown), %arg495: tensor<f32> {tf.aliasing_output = 407 : i64, tf.resource_name = "state.optimizer.state.81.beta1_power"} loc(unknown), %arg496: tensor<f32> {tf.aliasing_output = 408 : i64, tf.resource_name = "state.optimizer.state.81.beta2_power"} loc(unknown), %arg497: tensor<768xf32> {tf.aliasing_output = 410 : i64, tf.resource_name = "state.optimizer.state.82.exp_avg"} loc(unknown), %arg498: tensor<768xf32> {tf.aliasing_output = 411 : i64, tf.resource_name = "state.optimizer.state.82.exp_avg_sq"} loc(unknown), %arg499: tensor<f32> {tf.aliasing_output = 412 : i64, tf.resource_name = "state.optimizer.state.82.beta1_power"} loc(unknown), %arg500: tensor<f32> {tf.aliasing_output = 413 : i64, tf.resource_name = "state.optimizer.state.82.beta2_power"} loc(unknown), %arg501: tensor<768xf32> {tf.aliasing_output = 415 : i64, tf.resource_name = "state.optimizer.state.83.exp_avg"} loc(unknown), %arg502: tensor<768xf32> {tf.aliasing_output = 416 : i64, tf.resource_name = "state.optimizer.state.83.exp_avg_sq"} loc(unknown), %arg503: tensor<f32> {tf.aliasing_output = 417 : i64, tf.resource_name = "state.optimizer.state.83.beta1_power"} loc(unknown), %arg504: tensor<f32> {tf.aliasing_output = 418 : i64, tf.resource_name = "state.optimizer.state.83.beta2_power"} loc(unknown), %arg505: tensor<768xf32> {tf.aliasing_output = 420 : i64, tf.resource_name = "state.optimizer.state.84.exp_avg"} loc(unknown), %arg506: tensor<768xf32> {tf.aliasing_output = 421 : i64, tf.resource_name = "state.optimizer.state.84.exp_avg_sq"} loc(unknown), %arg507: tensor<f32> {tf.aliasing_output = 422 : i64, tf.resource_name = "state.optimizer.state.84.beta1_power"} loc(unknown), %arg508: tensor<f32> {tf.aliasing_output = 423 : i64, tf.resource_name = "state.optimizer.state.84.beta2_power"} loc(unknown), %arg509: tensor<768xf32> {tf.aliasing_output = 425 : i64, tf.resource_name = "state.optimizer.state.85.exp_avg"} loc(unknown), %arg510: tensor<768xf32> {tf.aliasing_output = 426 : i64, tf.resource_name = "state.optimizer.state.85.exp_avg_sq"} loc(unknown), %arg511: tensor<f32> {tf.aliasing_output = 427 : i64, tf.resource_name = "state.optimizer.state.85.beta1_power"} loc(unknown), %arg512: tensor<f32> {tf.aliasing_output = 428 : i64, tf.resource_name = "state.optimizer.state.85.beta2_power"} loc(unknown), %arg513: tensor<768xf32> {tf.aliasing_output = 430 : i64, tf.resource_name = "state.optimizer.state.86.exp_avg"} loc(unknown), %arg514: tensor<768xf32> {tf.aliasing_output = 431 : i64, tf.resource_name = "state.optimizer.state.86.exp_avg_sq"} loc(unknown), %arg515: tensor<f32> {tf.aliasing_output = 432 : i64, tf.resource_name = "state.optimizer.state.86.beta1_power"} loc(unknown), %arg516: tensor<f32> {tf.aliasing_output = 433 : i64, tf.resource_name = "state.optimizer.state.86.beta2_power"} loc(unknown), %arg517: tensor<768xf32> {tf.aliasing_output = 435 : i64, tf.resource_name = "state.optimizer.state.87.exp_avg"} loc(unknown), %arg518: tensor<768xf32> {tf.aliasing_output = 436 : i64, tf.resource_name = "state.optimizer.state.87.exp_avg_sq"} loc(unknown), %arg519: tensor<f32> {tf.aliasing_output = 437 : i64, tf.resource_name = "state.optimizer.state.87.beta1_power"} loc(unknown), %arg520: tensor<f32> {tf.aliasing_output = 438 : i64, tf.resource_name = "state.optimizer.state.87.beta2_power"} loc(unknown), %arg521: tensor<768xf32> {tf.aliasing_output = 440 : i64, tf.resource_name = "state.optimizer.state.88.exp_avg"} loc(unknown), %arg522: tensor<768xf32> {tf.aliasing_output = 441 : i64, tf.resource_name = "state.optimizer.state.88.exp_avg_sq"} loc(unknown), %arg523: tensor<f32> {tf.aliasing_output = 442 : i64, tf.resource_name = "state.optimizer.state.88.beta1_power"} loc(unknown), %arg524: tensor<f32> {tf.aliasing_output = 443 : i64, tf.resource_name = "state.optimizer.state.88.beta2_power"} loc(unknown), %arg525: tensor<768xf32> {tf.aliasing_output = 445 : i64, tf.resource_name = "state.optimizer.state.89.exp_avg"} loc(unknown), %arg526: tensor<768xf32> {tf.aliasing_output = 446 : i64, tf.resource_name = "state.optimizer.state.89.exp_avg_sq"} loc(unknown), %arg527: tensor<f32> {tf.aliasing_output = 447 : i64, tf.resource_name = "state.optimizer.state.89.beta1_power"} loc(unknown), %arg528: tensor<f32> {tf.aliasing_output = 448 : i64, tf.resource_name = "state.optimizer.state.89.beta2_power"} loc(unknown), %arg529: tensor<3072xf32> {tf.aliasing_output = 450 : i64, tf.resource_name = "state.optimizer.state.90.exp_avg"} loc(unknown), %arg530: tensor<3072xf32> {tf.aliasing_output = 451 : i64, tf.resource_name = "state.optimizer.state.90.exp_avg_sq"} loc(unknown), %arg531: tensor<f32> {tf.aliasing_output = 452 : i64, tf.resource_name = "state.optimizer.state.90.beta1_power"} loc(unknown), %arg532: tensor<f32> {tf.aliasing_output = 453 : i64, tf.resource_name = "state.optimizer.state.90.beta2_power"} loc(unknown), %arg533: tensor<768xf32> {tf.aliasing_output = 455 : i64, tf.resource_name = "state.optimizer.state.91.exp_avg"} loc(unknown), %arg534: tensor<768xf32> {tf.aliasing_output = 456 : i64, tf.resource_name = "state.optimizer.state.91.exp_avg_sq"} loc(unknown), %arg535: tensor<f32> {tf.aliasing_output = 457 : i64, tf.resource_name = "state.optimizer.state.91.beta1_power"} loc(unknown), %arg536: tensor<f32> {tf.aliasing_output = 458 : i64, tf.resource_name = "state.optimizer.state.91.beta2_power"} loc(unknown), %arg537: tensor<768xf32> {tf.aliasing_output = 460 : i64, tf.resource_name = "state.optimizer.state.92.exp_avg"} loc(unknown), %arg538: tensor<768xf32> {tf.aliasing_output = 461 : i64, tf.resource_name = "state.optimizer.state.92.exp_avg_sq"} loc(unknown), %arg539: tensor<f32> {tf.aliasing_output = 462 : i64, tf.resource_name = "state.optimizer.state.92.beta1_power"} loc(unknown), %arg540: tensor<f32> {tf.aliasing_output = 463 : i64, tf.resource_name = "state.optimizer.state.92.beta2_power"} loc(unknown), %arg541: tensor<768xf32> {tf.aliasing_output = 465 : i64, tf.resource_name = "state.optimizer.state.93.exp_avg"} loc(unknown), %arg542: tensor<768xf32> {tf.aliasing_output = 466 : i64, tf.resource_name = "state.optimizer.state.93.exp_avg_sq"} loc(unknown), %arg543: tensor<f32> {tf.aliasing_output = 467 : i64, tf.resource_name = "state.optimizer.state.93.beta1_power"} loc(unknown), %arg544: tensor<f32> {tf.aliasing_output = 468 : i64, tf.resource_name = "state.optimizer.state.93.beta2_power"} loc(unknown), %arg545: tensor<768xf32> {tf.aliasing_output = 470 : i64, tf.resource_name = "state.optimizer.state.94.exp_avg"} loc(unknown), %arg546: tensor<768xf32> {tf.aliasing_output = 471 : i64, tf.resource_name = "state.optimizer.state.94.exp_avg_sq"} loc(unknown), %arg547: tensor<f32> {tf.aliasing_output = 472 : i64, tf.resource_name = "state.optimizer.state.94.beta1_power"} loc(unknown), %arg548: tensor<f32> {tf.aliasing_output = 473 : i64, tf.resource_name = "state.optimizer.state.94.beta2_power"} loc(unknown), %arg549: tensor<768xf32> {tf.aliasing_output = 475 : i64, tf.resource_name = "state.optimizer.state.95.exp_avg"} loc(unknown), %arg550: tensor<768xf32> {tf.aliasing_output = 476 : i64, tf.resource_name = "state.optimizer.state.95.exp_avg_sq"} loc(unknown), %arg551: tensor<f32> {tf.aliasing_output = 477 : i64, tf.resource_name = "state.optimizer.state.95.beta1_power"} loc(unknown), %arg552: tensor<f32> {tf.aliasing_output = 478 : i64, tf.resource_name = "state.optimizer.state.95.beta2_power"} loc(unknown), %arg553: tensor<768xf32> {tf.aliasing_output = 480 : i64, tf.resource_name = "state.optimizer.state.96.exp_avg"} loc(unknown), %arg554: tensor<768xf32> {tf.aliasing_output = 481 : i64, tf.resource_name = "state.optimizer.state.96.exp_avg_sq"} loc(unknown), %arg555: tensor<f32> {tf.aliasing_output = 482 : i64, tf.resource_name = "state.optimizer.state.96.beta1_power"} loc(unknown), %arg556: tensor<f32> {tf.aliasing_output = 483 : i64, tf.resource_name = "state.optimizer.state.96.beta2_power"} loc(unknown), %arg557: tensor<768xf32> {tf.aliasing_output = 485 : i64, tf.resource_name = "state.optimizer.state.97.exp_avg"} loc(unknown), %arg558: tensor<768xf32> {tf.aliasing_output = 486 : i64, tf.resource_name = "state.optimizer.state.97.exp_avg_sq"} loc(unknown), %arg559: tensor<f32> {tf.aliasing_output = 487 : i64, tf.resource_name = "state.optimizer.state.97.beta1_power"} loc(unknown), %arg560: tensor<f32> {tf.aliasing_output = 488 : i64, tf.resource_name = "state.optimizer.state.97.beta2_power"} loc(unknown), %arg561: tensor<768xf32> {tf.aliasing_output = 490 : i64, tf.resource_name = "state.optimizer.state.98.exp_avg"} loc(unknown), %arg562: tensor<768xf32> {tf.aliasing_output = 491 : i64, tf.resource_name = "state.optimizer.state.98.exp_avg_sq"} loc(unknown), %arg563: tensor<f32> {tf.aliasing_output = 492 : i64, tf.resource_name = "state.optimizer.state.98.beta1_power"} loc(unknown), %arg564: tensor<f32> {tf.aliasing_output = 493 : i64, tf.resource_name = "state.optimizer.state.98.beta2_power"} loc(unknown), %arg565: tensor<768xf32> {tf.aliasing_output = 495 : i64, tf.resource_name = "state.optimizer.state.99.exp_avg"} loc(unknown), %arg566: tensor<768xf32> {tf.aliasing_output = 496 : i64, tf.resource_name = "state.optimizer.state.99.exp_avg_sq"} loc(unknown), %arg567: tensor<f32> {tf.aliasing_output = 497 : i64, tf.resource_name = "state.optimizer.state.99.beta1_power"} loc(unknown), %arg568: tensor<f32> {tf.aliasing_output = 498 : i64, tf.resource_name = "state.optimizer.state.99.beta2_power"} loc(unknown), %arg569: tensor<3072xf32> {tf.aliasing_output = 500 : i64, tf.resource_name = "state.optimizer.state.100.exp_avg"} loc(unknown), %arg570: tensor<3072xf32> {tf.aliasing_output = 501 : i64, tf.resource_name = "state.optimizer.state.100.exp_avg_sq"} loc(unknown), %arg571: tensor<f32> {tf.aliasing_output = 502 : i64, tf.resource_name = "state.optimizer.state.100.beta1_power"} loc(unknown), %arg572: tensor<f32> {tf.aliasing_output = 503 : i64, tf.resource_name = "state.optimizer.state.100.beta2_power"} loc(unknown), %arg573: tensor<768xf32> {tf.aliasing_output = 505 : i64, tf.resource_name = "state.optimizer.state.101.exp_avg"} loc(unknown), %arg574: tensor<768xf32> {tf.aliasing_output = 506 : i64, tf.resource_name = "state.optimizer.state.101.exp_avg_sq"} loc(unknown), %arg575: tensor<f32> {tf.aliasing_output = 507 : i64, tf.resource_name = "state.optimizer.state.101.beta1_power"} loc(unknown), %arg576: tensor<f32> {tf.aliasing_output = 508 : i64, tf.resource_name = "state.optimizer.state.101.beta2_power"} loc(unknown), %arg577: tensor<768xf32> {tf.aliasing_output = 510 : i64, tf.resource_name = "state.optimizer.state.102.exp_avg"} loc(unknown), %arg578: tensor<768xf32> {tf.aliasing_output = 511 : i64, tf.resource_name = "state.optimizer.state.102.exp_avg_sq"} loc(unknown), %arg579: tensor<f32> {tf.aliasing_output = 512 : i64, tf.resource_name = "state.optimizer.state.102.beta1_power"} loc(unknown), %arg580: tensor<f32> {tf.aliasing_output = 513 : i64, tf.resource_name = "state.optimizer.state.102.beta2_power"} loc(unknown), %arg581: tensor<768xf32> {tf.aliasing_output = 515 : i64, tf.resource_name = "state.optimizer.state.103.exp_avg"} loc(unknown), %arg582: tensor<768xf32> {tf.aliasing_output = 516 : i64, tf.resource_name = "state.optimizer.state.103.exp_avg_sq"} loc(unknown), %arg583: tensor<f32> {tf.aliasing_output = 517 : i64, tf.resource_name = "state.optimizer.state.103.beta1_power"} loc(unknown), %arg584: tensor<f32> {tf.aliasing_output = 518 : i64, tf.resource_name = "state.optimizer.state.103.beta2_power"} loc(unknown), %arg585: tensor<768xf32> {tf.aliasing_output = 520 : i64, tf.resource_name = "state.optimizer.state.104.exp_avg"} loc(unknown), %arg586: tensor<768xf32> {tf.aliasing_output = 521 : i64, tf.resource_name = "state.optimizer.state.104.exp_avg_sq"} loc(unknown), %arg587: tensor<f32> {tf.aliasing_output = 522 : i64, tf.resource_name = "state.optimizer.state.104.beta1_power"} loc(unknown), %arg588: tensor<f32> {tf.aliasing_output = 523 : i64, tf.resource_name = "state.optimizer.state.104.beta2_power"} loc(unknown), %arg589: tensor<768xf32> {tf.aliasing_output = 525 : i64, tf.resource_name = "state.optimizer.state.105.exp_avg"} loc(unknown), %arg590: tensor<768xf32> {tf.aliasing_output = 526 : i64, tf.resource_name = "state.optimizer.state.105.exp_avg_sq"} loc(unknown), %arg591: tensor<f32> {tf.aliasing_output = 527 : i64, tf.resource_name = "state.optimizer.state.105.beta1_power"} loc(unknown), %arg592: tensor<f32> {tf.aliasing_output = 528 : i64, tf.resource_name = "state.optimizer.state.105.beta2_power"} loc(unknown), %arg593: tensor<768xf32> {tf.aliasing_output = 530 : i64, tf.resource_name = "state.optimizer.state.106.exp_avg"} loc(unknown), %arg594: tensor<768xf32> {tf.aliasing_output = 531 : i64, tf.resource_name = "state.optimizer.state.106.exp_avg_sq"} loc(unknown), %arg595: tensor<f32> {tf.aliasing_output = 532 : i64, tf.resource_name = "state.optimizer.state.106.beta1_power"} loc(unknown), %arg596: tensor<f32> {tf.aliasing_output = 533 : i64, tf.resource_name = "state.optimizer.state.106.beta2_power"} loc(unknown), %arg597: tensor<768xf32> {tf.aliasing_output = 535 : i64, tf.resource_name = "state.optimizer.state.107.exp_avg"} loc(unknown), %arg598: tensor<768xf32> {tf.aliasing_output = 536 : i64, tf.resource_name = "state.optimizer.state.107.exp_avg_sq"} loc(unknown), %arg599: tensor<f32> {tf.aliasing_output = 537 : i64, tf.resource_name = "state.optimizer.state.107.beta1_power"} loc(unknown), %arg600: tensor<f32> {tf.aliasing_output = 538 : i64, tf.resource_name = "state.optimizer.state.107.beta2_power"} loc(unknown), %arg601: tensor<768xf32> {tf.aliasing_output = 540 : i64, tf.resource_name = "state.optimizer.state.108.exp_avg"} loc(unknown), %arg602: tensor<768xf32> {tf.aliasing_output = 541 : i64, tf.resource_name = "state.optimizer.state.108.exp_avg_sq"} loc(unknown), %arg603: tensor<f32> {tf.aliasing_output = 542 : i64, tf.resource_name = "state.optimizer.state.108.beta1_power"} loc(unknown), %arg604: tensor<f32> {tf.aliasing_output = 543 : i64, tf.resource_name = "state.optimizer.state.108.beta2_power"} loc(unknown), %arg605: tensor<768xf32> {tf.aliasing_output = 545 : i64, tf.resource_name = "state.optimizer.state.109.exp_avg"} loc(unknown), %arg606: tensor<768xf32> {tf.aliasing_output = 546 : i64, tf.resource_name = "state.optimizer.state.109.exp_avg_sq"} loc(unknown), %arg607: tensor<f32> {tf.aliasing_output = 547 : i64, tf.resource_name = "state.optimizer.state.109.beta1_power"} loc(unknown), %arg608: tensor<f32> {tf.aliasing_output = 548 : i64, tf.resource_name = "state.optimizer.state.109.beta2_power"} loc(unknown), %arg609: tensor<3072xf32> {tf.aliasing_output = 550 : i64, tf.resource_name = "state.optimizer.state.110.exp_avg"} loc(unknown), %arg610: tensor<3072xf32> {tf.aliasing_output = 551 : i64, tf.resource_name = "state.optimizer.state.110.exp_avg_sq"} loc(unknown), %arg611: tensor<f32> {tf.aliasing_output = 552 : i64, tf.resource_name = "state.optimizer.state.110.beta1_power"} loc(unknown), %arg612: tensor<f32> {tf.aliasing_output = 553 : i64, tf.resource_name = "state.optimizer.state.110.beta2_power"} loc(unknown), %arg613: tensor<768xf32> {tf.aliasing_output = 555 : i64, tf.resource_name = "state.optimizer.state.111.exp_avg"} loc(unknown), %arg614: tensor<768xf32> {tf.aliasing_output = 556 : i64, tf.resource_name = "state.optimizer.state.111.exp_avg_sq"} loc(unknown), %arg615: tensor<f32> {tf.aliasing_output = 557 : i64, tf.resource_name = "state.optimizer.state.111.beta1_power"} loc(unknown), %arg616: tensor<f32> {tf.aliasing_output = 558 : i64, tf.resource_name = "state.optimizer.state.111.beta2_power"} loc(unknown), %arg617: tensor<768xf32> {tf.aliasing_output = 560 : i64, tf.resource_name = "state.optimizer.state.112.exp_avg"} loc(unknown), %arg618: tensor<768xf32> {tf.aliasing_output = 561 : i64, tf.resource_name = "state.optimizer.state.112.exp_avg_sq"} loc(unknown), %arg619: tensor<f32> {tf.aliasing_output = 562 : i64, tf.resource_name = "state.optimizer.state.112.beta1_power"} loc(unknown), %arg620: tensor<f32> {tf.aliasing_output = 563 : i64, tf.resource_name = "state.optimizer.state.112.beta2_power"} loc(unknown), %arg621: tensor<768xf32> {tf.aliasing_output = 565 : i64, tf.resource_name = "state.optimizer.state.113.exp_avg"} loc(unknown), %arg622: tensor<768xf32> {tf.aliasing_output = 566 : i64, tf.resource_name = "state.optimizer.state.113.exp_avg_sq"} loc(unknown), %arg623: tensor<f32> {tf.aliasing_output = 567 : i64, tf.resource_name = "state.optimizer.state.113.beta1_power"} loc(unknown), %arg624: tensor<f32> {tf.aliasing_output = 568 : i64, tf.resource_name = "state.optimizer.state.113.beta2_power"} loc(unknown), %arg625: tensor<768xf32> {tf.aliasing_output = 570 : i64, tf.resource_name = "state.optimizer.state.114.exp_avg"} loc(unknown), %arg626: tensor<768xf32> {tf.aliasing_output = 571 : i64, tf.resource_name = "state.optimizer.state.114.exp_avg_sq"} loc(unknown), %arg627: tensor<f32> {tf.aliasing_output = 572 : i64, tf.resource_name = "state.optimizer.state.114.beta1_power"} loc(unknown), %arg628: tensor<f32> {tf.aliasing_output = 573 : i64, tf.resource_name = "state.optimizer.state.114.beta2_power"} loc(unknown), %arg629: tensor<768xf32> {tf.aliasing_output = 575 : i64, tf.resource_name = "state.optimizer.state.115.exp_avg"} loc(unknown), %arg630: tensor<768xf32> {tf.aliasing_output = 576 : i64, tf.resource_name = "state.optimizer.state.115.exp_avg_sq"} loc(unknown), %arg631: tensor<f32> {tf.aliasing_output = 577 : i64, tf.resource_name = "state.optimizer.state.115.beta1_power"} loc(unknown), %arg632: tensor<f32> {tf.aliasing_output = 578 : i64, tf.resource_name = "state.optimizer.state.115.beta2_power"} loc(unknown), %arg633: tensor<768xf32> {tf.aliasing_output = 580 : i64, tf.resource_name = "state.optimizer.state.116.exp_avg"} loc(unknown), %arg634: tensor<768xf32> {tf.aliasing_output = 581 : i64, tf.resource_name = "state.optimizer.state.116.exp_avg_sq"} loc(unknown), %arg635: tensor<f32> {tf.aliasing_output = 582 : i64, tf.resource_name = "state.optimizer.state.116.beta1_power"} loc(unknown), %arg636: tensor<f32> {tf.aliasing_output = 583 : i64, tf.resource_name = "state.optimizer.state.116.beta2_power"} loc(unknown), %arg637: tensor<768xf32> {tf.aliasing_output = 585 : i64, tf.resource_name = "state.optimizer.state.117.exp_avg"} loc(unknown), %arg638: tensor<768xf32> {tf.aliasing_output = 586 : i64, tf.resource_name = "state.optimizer.state.117.exp_avg_sq"} loc(unknown), %arg639: tensor<f32> {tf.aliasing_output = 587 : i64, tf.resource_name = "state.optimizer.state.117.beta1_power"} loc(unknown), %arg640: tensor<f32> {tf.aliasing_output = 588 : i64, tf.resource_name = "state.optimizer.state.117.beta2_power"} loc(unknown), %arg641: tensor<768xf32> {tf.aliasing_output = 590 : i64, tf.resource_name = "state.optimizer.state.118.exp_avg"} loc(unknown), %arg642: tensor<768xf32> {tf.aliasing_output = 591 : i64, tf.resource_name = "state.optimizer.state.118.exp_avg_sq"} loc(unknown), %arg643: tensor<f32> {tf.aliasing_output = 592 : i64, tf.resource_name = "state.optimizer.state.118.beta1_power"} loc(unknown), %arg644: tensor<f32> {tf.aliasing_output = 593 : i64, tf.resource_name = "state.optimizer.state.118.beta2_power"} loc(unknown), %arg645: tensor<768xf32> {tf.aliasing_output = 595 : i64, tf.resource_name = "state.optimizer.state.119.exp_avg"} loc(unknown), %arg646: tensor<768xf32> {tf.aliasing_output = 596 : i64, tf.resource_name = "state.optimizer.state.119.exp_avg_sq"} loc(unknown), %arg647: tensor<f32> {tf.aliasing_output = 597 : i64, tf.resource_name = "state.optimizer.state.119.beta1_power"} loc(unknown), %arg648: tensor<f32> {tf.aliasing_output = 598 : i64, tf.resource_name = "state.optimizer.state.119.beta2_power"} loc(unknown), %arg649: tensor<3072xf32> {tf.aliasing_output = 600 : i64, tf.resource_name = "state.optimizer.state.120.exp_avg"} loc(unknown), %arg650: tensor<3072xf32> {tf.aliasing_output = 601 : i64, tf.resource_name = "state.optimizer.state.120.exp_avg_sq"} loc(unknown), %arg651: tensor<f32> {tf.aliasing_output = 602 : i64, tf.resource_name = "state.optimizer.state.120.beta1_power"} loc(unknown), %arg652: tensor<f32> {tf.aliasing_output = 603 : i64, tf.resource_name = "state.optimizer.state.120.beta2_power"} loc(unknown), %arg653: tensor<768xf32> {tf.aliasing_output = 605 : i64, tf.resource_name = "state.optimizer.state.121.exp_avg"} loc(unknown), %arg654: tensor<768xf32> {tf.aliasing_output = 606 : i64, tf.resource_name = "state.optimizer.state.121.exp_avg_sq"} loc(unknown), %arg655: tensor<f32> {tf.aliasing_output = 607 : i64, tf.resource_name = "state.optimizer.state.121.beta1_power"} loc(unknown), %arg656: tensor<f32> {tf.aliasing_output = 608 : i64, tf.resource_name = "state.optimizer.state.121.beta2_power"} loc(unknown), %arg657: tensor<768xf32> {tf.aliasing_output = 610 : i64, tf.resource_name = "state.optimizer.state.122.exp_avg"} loc(unknown), %arg658: tensor<768xf32> {tf.aliasing_output = 611 : i64, tf.resource_name = "state.optimizer.state.122.exp_avg_sq"} loc(unknown), %arg659: tensor<f32> {tf.aliasing_output = 612 : i64, tf.resource_name = "state.optimizer.state.122.beta1_power"} loc(unknown), %arg660: tensor<f32> {tf.aliasing_output = 613 : i64, tf.resource_name = "state.optimizer.state.122.beta2_power"} loc(unknown), %arg661: tensor<768xf32> {tf.aliasing_output = 615 : i64, tf.resource_name = "state.optimizer.state.123.exp_avg"} loc(unknown), %arg662: tensor<768xf32> {tf.aliasing_output = 616 : i64, tf.resource_name = "state.optimizer.state.123.exp_avg_sq"} loc(unknown), %arg663: tensor<f32> {tf.aliasing_output = 617 : i64, tf.resource_name = "state.optimizer.state.123.beta1_power"} loc(unknown), %arg664: tensor<f32> {tf.aliasing_output = 618 : i64, tf.resource_name = "state.optimizer.state.123.beta2_power"} loc(unknown), %arg665: tensor<768xf32> {tf.aliasing_output = 620 : i64, tf.resource_name = "state.optimizer.state.124.exp_avg"} loc(unknown), %arg666: tensor<768xf32> {tf.aliasing_output = 621 : i64, tf.resource_name = "state.optimizer.state.124.exp_avg_sq"} loc(unknown), %arg667: tensor<f32> {tf.aliasing_output = 622 : i64, tf.resource_name = "state.optimizer.state.124.beta1_power"} loc(unknown), %arg668: tensor<f32> {tf.aliasing_output = 623 : i64, tf.resource_name = "state.optimizer.state.124.beta2_power"} loc(unknown), %arg669: tensor<768xf32> {tf.aliasing_output = 625 : i64, tf.resource_name = "state.optimizer.state.125.exp_avg"} loc(unknown), %arg670: tensor<768xf32> {tf.aliasing_output = 626 : i64, tf.resource_name = "state.optimizer.state.125.exp_avg_sq"} loc(unknown), %arg671: tensor<f32> {tf.aliasing_output = 627 : i64, tf.resource_name = "state.optimizer.state.125.beta1_power"} loc(unknown), %arg672: tensor<f32> {tf.aliasing_output = 628 : i64, tf.resource_name = "state.optimizer.state.125.beta2_power"} loc(unknown), %arg673: tensor<768xf32> {tf.aliasing_output = 630 : i64, tf.resource_name = "state.optimizer.state.126.exp_avg"} loc(unknown), %arg674: tensor<768xf32> {tf.aliasing_output = 631 : i64, tf.resource_name = "state.optimizer.state.126.exp_avg_sq"} loc(unknown), %arg675: tensor<f32> {tf.aliasing_output = 632 : i64, tf.resource_name = "state.optimizer.state.126.beta1_power"} loc(unknown), %arg676: tensor<f32> {tf.aliasing_output = 633 : i64, tf.resource_name = "state.optimizer.state.126.beta2_power"} loc(unknown), %arg677: tensor<768xf32> {tf.aliasing_output = 635 : i64, tf.resource_name = "state.optimizer.state.127.exp_avg"} loc(unknown), %arg678: tensor<768xf32> {tf.aliasing_output = 636 : i64, tf.resource_name = "state.optimizer.state.127.exp_avg_sq"} loc(unknown), %arg679: tensor<f32> {tf.aliasing_output = 637 : i64, tf.resource_name = "state.optimizer.state.127.beta1_power"} loc(unknown), %arg680: tensor<f32> {tf.aliasing_output = 638 : i64, tf.resource_name = "state.optimizer.state.127.beta2_power"} loc(unknown), %arg681: tensor<768xf32> {tf.aliasing_output = 640 : i64, tf.resource_name = "state.optimizer.state.128.exp_avg"} loc(unknown), %arg682: tensor<768xf32> {tf.aliasing_output = 641 : i64, tf.resource_name = "state.optimizer.state.128.exp_avg_sq"} loc(unknown), %arg683: tensor<f32> {tf.aliasing_output = 642 : i64, tf.resource_name = "state.optimizer.state.128.beta1_power"} loc(unknown), %arg684: tensor<f32> {tf.aliasing_output = 643 : i64, tf.resource_name = "state.optimizer.state.128.beta2_power"} loc(unknown), %arg685: tensor<768xf32> {tf.aliasing_output = 645 : i64, tf.resource_name = "state.optimizer.state.129.exp_avg"} loc(unknown), %arg686: tensor<768xf32> {tf.aliasing_output = 646 : i64, tf.resource_name = "state.optimizer.state.129.exp_avg_sq"} loc(unknown), %arg687: tensor<f32> {tf.aliasing_output = 647 : i64, tf.resource_name = "state.optimizer.state.129.beta1_power"} loc(unknown), %arg688: tensor<f32> {tf.aliasing_output = 648 : i64, tf.resource_name = "state.optimizer.state.129.beta2_power"} loc(unknown), %arg689: tensor<3072xf32> {tf.aliasing_output = 650 : i64, tf.resource_name = "state.optimizer.state.130.exp_avg"} loc(unknown), %arg690: tensor<3072xf32> {tf.aliasing_output = 651 : i64, tf.resource_name = "state.optimizer.state.130.exp_avg_sq"} loc(unknown), %arg691: tensor<f32> {tf.aliasing_output = 652 : i64, tf.resource_name = "state.optimizer.state.130.beta1_power"} loc(unknown), %arg692: tensor<f32> {tf.aliasing_output = 653 : i64, tf.resource_name = "state.optimizer.state.130.beta2_power"} loc(unknown), %arg693: tensor<768xf32> {tf.aliasing_output = 655 : i64, tf.resource_name = "state.optimizer.state.131.exp_avg"} loc(unknown), %arg694: tensor<768xf32> {tf.aliasing_output = 656 : i64, tf.resource_name = "state.optimizer.state.131.exp_avg_sq"} loc(unknown), %arg695: tensor<f32> {tf.aliasing_output = 657 : i64, tf.resource_name = "state.optimizer.state.131.beta1_power"} loc(unknown), %arg696: tensor<f32> {tf.aliasing_output = 658 : i64, tf.resource_name = "state.optimizer.state.131.beta2_power"} loc(unknown), %arg697: tensor<768xf32> {tf.aliasing_output = 660 : i64, tf.resource_name = "state.optimizer.state.132.exp_avg"} loc(unknown), %arg698: tensor<768xf32> {tf.aliasing_output = 661 : i64, tf.resource_name = "state.optimizer.state.132.exp_avg_sq"} loc(unknown), %arg699: tensor<f32> {tf.aliasing_output = 662 : i64, tf.resource_name = "state.optimizer.state.132.beta1_power"} loc(unknown), %arg700: tensor<f32> {tf.aliasing_output = 663 : i64, tf.resource_name = "state.optimizer.state.132.beta2_power"} loc(unknown), %arg701: tensor<768xf32> {tf.aliasing_output = 665 : i64, tf.resource_name = "state.optimizer.state.133.exp_avg"} loc(unknown), %arg702: tensor<768xf32> {tf.aliasing_output = 666 : i64, tf.resource_name = "state.optimizer.state.133.exp_avg_sq"} loc(unknown), %arg703: tensor<f32> {tf.aliasing_output = 667 : i64, tf.resource_name = "state.optimizer.state.133.beta1_power"} loc(unknown), %arg704: tensor<f32> {tf.aliasing_output = 668 : i64, tf.resource_name = "state.optimizer.state.133.beta2_power"} loc(unknown), %arg705: tensor<768xf32> {tf.aliasing_output = 670 : i64, tf.resource_name = "state.optimizer.state.134.exp_avg"} loc(unknown), %arg706: tensor<768xf32> {tf.aliasing_output = 671 : i64, tf.resource_name = "state.optimizer.state.134.exp_avg_sq"} loc(unknown), %arg707: tensor<f32> {tf.aliasing_output = 672 : i64, tf.resource_name = "state.optimizer.state.134.beta1_power"} loc(unknown), %arg708: tensor<f32> {tf.aliasing_output = 673 : i64, tf.resource_name = "state.optimizer.state.134.beta2_power"} loc(unknown), %arg709: tensor<768xf32> {tf.aliasing_output = 675 : i64, tf.resource_name = "state.optimizer.state.135.exp_avg"} loc(unknown), %arg710: tensor<768xf32> {tf.aliasing_output = 676 : i64, tf.resource_name = "state.optimizer.state.135.exp_avg_sq"} loc(unknown), %arg711: tensor<f32> {tf.aliasing_output = 677 : i64, tf.resource_name = "state.optimizer.state.135.beta1_power"} loc(unknown), %arg712: tensor<f32> {tf.aliasing_output = 678 : i64, tf.resource_name = "state.optimizer.state.135.beta2_power"} loc(unknown), %arg713: tensor<768xf32> {tf.aliasing_output = 680 : i64, tf.resource_name = "state.optimizer.state.136.exp_avg"} loc(unknown), %arg714: tensor<768xf32> {tf.aliasing_output = 681 : i64, tf.resource_name = "state.optimizer.state.136.exp_avg_sq"} loc(unknown), %arg715: tensor<f32> {tf.aliasing_output = 682 : i64, tf.resource_name = "state.optimizer.state.136.beta1_power"} loc(unknown), %arg716: tensor<f32> {tf.aliasing_output = 683 : i64, tf.resource_name = "state.optimizer.state.136.beta2_power"} loc(unknown), %arg717: tensor<768xf32> {tf.aliasing_output = 685 : i64, tf.resource_name = "state.optimizer.state.137.exp_avg"} loc(unknown), %arg718: tensor<768xf32> {tf.aliasing_output = 686 : i64, tf.resource_name = "state.optimizer.state.137.exp_avg_sq"} loc(unknown), %arg719: tensor<f32> {tf.aliasing_output = 687 : i64, tf.resource_name = "state.optimizer.state.137.beta1_power"} loc(unknown), %arg720: tensor<f32> {tf.aliasing_output = 688 : i64, tf.resource_name = "state.optimizer.state.137.beta2_power"} loc(unknown), %arg721: tensor<768xf32> {tf.aliasing_output = 690 : i64, tf.resource_name = "state.optimizer.state.138.exp_avg"} loc(unknown), %arg722: tensor<768xf32> {tf.aliasing_output = 691 : i64, tf.resource_name = "state.optimizer.state.138.exp_avg_sq"} loc(unknown), %arg723: tensor<f32> {tf.aliasing_output = 692 : i64, tf.resource_name = "state.optimizer.state.138.beta1_power"} loc(unknown), %arg724: tensor<f32> {tf.aliasing_output = 693 : i64, tf.resource_name = "state.optimizer.state.138.beta2_power"} loc(unknown), %arg725: tensor<768xf32> {tf.aliasing_output = 695 : i64, tf.resource_name = "state.optimizer.state.139.exp_avg"} loc(unknown), %arg726: tensor<768xf32> {tf.aliasing_output = 696 : i64, tf.resource_name = "state.optimizer.state.139.exp_avg_sq"} loc(unknown), %arg727: tensor<f32> {tf.aliasing_output = 697 : i64, tf.resource_name = "state.optimizer.state.139.beta1_power"} loc(unknown), %arg728: tensor<f32> {tf.aliasing_output = 698 : i64, tf.resource_name = "state.optimizer.state.139.beta2_power"} loc(unknown), %arg729: tensor<3072xf32> {tf.aliasing_output = 700 : i64, tf.resource_name = "state.optimizer.state.140.exp_avg"} loc(unknown), %arg730: tensor<3072xf32> {tf.aliasing_output = 701 : i64, tf.resource_name = "state.optimizer.state.140.exp_avg_sq"} loc(unknown), %arg731: tensor<f32> {tf.aliasing_output = 702 : i64, tf.resource_name = "state.optimizer.state.140.beta1_power"} loc(unknown), %arg732: tensor<f32> {tf.aliasing_output = 703 : i64, tf.resource_name = "state.optimizer.state.140.beta2_power"} loc(unknown), %arg733: tensor<768xf32> {tf.aliasing_output = 705 : i64, tf.resource_name = "state.optimizer.state.141.exp_avg"} loc(unknown), %arg734: tensor<768xf32> {tf.aliasing_output = 706 : i64, tf.resource_name = "state.optimizer.state.141.exp_avg_sq"} loc(unknown), %arg735: tensor<f32> {tf.aliasing_output = 707 : i64, tf.resource_name = "state.optimizer.state.141.beta1_power"} loc(unknown), %arg736: tensor<f32> {tf.aliasing_output = 708 : i64, tf.resource_name = "state.optimizer.state.141.beta2_power"} loc(unknown), %arg737: tensor<768xf32> {tf.aliasing_output = 710 : i64, tf.resource_name = "state.optimizer.state.142.exp_avg"} loc(unknown), %arg738: tensor<768xf32> {tf.aliasing_output = 711 : i64, tf.resource_name = "state.optimizer.state.142.exp_avg_sq"} loc(unknown), %arg739: tensor<f32> {tf.aliasing_output = 712 : i64, tf.resource_name = "state.optimizer.state.142.beta1_power"} loc(unknown), %arg740: tensor<f32> {tf.aliasing_output = 713 : i64, tf.resource_name = "state.optimizer.state.142.beta2_power"} loc(unknown), %arg741: tensor<768xf32> {tf.aliasing_output = 715 : i64, tf.resource_name = "state.optimizer.state.143.exp_avg"} loc(unknown), %arg742: tensor<768xf32> {tf.aliasing_output = 716 : i64, tf.resource_name = "state.optimizer.state.143.exp_avg_sq"} loc(unknown), %arg743: tensor<f32> {tf.aliasing_output = 717 : i64, tf.resource_name = "state.optimizer.state.143.beta1_power"} loc(unknown), %arg744: tensor<f32> {tf.aliasing_output = 718 : i64, tf.resource_name = "state.optimizer.state.143.beta2_power"} loc(unknown), %arg745: tensor<768xf32> {tf.aliasing_output = 720 : i64, tf.resource_name = "state.optimizer.state.144.exp_avg"} loc(unknown), %arg746: tensor<768xf32> {tf.aliasing_output = 721 : i64, tf.resource_name = "state.optimizer.state.144.exp_avg_sq"} loc(unknown), %arg747: tensor<f32> {tf.aliasing_output = 722 : i64, tf.resource_name = "state.optimizer.state.144.beta1_power"} loc(unknown), %arg748: tensor<f32> {tf.aliasing_output = 723 : i64, tf.resource_name = "state.optimizer.state.144.beta2_power"} loc(unknown), %arg749: tensor<768xf32> {tf.aliasing_output = 725 : i64, tf.resource_name = "state.optimizer.state.145.exp_avg"} loc(unknown), %arg750: tensor<768xf32> {tf.aliasing_output = 726 : i64, tf.resource_name = "state.optimizer.state.145.exp_avg_sq"} loc(unknown), %arg751: tensor<f32> {tf.aliasing_output = 727 : i64, tf.resource_name = "state.optimizer.state.145.beta1_power"} loc(unknown), %arg752: tensor<f32> {tf.aliasing_output = 728 : i64, tf.resource_name = "state.optimizer.state.145.beta2_power"} loc(unknown), %arg753: tensor<768xf32> {tf.aliasing_output = 730 : i64, tf.resource_name = "state.optimizer.state.146.exp_avg"} loc(unknown), %arg754: tensor<768xf32> {tf.aliasing_output = 731 : i64, tf.resource_name = "state.optimizer.state.146.exp_avg_sq"} loc(unknown), %arg755: tensor<f32> {tf.aliasing_output = 732 : i64, tf.resource_name = "state.optimizer.state.146.beta1_power"} loc(unknown), %arg756: tensor<f32> {tf.aliasing_output = 733 : i64, tf.resource_name = "state.optimizer.state.146.beta2_power"} loc(unknown), %arg757: tensor<768xf32> {tf.aliasing_output = 735 : i64, tf.resource_name = "state.optimizer.state.147.exp_avg"} loc(unknown), %arg758: tensor<768xf32> {tf.aliasing_output = 736 : i64, tf.resource_name = "state.optimizer.state.147.exp_avg_sq"} loc(unknown), %arg759: tensor<f32> {tf.aliasing_output = 737 : i64, tf.resource_name = "state.optimizer.state.147.beta1_power"} loc(unknown), %arg760: tensor<f32> {tf.aliasing_output = 738 : i64, tf.resource_name = "state.optimizer.state.147.beta2_power"} loc(unknown), %arg761: tensor<768xf32> {tf.aliasing_output = 740 : i64, tf.resource_name = "state.optimizer.state.148.exp_avg"} loc(unknown), %arg762: tensor<768xf32> {tf.aliasing_output = 741 : i64, tf.resource_name = "state.optimizer.state.148.exp_avg_sq"} loc(unknown), %arg763: tensor<f32> {tf.aliasing_output = 742 : i64, tf.resource_name = "state.optimizer.state.148.beta1_power"} loc(unknown), %arg764: tensor<f32> {tf.aliasing_output = 743 : i64, tf.resource_name = "state.optimizer.state.148.beta2_power"} loc(unknown), %arg765: tensor<768xf32> {tf.aliasing_output = 745 : i64, tf.resource_name = "state.optimizer.state.149.exp_avg"} loc(unknown), %arg766: tensor<768xf32> {tf.aliasing_output = 746 : i64, tf.resource_name = "state.optimizer.state.149.exp_avg_sq"} loc(unknown), %arg767: tensor<f32> {tf.aliasing_output = 747 : i64, tf.resource_name = "state.optimizer.state.149.beta1_power"} loc(unknown), %arg768: tensor<f32> {tf.aliasing_output = 748 : i64, tf.resource_name = "state.optimizer.state.149.beta2_power"} loc(unknown), %arg769: tensor<3072xf32> {tf.aliasing_output = 750 : i64, tf.resource_name = "state.optimizer.state.150.exp_avg"} loc(unknown), %arg770: tensor<3072xf32> {tf.aliasing_output = 751 : i64, tf.resource_name = "state.optimizer.state.150.exp_avg_sq"} loc(unknown), %arg771: tensor<f32> {tf.aliasing_output = 752 : i64, tf.resource_name = "state.optimizer.state.150.beta1_power"} loc(unknown), %arg772: tensor<f32> {tf.aliasing_output = 753 : i64, tf.resource_name = "state.optimizer.state.150.beta2_power"} loc(unknown), %arg773: tensor<768xf32> {tf.aliasing_output = 755 : i64, tf.resource_name = "state.optimizer.state.151.exp_avg"} loc(unknown), %arg774: tensor<768xf32> {tf.aliasing_output = 756 : i64, tf.resource_name = "state.optimizer.state.151.exp_avg_sq"} loc(unknown), %arg775: tensor<f32> {tf.aliasing_output = 757 : i64, tf.resource_name = "state.optimizer.state.151.beta1_power"} loc(unknown), %arg776: tensor<f32> {tf.aliasing_output = 758 : i64, tf.resource_name = "state.optimizer.state.151.beta2_power"} loc(unknown), %arg777: tensor<768xf32> {tf.aliasing_output = 760 : i64, tf.resource_name = "state.optimizer.state.152.exp_avg"} loc(unknown), %arg778: tensor<768xf32> {tf.aliasing_output = 761 : i64, tf.resource_name = "state.optimizer.state.152.exp_avg_sq"} loc(unknown), %arg779: tensor<f32> {tf.aliasing_output = 762 : i64, tf.resource_name = "state.optimizer.state.152.beta1_power"} loc(unknown), %arg780: tensor<f32> {tf.aliasing_output = 763 : i64, tf.resource_name = "state.optimizer.state.152.beta2_power"} loc(unknown), %arg781: tensor<768xf32> {tf.aliasing_output = 765 : i64, tf.resource_name = "state.optimizer.state.153.exp_avg"} loc(unknown), %arg782: tensor<768xf32> {tf.aliasing_output = 766 : i64, tf.resource_name = "state.optimizer.state.153.exp_avg_sq"} loc(unknown), %arg783: tensor<f32> {tf.aliasing_output = 767 : i64, tf.resource_name = "state.optimizer.state.153.beta1_power"} loc(unknown), %arg784: tensor<f32> {tf.aliasing_output = 768 : i64, tf.resource_name = "state.optimizer.state.153.beta2_power"} loc(unknown), %arg785: tensor<768xf32> {tf.aliasing_output = 770 : i64, tf.resource_name = "state.optimizer.state.154.exp_avg"} loc(unknown), %arg786: tensor<768xf32> {tf.aliasing_output = 771 : i64, tf.resource_name = "state.optimizer.state.154.exp_avg_sq"} loc(unknown), %arg787: tensor<f32> {tf.aliasing_output = 772 : i64, tf.resource_name = "state.optimizer.state.154.beta1_power"} loc(unknown), %arg788: tensor<f32> {tf.aliasing_output = 773 : i64, tf.resource_name = "state.optimizer.state.154.beta2_power"} loc(unknown), %arg789: tensor<768xf32> {tf.aliasing_output = 775 : i64, tf.resource_name = "state.optimizer.state.155.exp_avg"} loc(unknown), %arg790: tensor<768xf32> {tf.aliasing_output = 776 : i64, tf.resource_name = "state.optimizer.state.155.exp_avg_sq"} loc(unknown), %arg791: tensor<f32> {tf.aliasing_output = 777 : i64, tf.resource_name = "state.optimizer.state.155.beta1_power"} loc(unknown), %arg792: tensor<f32> {tf.aliasing_output = 778 : i64, tf.resource_name = "state.optimizer.state.155.beta2_power"} loc(unknown), %arg793: tensor<768xf32> {tf.aliasing_output = 780 : i64, tf.resource_name = "state.optimizer.state.156.exp_avg"} loc(unknown), %arg794: tensor<768xf32> {tf.aliasing_output = 781 : i64, tf.resource_name = "state.optimizer.state.156.exp_avg_sq"} loc(unknown), %arg795: tensor<f32> {tf.aliasing_output = 782 : i64, tf.resource_name = "state.optimizer.state.156.beta1_power"} loc(unknown), %arg796: tensor<f32> {tf.aliasing_output = 783 : i64, tf.resource_name = "state.optimizer.state.156.beta2_power"} loc(unknown), %arg797: tensor<768xf32> {tf.aliasing_output = 785 : i64, tf.resource_name = "state.optimizer.state.157.exp_avg"} loc(unknown), %arg798: tensor<768xf32> {tf.aliasing_output = 786 : i64, tf.resource_name = "state.optimizer.state.157.exp_avg_sq"} loc(unknown), %arg799: tensor<f32> {tf.aliasing_output = 787 : i64, tf.resource_name = "state.optimizer.state.157.beta1_power"} loc(unknown), %arg800: tensor<f32> {tf.aliasing_output = 788 : i64, tf.resource_name = "state.optimizer.state.157.beta2_power"} loc(unknown), %arg801: tensor<768xf32> {tf.aliasing_output = 790 : i64, tf.resource_name = "state.optimizer.state.158.exp_avg"} loc(unknown), %arg802: tensor<768xf32> {tf.aliasing_output = 791 : i64, tf.resource_name = "state.optimizer.state.158.exp_avg_sq"} loc(unknown), %arg803: tensor<f32> {tf.aliasing_output = 792 : i64, tf.resource_name = "state.optimizer.state.158.beta1_power"} loc(unknown), %arg804: tensor<f32> {tf.aliasing_output = 793 : i64, tf.resource_name = "state.optimizer.state.158.beta2_power"} loc(unknown), %arg805: tensor<768xf32> {tf.aliasing_output = 795 : i64, tf.resource_name = "state.optimizer.state.159.exp_avg"} loc(unknown), %arg806: tensor<768xf32> {tf.aliasing_output = 796 : i64, tf.resource_name = "state.optimizer.state.159.exp_avg_sq"} loc(unknown), %arg807: tensor<f32> {tf.aliasing_output = 797 : i64, tf.resource_name = "state.optimizer.state.159.beta1_power"} loc(unknown), %arg808: tensor<f32> {tf.aliasing_output = 798 : i64, tf.resource_name = "state.optimizer.state.159.beta2_power"} loc(unknown), %arg809: tensor<3072xf32> {tf.aliasing_output = 800 : i64, tf.resource_name = "state.optimizer.state.160.exp_avg"} loc(unknown), %arg810: tensor<3072xf32> {tf.aliasing_output = 801 : i64, tf.resource_name = "state.optimizer.state.160.exp_avg_sq"} loc(unknown), %arg811: tensor<f32> {tf.aliasing_output = 802 : i64, tf.resource_name = "state.optimizer.state.160.beta1_power"} loc(unknown), %arg812: tensor<f32> {tf.aliasing_output = 803 : i64, tf.resource_name = "state.optimizer.state.160.beta2_power"} loc(unknown), %arg813: tensor<768xf32> {tf.aliasing_output = 805 : i64, tf.resource_name = "state.optimizer.state.161.exp_avg"} loc(unknown), %arg814: tensor<768xf32> {tf.aliasing_output = 806 : i64, tf.resource_name = "state.optimizer.state.161.exp_avg_sq"} loc(unknown), %arg815: tensor<f32> {tf.aliasing_output = 807 : i64, tf.resource_name = "state.optimizer.state.161.beta1_power"} loc(unknown), %arg816: tensor<f32> {tf.aliasing_output = 808 : i64, tf.resource_name = "state.optimizer.state.161.beta2_power"} loc(unknown), %arg817: tensor<768xf32> {tf.aliasing_output = 810 : i64, tf.resource_name = "state.optimizer.state.162.exp_avg"} loc(unknown), %arg818: tensor<768xf32> {tf.aliasing_output = 811 : i64, tf.resource_name = "state.optimizer.state.162.exp_avg_sq"} loc(unknown), %arg819: tensor<f32> {tf.aliasing_output = 812 : i64, tf.resource_name = "state.optimizer.state.162.beta1_power"} loc(unknown), %arg820: tensor<f32> {tf.aliasing_output = 813 : i64, tf.resource_name = "state.optimizer.state.162.beta2_power"} loc(unknown), %arg821: tensor<768xf32> {tf.aliasing_output = 815 : i64, tf.resource_name = "state.optimizer.state.163.exp_avg"} loc(unknown), %arg822: tensor<768xf32> {tf.aliasing_output = 816 : i64, tf.resource_name = "state.optimizer.state.163.exp_avg_sq"} loc(unknown), %arg823: tensor<f32> {tf.aliasing_output = 817 : i64, tf.resource_name = "state.optimizer.state.163.beta1_power"} loc(unknown), %arg824: tensor<f32> {tf.aliasing_output = 818 : i64, tf.resource_name = "state.optimizer.state.163.beta2_power"} loc(unknown)) -> (tensor<50257x768xf32>, tensor<50257x768xf32>, tensor<f32>, tensor<f32>, tensor<50257x768xf32>, tensor<2048x768xf32>, tensor<2048x768xf32>, tensor<f32>, tensor<f32>, tensor<2048x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<i64>, tensor<i64>, tensor<i64>, tensor<f32> {cs.output_name = "output_values_1"}, tensor<bf16> {cs.output_name = "output_loss"}) {
    %cst = cirh.Const dense<9.99999993E-9> : tensor<3072xf32> loc(#loc1)
    %cst_0 = cirh.Const dense<0.0500000119> : tensor<3072xf32> loc(#loc2)
    %cst_1 = cirh.Const dense<0.949999988> : tensor<3072xf32> loc(#loc2)
    %cst_2 = cirh.Const dense<0.100000024> : tensor<3072xf32> loc(#loc3)
    %cst_3 = cirh.Const dense<0.899999976> : tensor<3072xf32> loc(#loc3)
    %cst_4 = cirh.Const dense<9.99999993E-9> : tensor<768xf32> loc(#loc1)
    %cst_5 = cirh.Const dense<0.0500000119> : tensor<768xf32> loc(#loc2)
    %cst_6 = cirh.Const dense<0.949999988> : tensor<768xf32> loc(#loc2)
    %cst_7 = cirh.Const dense<0.100000024> : tensor<768xf32> loc(#loc3)
    %cst_8 = cirh.Const dense<0.899999976> : tensor<768xf32> loc(#loc3)
    %cst_9 = cirh.Const dense<1.000000e-01> : tensor<768x3072xf32> loc(#loc4)
    %cst_10 = cirh.Const dense<9.99999993E-9> : tensor<768x3072xf32> loc(#loc1)
    %cst_11 = cirh.Const dense<0.0500000119> : tensor<768x3072xf32> loc(#loc2)
    %cst_12 = cirh.Const dense<0.949999988> : tensor<768x3072xf32> loc(#loc2)
    %cst_13 = cirh.Const dense<0.100000024> : tensor<768x3072xf32> loc(#loc3)
    %cst_14 = cirh.Const dense<0.899999976> : tensor<768x3072xf32> loc(#loc3)
    %cst_15 = cirh.Const dense<1.000000e-01> : tensor<3072x768xf32> loc(#loc4)
    %cst_16 = cirh.Const dense<9.99999993E-9> : tensor<3072x768xf32> loc(#loc1)
    %cst_17 = cirh.Const dense<0.0500000119> : tensor<3072x768xf32> loc(#loc2)
    %cst_18 = cirh.Const dense<0.949999988> : tensor<3072x768xf32> loc(#loc2)
    %cst_19 = cirh.Const dense<0.100000024> : tensor<3072x768xf32> loc(#loc3)
    %cst_20 = cirh.Const dense<0.899999976> : tensor<3072x768xf32> loc(#loc3)
    %cst_21 = cirh.Const dense<1.000000e-01> : tensor<768x768xf32> loc(#loc4)
    %cst_22 = cirh.Const dense<9.99999993E-9> : tensor<768x768xf32> loc(#loc1)
    %cst_23 = cirh.Const dense<0.0500000119> : tensor<768x768xf32> loc(#loc2)
    %cst_24 = cirh.Const dense<0.949999988> : tensor<768x768xf32> loc(#loc2)
    %cst_25 = cirh.Const dense<0.100000024> : tensor<768x768xf32> loc(#loc3)
    %cst_26 = cirh.Const dense<0.899999976> : tensor<768x768xf32> loc(#loc3)
    %cst_27 = cirh.Const dense<1.000000e-01> : tensor<2048x768xf32> loc(#loc4)
    %cst_28 = cirh.Const dense<9.99999993E-9> : tensor<2048x768xf32> loc(#loc1)
    %cst_29 = cirh.Const dense<0.0500000119> : tensor<2048x768xf32> loc(#loc2)
    %cst_30 = cirh.Const dense<0.949999988> : tensor<2048x768xf32> loc(#loc2)
    %cst_31 = cirh.Const dense<0.100000024> : tensor<2048x768xf32> loc(#loc3)
    %cst_32 = cirh.Const dense<0.899999976> : tensor<2048x768xf32> loc(#loc3)
    %cst_33 = cirh.Const dense<1.000000e-01> : tensor<50257x768xf32> loc(#loc4)
    %cst_34 = cirh.Const dense<9.99999993E-9> : tensor<50257x768xf32> loc(#loc1)
    %cst_35 = cirh.Const dense<1.525000e+03> : tensor<f32> loc(#loc5)
    %cst_36 = cirh.Const dense<1.000000e+00> : tensor<f32> loc(#loc6)
    %cst_37 = cirh.Const dense<0.0500000119> : tensor<50257x768xf32> loc(#loc2)
    %cst_38 = cirh.Const dense<0.949999988> : tensor<50257x768xf32> loc(#loc2)
    %cst_39 = cirh.Const dense<0.100000024> : tensor<50257x768xf32> loc(#loc3)
    %cst_40 = cirh.Const dense<0.899999976> : tensor<50257x768xf32> loc(#loc3)
    %cst_41 = cirh.Const dense<0xFF800000> : tensor<f32> loc(#loc7)
    %cst_42 = cirh.Const dense<50257> : tensor<245760xi32> loc(#loc8)
    %cst_43 = cirh.Const dense<0> : tensor<245760xi32> loc(#loc8)
    %cst_44 = cirh.Const dense<[50257, 768]> : tensor<2xi64> loc(#loc8)
    %cst_45 = cirh.Const dense<-1> : tensor<245760xi32> loc(#loc8)
    %cst_46 = cirh.Const dense<2048> : tensor<245760xi64> loc(#loc9)
    %cst_47 = cirh.Const dense<0> : tensor<245760xi64> loc(#loc9)
    %cst_48 = cirh.Const dense<[2048, 768]> : tensor<2xi64> loc(#loc9)
    %cst_49 = cirh.Const dense<0.000000e+00> : tensor<245760x768xf32> loc(#loc9)
    %cst_50 = cirh.Const dense<-1> : tensor<245760xi64> loc(#loc9)
    %cst_51 = cirh.Const dense<4.06901063E-6> : tensor<245760x50257xf32> loc(#loc6)
    %cst_52 = cirh.Const dense<2.457600e+05> : tensor<f32> loc(#loc10)
    %cst_53 = cirh.Const dense<1.250000e-01> : tensor<120x12x2048x64xbf16> loc(#loc11)
    %cst_54 = cirh.Const dense<-3.389530e+38> : tensor<1x1x2048x2048xbf16> loc(#loc12)
    %cst_55 = cirh.Const dense<-1> : tensor<i64> loc(#loc13)
    %cst_56 = cirh.Const dense<1.000000e+00> : tensor<2048x2048xbf16> loc(#loc14)
    %cst_57 = cirh.Const dense<[0, 2, 1, 3]> : tensor<4xi64> loc(#loc15)
    %cst_58 = cirh.Const dense<0> : tensor<i64> loc(#loc13)
    %cst_59 = cirh.Const dense<1> : tensor<i64> loc(#loc0)
    %cst_60 = cirh.Const dense<1525> : tensor<i64> loc(#loc0)
    %cst_61 = cirh.Const dense<-6.000000e-04> : tensor<f32> loc(#loc0)
    %cst_62 = cirh.Const dense<6.000000e-04> : tensor<f32> loc(#loc0)
    %cst_63 = cirh.Const dense<4.18209907E-4> : tensor<f32> loc(#loc0)
    %cst_64 = cirh.Const dense<7.512000e+03> : tensor<f32> loc(#loc0)
    %cst_65 = cirh.Const dense<5.000000e-01> : tensor<f32> loc(#loc0)
    %cst_66 = cirh.Const dense<5.400000e-04> : tensor<f32> loc(#loc0)
    %cst_67 = cirh.Const dense<6.000000e-05> : tensor<f32> loc(#loc0)
    %cst_68 = cirh.Const dense<0.949999988> : tensor<f32> loc(#loc0)
    %cst_69 = cirh.Const dense<0.899999976> : tensor<f32> loc(#loc0)
    %cst_70 = cirh.Const dense<2048> : tensor<i64> loc(#loc0)
    %cst_71 = cirh.Const dense<9.99999997E-7> : tensor<f32> loc(#loc0)
    %0 = cirh.Cast %arg2 {Truncate = false} : tensor<768x3072xf32> -> tensor<768x3072xbf16> loc(#loc16)
    %1 = cirh.Cast %arg3 {Truncate = false} : tensor<3072x768xf32> -> tensor<3072x768xbf16> loc(#loc17)
    %2 = cirh.Cast %arg6 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc18)
    %3 = cirh.Cast %arg7 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc19)
    %4 = cirh.Cast %arg10 {Truncate = false} : tensor<768x3072xf32> -> tensor<768x3072xbf16> loc(#loc20)
    %5 = cirh.Cast %arg11 {Truncate = false} : tensor<3072x768xf32> -> tensor<3072x768xbf16> loc(#loc21)
    %6 = cirh.Cast %arg14 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc22)
    %7 = cirh.Cast %arg15 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc23)
    %8 = cirh.Cast %arg18 {Truncate = false} : tensor<768x3072xf32> -> tensor<768x3072xbf16> loc(#loc24)
    %9 = cirh.Cast %arg19 {Truncate = false} : tensor<3072x768xf32> -> tensor<3072x768xbf16> loc(#loc25)
    %10 = cirh.Cast %arg22 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc26)
    %11 = cirh.Cast %arg23 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc27)
    %12 = cirh.Cast %arg26 {Truncate = false} : tensor<768x3072xf32> -> tensor<768x3072xbf16> loc(#loc28)
    %13 = cirh.Cast %arg27 {Truncate = false} : tensor<3072x768xf32> -> tensor<3072x768xbf16> loc(#loc29)
    %14 = cirh.Cast %arg30 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc30)
    %15 = cirh.Cast %arg31 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc31)
    %16 = cirh.Cast %arg34 {Truncate = false} : tensor<768x3072xf32> -> tensor<768x3072xbf16> loc(#loc32)
    %17 = cirh.Cast %arg35 {Truncate = false} : tensor<3072x768xf32> -> tensor<3072x768xbf16> loc(#loc33)
    %18 = cirh.Cast %arg38 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc34)
    %19 = cirh.Cast %arg39 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc35)
    %20 = cirh.Cast %arg42 {Truncate = false} : tensor<768x3072xf32> -> tensor<768x3072xbf16> loc(#loc36)
    %21 = cirh.Cast %arg43 {Truncate = false} : tensor<3072x768xf32> -> tensor<3072x768xbf16> loc(#loc37)
    %22 = cirh.Cast %arg46 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc38)
    %23 = cirh.Cast %arg47 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc39)
    %24 = cirh.Cast %arg50 {Truncate = false} : tensor<768x3072xf32> -> tensor<768x3072xbf16> loc(#loc40)
    %25 = cirh.Cast %arg51 {Truncate = false} : tensor<3072x768xf32> -> tensor<3072x768xbf16> loc(#loc41)
    %26 = cirh.Cast %arg54 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc42)
    %27 = cirh.Cast %arg55 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc43)
    %28 = cirh.Cast %arg58 {Truncate = false} : tensor<768x3072xf32> -> tensor<768x3072xbf16> loc(#loc44)
    %29 = cirh.Cast %arg59 {Truncate = false} : tensor<3072x768xf32> -> tensor<3072x768xbf16> loc(#loc45)
    %30 = cirh.Cast %arg62 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc46)
    %31 = cirh.Cast %arg63 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc47)
    %32 = cirh.Cast %arg66 {Truncate = false} : tensor<768x3072xf32> -> tensor<768x3072xbf16> loc(#loc48)
    %33 = cirh.Cast %arg67 {Truncate = false} : tensor<3072x768xf32> -> tensor<3072x768xbf16> loc(#loc49)
    %34 = cirh.Cast %arg70 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc50)
    %35 = cirh.Cast %arg71 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc51)
    %36 = cirh.Cast %arg74 {Truncate = false} : tensor<768x3072xf32> -> tensor<768x3072xbf16> loc(#loc52)
    %37 = cirh.Cast %arg75 {Truncate = false} : tensor<3072x768xf32> -> tensor<3072x768xbf16> loc(#loc53)
    %38 = cirh.Cast %arg78 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc54)
    %39 = cirh.Cast %arg79 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc55)
    %40 = cirh.Arange %cst_58, %cst_70, %cst_59 {dim = 0 : i64} : (tensor<i64>, tensor<i64>, tensor<i64>) -> tensor<2048xi64> loc(#loc56)
    %41 = cirh.BroadcastInDim %40 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<2048xi64>) -> tensor<120x2048xi64> loc(#loc56)
    %42 = cirh.Reshape %41 : (tensor<120x2048xi64>) -> tensor<245760xi64> loc(#loc57)
    %43 = cirh.Gather %arg82, %42 {axis = 0 : i64, batch_dims = 0 : i64, is_sparse = false} : (tensor<2048x768xf32>, tensor<245760xi64>) -> tensor<245760x768xf32> loc(#loc57)
    %44 = cirh.Reshape %43 : (tensor<245760x768xf32>) -> tensor<120x2048x768xf32> loc(#loc57)
    %45 = cirh.Cast %44 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc58)
    %46 = cirh.Reshape %arg83 : (tensor<120x2048xi32>) -> tensor<245760xi32> loc(#loc59)
    %47 = cirh.Gather %arg84, %46 {axis = 0 : i64, batch_dims = 0 : i64, is_sparse = false} : (tensor<50257x768xf32>, tensor<245760xi32>) -> tensor<245760x768xf32> loc(#loc59)
    %48 = cirh.Reshape %47 : (tensor<245760x768xf32>) -> tensor<120x2048x768xf32> loc(#loc59)
    %49 = cirh.Cast %48 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc60)
    %50 = cirh.Add %49, %45 : tensor<120x2048x768xbf16> loc(#loc61)
    %51 = cirh.Cast %50 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc62)
    %52 = cirh.LayerNorm %51, %arg80, %arg81 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc63)
    %53 = cirh.Cast %52 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc64)
    %54 = cirh.Reshape %53 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc65)
    %55 = cirh.Cast %arg85 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc55)
    %56 = cirh.MatMul %54, %39 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc65)
    %57 = cirh.BroadcastInDim %55 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc65)
    %58 = cirh.Add %57, %56 : tensor<245760x768xbf16> loc(#loc65)
    %59 = cirh.Reshape %58 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc65)
    %60 = cirh.Reshape %59 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc15)
    %61 = cirh.Transpose %60, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc15)
    %62 = cirh.MatrixBandPart %cst_56, %cst_55, %cst_58 : (tensor<2048x2048xbf16>, tensor<i64>, tensor<i64>) -> tensor<2048x2048xbf16> loc(#loc13)
    %63 = cirh.Sub %cst_56, %62 : tensor<2048x2048xbf16> loc(#loc13)
    %64 = cirh.Reshape %63 : (tensor<2048x2048xbf16>) -> tensor<1x2048x2048xbf16> loc(#loc13)
    %65 = cirh.Reshape %64 : (tensor<1x2048x2048xbf16>) -> tensor<1x1x2048x2048xbf16> loc(#loc13)
    %66 = cirh.Mul %65, %cst_54 : tensor<1x1x2048x2048xbf16> loc(#loc12)
    %67 = cirh.Reshape %66 : (tensor<1x1x2048x2048xbf16>) -> tensor<1x2048x2048xbf16> loc(#loc12)
    %68 = cirh.Reshape %67 : (tensor<1x2048x2048xbf16>) -> tensor<2048x2048xbf16> loc(#loc12)
    %69 = cirh.Reshape %68 : (tensor<2048x2048xbf16>) -> tensor<1x2048x2048xbf16> loc(#loc12)
    %70 = cirh.Reshape %69 : (tensor<1x2048x2048xbf16>) -> tensor<1x1x2048x2048xbf16> loc(#loc12)
    %71 = cirh.Cast %arg86 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc66)
    %72 = cirh.Cast %arg87 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc66)
    %73 = cirh.MatMul %54, %71 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc67)
    %74 = cirh.BroadcastInDim %72 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc67)
    %75 = cirh.Add %74, %73 : tensor<245760x768xbf16> loc(#loc67)
    %76 = cirh.Reshape %75 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc67)
    %77 = cirh.Reshape %76 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc68)
    %78 = cirh.Transpose %77, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc68)
    %79 = cirh.Cast %arg88 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc69)
    %80 = cirh.Cast %arg89 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc69)
    %81 = cirh.MatMul %54, %79 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc70)
    %82 = cirh.BroadcastInDim %80 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc70)
    %83 = cirh.Add %82, %81 : tensor<245760x768xbf16> loc(#loc70)
    %84 = cirh.Reshape %83 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc70)
    %85 = cirh.Reshape %84 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc71)
    %86 = cirh.Transpose %85, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc71)
    %87 = cirh.Mul %86, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc11)
    %88 = cirh.DotGeneral %87, %78 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc72)
    %89 = cirh.BroadcastInDim %70 {broadcast_dimensions = dense<[0, 1, 2, 3]> : tensor<4xi64>} : (tensor<1x1x2048x2048xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc73)
    %90 = cirh.Add %88, %89 : tensor<120x12x2048x2048xbf16> loc(#loc73)
    %91 = cirh.Reshape %90 : (tensor<120x12x2048x2048xbf16>) -> tensor<1440x2048x2048xbf16> loc(#loc73)
    %92 = cirh.Reshape %91 : (tensor<1440x2048x2048xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc73)
    %93 = cirh.Cast %92 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc74)
    %94 = cirh.Softmax %93 {axis = 3 : i64} : tensor<120x12x2048x2048xf32> loc(#loc75)
    %95 = cirh.Cast %94 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc74)
    %96 = cirh.DotGeneral %95, %61 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc76)
    %97 = cirh.Transpose %96, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc77)
    %98 = cirh.Reshape %97 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc77)
    %99 = cirh.Reshape %98 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc78)
    %100 = cirh.Cast %arg90 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc54)
    %101 = cirh.MatMul %99, %38 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc78)
    %102 = cirh.BroadcastInDim %100 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc78)
    %103 = cirh.Add %102, %101 : tensor<245760x768xbf16> loc(#loc78)
    %104 = cirh.Reshape %103 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc78)
    %105 = cirh.Add %50, %104 : tensor<120x2048x768xbf16> loc(#loc79)
    %106 = cirh.Cast %105 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc80)
    %107 = cirh.LayerNorm %106, %arg76, %arg77 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc81)
    %108 = cirh.Cast %107 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc82)
    %109 = cirh.Reshape %108 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc83)
    %110 = cirh.Cast %arg91 {Truncate = false} : tensor<3072xf32> -> tensor<3072xbf16> loc(#loc53)
    %111 = cirh.MatMul %109, %37 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<3072x768xbf16>) -> tensor<245760x3072xbf16> loc(#loc83)
    %112 = cirh.BroadcastInDim %110 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc83)
    %113 = cirh.Add %112, %111 : tensor<245760x3072xbf16> loc(#loc83)
    %114 = cirh.Reshape %113 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc83)
    %115 = cirh.Gelu %114 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc84)
    %116 = cirh.Reshape %115 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc85)
    %117 = cirh.Cast %arg92 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc52)
    %118 = cirh.MatMul %116, %36 {transpose_a = false, transpose_b = true} : (tensor<245760x3072xbf16>, tensor<768x3072xbf16>) -> tensor<245760x768xbf16> loc(#loc85)
    %119 = cirh.BroadcastInDim %117 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc85)
    %120 = cirh.Add %119, %118 : tensor<245760x768xbf16> loc(#loc85)
    %121 = cirh.Reshape %120 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc85)
    %122 = cirh.Add %105, %121 : tensor<120x2048x768xbf16> loc(#loc86)
    %123 = cirh.Cast %122 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc87)
    %124 = cirh.LayerNorm %123, %arg72, %arg73 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc88)
    %125 = cirh.Cast %124 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc89)
    %126 = cirh.Reshape %125 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc90)
    %127 = cirh.Cast %arg93 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc51)
    %128 = cirh.MatMul %126, %35 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc90)
    %129 = cirh.BroadcastInDim %127 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc90)
    %130 = cirh.Add %129, %128 : tensor<245760x768xbf16> loc(#loc90)
    %131 = cirh.Reshape %130 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc90)
    %132 = cirh.Reshape %131 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc15)
    %133 = cirh.Transpose %132, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc15)
    %134 = cirh.Cast %arg94 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc91)
    %135 = cirh.Cast %arg95 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc91)
    %136 = cirh.MatMul %126, %134 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc92)
    %137 = cirh.BroadcastInDim %135 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc92)
    %138 = cirh.Add %137, %136 : tensor<245760x768xbf16> loc(#loc92)
    %139 = cirh.Reshape %138 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc92)
    %140 = cirh.Reshape %139 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc68)
    %141 = cirh.Transpose %140, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc68)
    %142 = cirh.Cast %arg96 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc93)
    %143 = cirh.Cast %arg97 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc93)
    %144 = cirh.MatMul %126, %142 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc94)
    %145 = cirh.BroadcastInDim %143 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc94)
    %146 = cirh.Add %145, %144 : tensor<245760x768xbf16> loc(#loc94)
    %147 = cirh.Reshape %146 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc94)
    %148 = cirh.Reshape %147 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc71)
    %149 = cirh.Transpose %148, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc71)
    %150 = cirh.Mul %149, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc11)
    %151 = cirh.DotGeneral %150, %141 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc72)
    %152 = cirh.Add %151, %89 : tensor<120x12x2048x2048xbf16> loc(#loc73)
    %153 = cirh.Reshape %152 : (tensor<120x12x2048x2048xbf16>) -> tensor<1440x2048x2048xbf16> loc(#loc73)
    %154 = cirh.Reshape %153 : (tensor<1440x2048x2048xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc73)
    %155 = cirh.Cast %154 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc74)
    %156 = cirh.Softmax %155 {axis = 3 : i64} : tensor<120x12x2048x2048xf32> loc(#loc75)
    %157 = cirh.Cast %156 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc74)
    %158 = cirh.DotGeneral %157, %133 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc76)
    %159 = cirh.Transpose %158, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc77)
    %160 = cirh.Reshape %159 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc77)
    %161 = cirh.Reshape %160 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc95)
    %162 = cirh.Cast %arg98 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc50)
    %163 = cirh.MatMul %161, %34 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc95)
    %164 = cirh.BroadcastInDim %162 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc95)
    %165 = cirh.Add %164, %163 : tensor<245760x768xbf16> loc(#loc95)
    %166 = cirh.Reshape %165 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc95)
    %167 = cirh.Add %122, %166 : tensor<120x2048x768xbf16> loc(#loc79)
    %168 = cirh.Cast %167 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc96)
    %169 = cirh.LayerNorm %168, %arg68, %arg69 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc97)
    %170 = cirh.Cast %169 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc98)
    %171 = cirh.Reshape %170 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc99)
    %172 = cirh.Cast %arg99 {Truncate = false} : tensor<3072xf32> -> tensor<3072xbf16> loc(#loc49)
    %173 = cirh.MatMul %171, %33 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<3072x768xbf16>) -> tensor<245760x3072xbf16> loc(#loc99)
    %174 = cirh.BroadcastInDim %172 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc99)
    %175 = cirh.Add %174, %173 : tensor<245760x3072xbf16> loc(#loc99)
    %176 = cirh.Reshape %175 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc99)
    %177 = cirh.Gelu %176 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc84)
    %178 = cirh.Reshape %177 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc100)
    %179 = cirh.Cast %arg100 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc48)
    %180 = cirh.MatMul %178, %32 {transpose_a = false, transpose_b = true} : (tensor<245760x3072xbf16>, tensor<768x3072xbf16>) -> tensor<245760x768xbf16> loc(#loc100)
    %181 = cirh.BroadcastInDim %179 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc100)
    %182 = cirh.Add %181, %180 : tensor<245760x768xbf16> loc(#loc100)
    %183 = cirh.Reshape %182 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc100)
    %184 = cirh.Add %167, %183 : tensor<120x2048x768xbf16> loc(#loc86)
    %185 = cirh.Cast %184 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc101)
    %186 = cirh.LayerNorm %185, %arg64, %arg65 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc102)
    %187 = cirh.Cast %186 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc103)
    %188 = cirh.Reshape %187 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc104)
    %189 = cirh.Cast %arg101 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc47)
    %190 = cirh.MatMul %188, %31 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc104)
    %191 = cirh.BroadcastInDim %189 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc104)
    %192 = cirh.Add %191, %190 : tensor<245760x768xbf16> loc(#loc104)
    %193 = cirh.Reshape %192 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc104)
    %194 = cirh.Reshape %193 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc15)
    %195 = cirh.Transpose %194, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc15)
    %196 = cirh.Cast %arg102 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc105)
    %197 = cirh.Cast %arg103 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc105)
    %198 = cirh.MatMul %188, %196 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc106)
    %199 = cirh.BroadcastInDim %197 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc106)
    %200 = cirh.Add %199, %198 : tensor<245760x768xbf16> loc(#loc106)
    %201 = cirh.Reshape %200 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc106)
    %202 = cirh.Reshape %201 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc68)
    %203 = cirh.Transpose %202, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc68)
    %204 = cirh.Cast %arg104 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc107)
    %205 = cirh.Cast %arg105 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc107)
    %206 = cirh.MatMul %188, %204 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc108)
    %207 = cirh.BroadcastInDim %205 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc108)
    %208 = cirh.Add %207, %206 : tensor<245760x768xbf16> loc(#loc108)
    %209 = cirh.Reshape %208 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc108)
    %210 = cirh.Reshape %209 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc71)
    %211 = cirh.Transpose %210, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc71)
    %212 = cirh.Mul %211, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc11)
    %213 = cirh.DotGeneral %212, %203 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc72)
    %214 = cirh.Add %213, %89 : tensor<120x12x2048x2048xbf16> loc(#loc73)
    %215 = cirh.Reshape %214 : (tensor<120x12x2048x2048xbf16>) -> tensor<1440x2048x2048xbf16> loc(#loc73)
    %216 = cirh.Reshape %215 : (tensor<1440x2048x2048xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc73)
    %217 = cirh.Cast %216 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc74)
    %218 = cirh.Softmax %217 {axis = 3 : i64} : tensor<120x12x2048x2048xf32> loc(#loc75)
    %219 = cirh.Cast %218 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc74)
    %220 = cirh.DotGeneral %219, %195 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc76)
    %221 = cirh.Transpose %220, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc77)
    %222 = cirh.Reshape %221 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc77)
    %223 = cirh.Reshape %222 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc109)
    %224 = cirh.Cast %arg106 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc46)
    %225 = cirh.MatMul %223, %30 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc109)
    %226 = cirh.BroadcastInDim %224 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc109)
    %227 = cirh.Add %226, %225 : tensor<245760x768xbf16> loc(#loc109)
    %228 = cirh.Reshape %227 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc109)
    %229 = cirh.Add %184, %228 : tensor<120x2048x768xbf16> loc(#loc79)
    %230 = cirh.Cast %229 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc110)
    %231 = cirh.LayerNorm %230, %arg60, %arg61 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc111)
    %232 = cirh.Cast %231 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc112)
    %233 = cirh.Reshape %232 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc113)
    %234 = cirh.Cast %arg107 {Truncate = false} : tensor<3072xf32> -> tensor<3072xbf16> loc(#loc45)
    %235 = cirh.MatMul %233, %29 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<3072x768xbf16>) -> tensor<245760x3072xbf16> loc(#loc113)
    %236 = cirh.BroadcastInDim %234 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc113)
    %237 = cirh.Add %236, %235 : tensor<245760x3072xbf16> loc(#loc113)
    %238 = cirh.Reshape %237 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc113)
    %239 = cirh.Gelu %238 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc84)
    %240 = cirh.Reshape %239 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc114)
    %241 = cirh.Cast %arg108 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc44)
    %242 = cirh.MatMul %240, %28 {transpose_a = false, transpose_b = true} : (tensor<245760x3072xbf16>, tensor<768x3072xbf16>) -> tensor<245760x768xbf16> loc(#loc114)
    %243 = cirh.BroadcastInDim %241 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc114)
    %244 = cirh.Add %243, %242 : tensor<245760x768xbf16> loc(#loc114)
    %245 = cirh.Reshape %244 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc114)
    %246 = cirh.Add %229, %245 : tensor<120x2048x768xbf16> loc(#loc86)
    %247 = cirh.Cast %246 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc115)
    %248 = cirh.LayerNorm %247, %arg56, %arg57 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc116)
    %249 = cirh.Cast %248 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc117)
    %250 = cirh.Reshape %249 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc118)
    %251 = cirh.Cast %arg109 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc43)
    %252 = cirh.MatMul %250, %27 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc118)
    %253 = cirh.BroadcastInDim %251 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc118)
    %254 = cirh.Add %253, %252 : tensor<245760x768xbf16> loc(#loc118)
    %255 = cirh.Reshape %254 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc118)
    %256 = cirh.Reshape %255 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc15)
    %257 = cirh.Transpose %256, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc15)
    %258 = cirh.Cast %arg110 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc119)
    %259 = cirh.Cast %arg111 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc119)
    %260 = cirh.MatMul %250, %258 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc120)
    %261 = cirh.BroadcastInDim %259 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc120)
    %262 = cirh.Add %261, %260 : tensor<245760x768xbf16> loc(#loc120)
    %263 = cirh.Reshape %262 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc120)
    %264 = cirh.Reshape %263 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc68)
    %265 = cirh.Transpose %264, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc68)
    %266 = cirh.Cast %arg112 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc121)
    %267 = cirh.Cast %arg113 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc121)
    %268 = cirh.MatMul %250, %266 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc122)
    %269 = cirh.BroadcastInDim %267 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc122)
    %270 = cirh.Add %269, %268 : tensor<245760x768xbf16> loc(#loc122)
    %271 = cirh.Reshape %270 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc122)
    %272 = cirh.Reshape %271 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc71)
    %273 = cirh.Transpose %272, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc71)
    %274 = cirh.Mul %273, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc11)
    %275 = cirh.DotGeneral %274, %265 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc72)
    %276 = cirh.Add %275, %89 : tensor<120x12x2048x2048xbf16> loc(#loc73)
    %277 = cirh.Reshape %276 : (tensor<120x12x2048x2048xbf16>) -> tensor<1440x2048x2048xbf16> loc(#loc73)
    %278 = cirh.Reshape %277 : (tensor<1440x2048x2048xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc73)
    %279 = cirh.Cast %278 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc74)
    %280 = cirh.Softmax %279 {axis = 3 : i64} : tensor<120x12x2048x2048xf32> loc(#loc75)
    %281 = cirh.Cast %280 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc74)
    %282 = cirh.DotGeneral %281, %257 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc76)
    %283 = cirh.Transpose %282, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc77)
    %284 = cirh.Reshape %283 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc77)
    %285 = cirh.Reshape %284 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc123)
    %286 = cirh.Cast %arg114 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc42)
    %287 = cirh.MatMul %285, %26 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc123)
    %288 = cirh.BroadcastInDim %286 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc123)
    %289 = cirh.Add %288, %287 : tensor<245760x768xbf16> loc(#loc123)
    %290 = cirh.Reshape %289 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc123)
    %291 = cirh.Add %246, %290 : tensor<120x2048x768xbf16> loc(#loc79)
    %292 = cirh.Cast %291 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc124)
    %293 = cirh.LayerNorm %292, %arg52, %arg53 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc125)
    %294 = cirh.Cast %293 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc126)
    %295 = cirh.Reshape %294 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc127)
    %296 = cirh.Cast %arg115 {Truncate = false} : tensor<3072xf32> -> tensor<3072xbf16> loc(#loc41)
    %297 = cirh.MatMul %295, %25 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<3072x768xbf16>) -> tensor<245760x3072xbf16> loc(#loc127)
    %298 = cirh.BroadcastInDim %296 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc127)
    %299 = cirh.Add %298, %297 : tensor<245760x3072xbf16> loc(#loc127)
    %300 = cirh.Reshape %299 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc127)
    %301 = cirh.Gelu %300 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc84)
    %302 = cirh.Reshape %301 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc128)
    %303 = cirh.Cast %arg116 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc40)
    %304 = cirh.MatMul %302, %24 {transpose_a = false, transpose_b = true} : (tensor<245760x3072xbf16>, tensor<768x3072xbf16>) -> tensor<245760x768xbf16> loc(#loc128)
    %305 = cirh.BroadcastInDim %303 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc128)
    %306 = cirh.Add %305, %304 : tensor<245760x768xbf16> loc(#loc128)
    %307 = cirh.Reshape %306 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc128)
    %308 = cirh.Add %291, %307 : tensor<120x2048x768xbf16> loc(#loc86)
    %309 = cirh.Cast %308 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc129)
    %310 = cirh.LayerNorm %309, %arg48, %arg49 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc130)
    %311 = cirh.Cast %310 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc131)
    %312 = cirh.Reshape %311 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc132)
    %313 = cirh.Cast %arg117 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc39)
    %314 = cirh.MatMul %312, %23 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc132)
    %315 = cirh.BroadcastInDim %313 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc132)
    %316 = cirh.Add %315, %314 : tensor<245760x768xbf16> loc(#loc132)
    %317 = cirh.Reshape %316 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc132)
    %318 = cirh.Reshape %317 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc15)
    %319 = cirh.Transpose %318, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc15)
    %320 = cirh.Cast %arg118 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc133)
    %321 = cirh.Cast %arg119 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc133)
    %322 = cirh.MatMul %312, %320 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc134)
    %323 = cirh.BroadcastInDim %321 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc134)
    %324 = cirh.Add %323, %322 : tensor<245760x768xbf16> loc(#loc134)
    %325 = cirh.Reshape %324 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc134)
    %326 = cirh.Reshape %325 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc68)
    %327 = cirh.Transpose %326, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc68)
    %328 = cirh.Cast %arg120 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc135)
    %329 = cirh.Cast %arg121 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc135)
    %330 = cirh.MatMul %312, %328 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc136)
    %331 = cirh.BroadcastInDim %329 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc136)
    %332 = cirh.Add %331, %330 : tensor<245760x768xbf16> loc(#loc136)
    %333 = cirh.Reshape %332 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc136)
    %334 = cirh.Reshape %333 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc71)
    %335 = cirh.Transpose %334, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc71)
    %336 = cirh.Mul %335, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc11)
    %337 = cirh.DotGeneral %336, %327 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc72)
    %338 = cirh.Add %337, %89 : tensor<120x12x2048x2048xbf16> loc(#loc73)
    %339 = cirh.Reshape %338 : (tensor<120x12x2048x2048xbf16>) -> tensor<1440x2048x2048xbf16> loc(#loc73)
    %340 = cirh.Reshape %339 : (tensor<1440x2048x2048xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc73)
    %341 = cirh.Cast %340 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc74)
    %342 = cirh.Softmax %341 {axis = 3 : i64} : tensor<120x12x2048x2048xf32> loc(#loc75)
    %343 = cirh.Cast %342 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc74)
    %344 = cirh.DotGeneral %343, %319 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc76)
    %345 = cirh.Transpose %344, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc77)
    %346 = cirh.Reshape %345 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc77)
    %347 = cirh.Reshape %346 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc137)
    %348 = cirh.Cast %arg122 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc38)
    %349 = cirh.MatMul %347, %22 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc137)
    %350 = cirh.BroadcastInDim %348 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc137)
    %351 = cirh.Add %350, %349 : tensor<245760x768xbf16> loc(#loc137)
    %352 = cirh.Reshape %351 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc137)
    %353 = cirh.Add %308, %352 : tensor<120x2048x768xbf16> loc(#loc79)
    %354 = cirh.Cast %353 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc138)
    %355 = cirh.LayerNorm %354, %arg44, %arg45 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc139)
    %356 = cirh.Cast %355 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc140)
    %357 = cirh.Reshape %356 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc141)
    %358 = cirh.Cast %arg123 {Truncate = false} : tensor<3072xf32> -> tensor<3072xbf16> loc(#loc37)
    %359 = cirh.MatMul %357, %21 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<3072x768xbf16>) -> tensor<245760x3072xbf16> loc(#loc141)
    %360 = cirh.BroadcastInDim %358 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc141)
    %361 = cirh.Add %360, %359 : tensor<245760x3072xbf16> loc(#loc141)
    %362 = cirh.Reshape %361 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc141)
    %363 = cirh.Gelu %362 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc84)
    %364 = cirh.Reshape %363 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc142)
    %365 = cirh.Cast %arg124 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc36)
    %366 = cirh.MatMul %364, %20 {transpose_a = false, transpose_b = true} : (tensor<245760x3072xbf16>, tensor<768x3072xbf16>) -> tensor<245760x768xbf16> loc(#loc142)
    %367 = cirh.BroadcastInDim %365 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc142)
    %368 = cirh.Add %367, %366 : tensor<245760x768xbf16> loc(#loc142)
    %369 = cirh.Reshape %368 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc142)
    %370 = cirh.Add %353, %369 : tensor<120x2048x768xbf16> loc(#loc86)
    %371 = cirh.Cast %370 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc143)
    %372 = cirh.LayerNorm %371, %arg40, %arg41 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc144)
    %373 = cirh.Cast %372 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc145)
    %374 = cirh.Reshape %373 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc146)
    %375 = cirh.Cast %arg125 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc35)
    %376 = cirh.MatMul %374, %19 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc146)
    %377 = cirh.BroadcastInDim %375 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc146)
    %378 = cirh.Add %377, %376 : tensor<245760x768xbf16> loc(#loc146)
    %379 = cirh.Reshape %378 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc146)
    %380 = cirh.Reshape %379 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc15)
    %381 = cirh.Transpose %380, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc15)
    %382 = cirh.Cast %arg126 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc147)
    %383 = cirh.Cast %arg127 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc147)
    %384 = cirh.MatMul %374, %382 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc148)
    %385 = cirh.BroadcastInDim %383 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc148)
    %386 = cirh.Add %385, %384 : tensor<245760x768xbf16> loc(#loc148)
    %387 = cirh.Reshape %386 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc148)
    %388 = cirh.Reshape %387 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc68)
    %389 = cirh.Transpose %388, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc68)
    %390 = cirh.Cast %arg128 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc149)
    %391 = cirh.Cast %arg129 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc149)
    %392 = cirh.MatMul %374, %390 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc150)
    %393 = cirh.BroadcastInDim %391 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc150)
    %394 = cirh.Add %393, %392 : tensor<245760x768xbf16> loc(#loc150)
    %395 = cirh.Reshape %394 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc150)
    %396 = cirh.Reshape %395 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc71)
    %397 = cirh.Transpose %396, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc71)
    %398 = cirh.Mul %397, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc11)
    %399 = cirh.DotGeneral %398, %389 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc72)
    %400 = cirh.Add %399, %89 : tensor<120x12x2048x2048xbf16> loc(#loc73)
    %401 = cirh.Reshape %400 : (tensor<120x12x2048x2048xbf16>) -> tensor<1440x2048x2048xbf16> loc(#loc73)
    %402 = cirh.Reshape %401 : (tensor<1440x2048x2048xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc73)
    %403 = cirh.Cast %402 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc74)
    %404 = cirh.Softmax %403 {axis = 3 : i64} : tensor<120x12x2048x2048xf32> loc(#loc75)
    %405 = cirh.Cast %404 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc74)
    %406 = cirh.DotGeneral %405, %381 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc76)
    %407 = cirh.Transpose %406, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc77)
    %408 = cirh.Reshape %407 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc77)
    %409 = cirh.Reshape %408 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc151)
    %410 = cirh.Cast %arg130 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc34)
    %411 = cirh.MatMul %409, %18 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc151)
    %412 = cirh.BroadcastInDim %410 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc151)
    %413 = cirh.Add %412, %411 : tensor<245760x768xbf16> loc(#loc151)
    %414 = cirh.Reshape %413 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc151)
    %415 = cirh.Add %370, %414 : tensor<120x2048x768xbf16> loc(#loc79)
    %416 = cirh.Cast %415 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc152)
    %417 = cirh.LayerNorm %416, %arg36, %arg37 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc153)
    %418 = cirh.Cast %417 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc154)
    %419 = cirh.Reshape %418 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc155)
    %420 = cirh.Cast %arg131 {Truncate = false} : tensor<3072xf32> -> tensor<3072xbf16> loc(#loc33)
    %421 = cirh.MatMul %419, %17 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<3072x768xbf16>) -> tensor<245760x3072xbf16> loc(#loc155)
    %422 = cirh.BroadcastInDim %420 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc155)
    %423 = cirh.Add %422, %421 : tensor<245760x3072xbf16> loc(#loc155)
    %424 = cirh.Reshape %423 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc155)
    %425 = cirh.Gelu %424 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc84)
    %426 = cirh.Reshape %425 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc156)
    %427 = cirh.Cast %arg132 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc32)
    %428 = cirh.MatMul %426, %16 {transpose_a = false, transpose_b = true} : (tensor<245760x3072xbf16>, tensor<768x3072xbf16>) -> tensor<245760x768xbf16> loc(#loc156)
    %429 = cirh.BroadcastInDim %427 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc156)
    %430 = cirh.Add %429, %428 : tensor<245760x768xbf16> loc(#loc156)
    %431 = cirh.Reshape %430 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc156)
    %432 = cirh.Add %415, %431 : tensor<120x2048x768xbf16> loc(#loc86)
    %433 = cirh.Cast %432 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc157)
    %434 = cirh.LayerNorm %433, %arg32, %arg33 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc158)
    %435 = cirh.Cast %434 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc159)
    %436 = cirh.Reshape %435 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc160)
    %437 = cirh.Cast %arg133 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc31)
    %438 = cirh.MatMul %436, %15 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc160)
    %439 = cirh.BroadcastInDim %437 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc160)
    %440 = cirh.Add %439, %438 : tensor<245760x768xbf16> loc(#loc160)
    %441 = cirh.Reshape %440 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc160)
    %442 = cirh.Reshape %441 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc15)
    %443 = cirh.Transpose %442, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc15)
    %444 = cirh.Cast %arg134 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc161)
    %445 = cirh.Cast %arg135 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc161)
    %446 = cirh.MatMul %436, %444 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc162)
    %447 = cirh.BroadcastInDim %445 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc162)
    %448 = cirh.Add %447, %446 : tensor<245760x768xbf16> loc(#loc162)
    %449 = cirh.Reshape %448 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc162)
    %450 = cirh.Reshape %449 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc68)
    %451 = cirh.Transpose %450, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc68)
    %452 = cirh.Cast %arg136 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc163)
    %453 = cirh.Cast %arg137 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc163)
    %454 = cirh.MatMul %436, %452 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc164)
    %455 = cirh.BroadcastInDim %453 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc164)
    %456 = cirh.Add %455, %454 : tensor<245760x768xbf16> loc(#loc164)
    %457 = cirh.Reshape %456 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc164)
    %458 = cirh.Reshape %457 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc71)
    %459 = cirh.Transpose %458, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc71)
    %460 = cirh.Mul %459, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc11)
    %461 = cirh.DotGeneral %460, %451 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc72)
    %462 = cirh.Add %461, %89 : tensor<120x12x2048x2048xbf16> loc(#loc73)
    %463 = cirh.Reshape %462 : (tensor<120x12x2048x2048xbf16>) -> tensor<1440x2048x2048xbf16> loc(#loc73)
    %464 = cirh.Reshape %463 : (tensor<1440x2048x2048xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc73)
    %465 = cirh.Cast %464 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc74)
    %466 = cirh.Softmax %465 {axis = 3 : i64} : tensor<120x12x2048x2048xf32> loc(#loc75)
    %467 = cirh.Cast %466 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc74)
    %468 = cirh.DotGeneral %467, %443 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc76)
    %469 = cirh.Transpose %468, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc77)
    %470 = cirh.Reshape %469 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc77)
    %471 = cirh.Reshape %470 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc165)
    %472 = cirh.Cast %arg138 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc30)
    %473 = cirh.MatMul %471, %14 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc165)
    %474 = cirh.BroadcastInDim %472 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc165)
    %475 = cirh.Add %474, %473 : tensor<245760x768xbf16> loc(#loc165)
    %476 = cirh.Reshape %475 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc165)
    %477 = cirh.Add %432, %476 : tensor<120x2048x768xbf16> loc(#loc79)
    %478 = cirh.Cast %477 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc166)
    %479 = cirh.LayerNorm %478, %arg28, %arg29 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc167)
    %480 = cirh.Cast %479 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc168)
    %481 = cirh.Reshape %480 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc169)
    %482 = cirh.Cast %arg139 {Truncate = false} : tensor<3072xf32> -> tensor<3072xbf16> loc(#loc29)
    %483 = cirh.MatMul %481, %13 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<3072x768xbf16>) -> tensor<245760x3072xbf16> loc(#loc169)
    %484 = cirh.BroadcastInDim %482 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc169)
    %485 = cirh.Add %484, %483 : tensor<245760x3072xbf16> loc(#loc169)
    %486 = cirh.Reshape %485 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc169)
    %487 = cirh.Gelu %486 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc84)
    %488 = cirh.Reshape %487 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc170)
    %489 = cirh.Cast %arg140 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc28)
    %490 = cirh.MatMul %488, %12 {transpose_a = false, transpose_b = true} : (tensor<245760x3072xbf16>, tensor<768x3072xbf16>) -> tensor<245760x768xbf16> loc(#loc170)
    %491 = cirh.BroadcastInDim %489 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc170)
    %492 = cirh.Add %491, %490 : tensor<245760x768xbf16> loc(#loc170)
    %493 = cirh.Reshape %492 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc170)
    %494 = cirh.Add %477, %493 : tensor<120x2048x768xbf16> loc(#loc86)
    %495 = cirh.Cast %494 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc171)
    %496 = cirh.LayerNorm %495, %arg24, %arg25 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc172)
    %497 = cirh.Cast %496 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc173)
    %498 = cirh.Reshape %497 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc174)
    %499 = cirh.Cast %arg141 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc27)
    %500 = cirh.MatMul %498, %11 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc174)
    %501 = cirh.BroadcastInDim %499 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc174)
    %502 = cirh.Add %501, %500 : tensor<245760x768xbf16> loc(#loc174)
    %503 = cirh.Reshape %502 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc174)
    %504 = cirh.Reshape %503 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc15)
    %505 = cirh.Transpose %504, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc15)
    %506 = cirh.Cast %arg142 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc175)
    %507 = cirh.Cast %arg143 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc175)
    %508 = cirh.MatMul %498, %506 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc176)
    %509 = cirh.BroadcastInDim %507 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc176)
    %510 = cirh.Add %509, %508 : tensor<245760x768xbf16> loc(#loc176)
    %511 = cirh.Reshape %510 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc176)
    %512 = cirh.Reshape %511 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc68)
    %513 = cirh.Transpose %512, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc68)
    %514 = cirh.Cast %arg144 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc177)
    %515 = cirh.Cast %arg145 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc177)
    %516 = cirh.MatMul %498, %514 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc178)
    %517 = cirh.BroadcastInDim %515 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc178)
    %518 = cirh.Add %517, %516 : tensor<245760x768xbf16> loc(#loc178)
    %519 = cirh.Reshape %518 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc178)
    %520 = cirh.Reshape %519 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc71)
    %521 = cirh.Transpose %520, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc71)
    %522 = cirh.Mul %521, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc11)
    %523 = cirh.DotGeneral %522, %513 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc72)
    %524 = cirh.Add %523, %89 : tensor<120x12x2048x2048xbf16> loc(#loc73)
    %525 = cirh.Reshape %524 : (tensor<120x12x2048x2048xbf16>) -> tensor<1440x2048x2048xbf16> loc(#loc73)
    %526 = cirh.Reshape %525 : (tensor<1440x2048x2048xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc73)
    %527 = cirh.Cast %526 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc74)
    %528 = cirh.Softmax %527 {axis = 3 : i64} : tensor<120x12x2048x2048xf32> loc(#loc75)
    %529 = cirh.Cast %528 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc74)
    %530 = cirh.DotGeneral %529, %505 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc76)
    %531 = cirh.Transpose %530, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc77)
    %532 = cirh.Reshape %531 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc77)
    %533 = cirh.Reshape %532 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc179)
    %534 = cirh.Cast %arg146 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc26)
    %535 = cirh.MatMul %533, %10 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc179)
    %536 = cirh.BroadcastInDim %534 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc179)
    %537 = cirh.Add %536, %535 : tensor<245760x768xbf16> loc(#loc179)
    %538 = cirh.Reshape %537 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc179)
    %539 = cirh.Add %494, %538 : tensor<120x2048x768xbf16> loc(#loc79)
    %540 = cirh.Cast %539 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc180)
    %541 = cirh.LayerNorm %540, %arg20, %arg21 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc181)
    %542 = cirh.Cast %541 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc182)
    %543 = cirh.Reshape %542 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc183)
    %544 = cirh.Cast %arg147 {Truncate = false} : tensor<3072xf32> -> tensor<3072xbf16> loc(#loc25)
    %545 = cirh.MatMul %543, %9 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<3072x768xbf16>) -> tensor<245760x3072xbf16> loc(#loc183)
    %546 = cirh.BroadcastInDim %544 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc183)
    %547 = cirh.Add %546, %545 : tensor<245760x3072xbf16> loc(#loc183)
    %548 = cirh.Reshape %547 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc183)
    %549 = cirh.Gelu %548 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc84)
    %550 = cirh.Reshape %549 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc184)
    %551 = cirh.Cast %arg148 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc24)
    %552 = cirh.MatMul %550, %8 {transpose_a = false, transpose_b = true} : (tensor<245760x3072xbf16>, tensor<768x3072xbf16>) -> tensor<245760x768xbf16> loc(#loc184)
    %553 = cirh.BroadcastInDim %551 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc184)
    %554 = cirh.Add %553, %552 : tensor<245760x768xbf16> loc(#loc184)
    %555 = cirh.Reshape %554 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc184)
    %556 = cirh.Add %539, %555 : tensor<120x2048x768xbf16> loc(#loc86)
    %557 = cirh.Cast %556 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc185)
    %558 = cirh.LayerNorm %557, %arg16, %arg17 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc186)
    %559 = cirh.Cast %558 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc187)
    %560 = cirh.Reshape %559 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc188)
    %561 = cirh.Cast %arg149 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc23)
    %562 = cirh.MatMul %560, %7 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc188)
    %563 = cirh.BroadcastInDim %561 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc188)
    %564 = cirh.Add %563, %562 : tensor<245760x768xbf16> loc(#loc188)
    %565 = cirh.Reshape %564 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc188)
    %566 = cirh.Reshape %565 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc15)
    %567 = cirh.Transpose %566, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc15)
    %568 = cirh.Cast %arg150 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc189)
    %569 = cirh.Cast %arg151 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc189)
    %570 = cirh.MatMul %560, %568 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc190)
    %571 = cirh.BroadcastInDim %569 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc190)
    %572 = cirh.Add %571, %570 : tensor<245760x768xbf16> loc(#loc190)
    %573 = cirh.Reshape %572 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc190)
    %574 = cirh.Reshape %573 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc68)
    %575 = cirh.Transpose %574, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc68)
    %576 = cirh.Cast %arg152 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc191)
    %577 = cirh.Cast %arg153 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc191)
    %578 = cirh.MatMul %560, %576 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc192)
    %579 = cirh.BroadcastInDim %577 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc192)
    %580 = cirh.Add %579, %578 : tensor<245760x768xbf16> loc(#loc192)
    %581 = cirh.Reshape %580 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc192)
    %582 = cirh.Reshape %581 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc71)
    %583 = cirh.Transpose %582, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc71)
    %584 = cirh.Mul %583, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc11)
    %585 = cirh.DotGeneral %584, %575 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc72)
    %586 = cirh.Add %585, %89 : tensor<120x12x2048x2048xbf16> loc(#loc73)
    %587 = cirh.Reshape %586 : (tensor<120x12x2048x2048xbf16>) -> tensor<1440x2048x2048xbf16> loc(#loc73)
    %588 = cirh.Reshape %587 : (tensor<1440x2048x2048xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc73)
    %589 = cirh.Cast %588 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc74)
    %590 = cirh.Softmax %589 {axis = 3 : i64} : tensor<120x12x2048x2048xf32> loc(#loc75)
    %591 = cirh.Cast %590 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc74)
    %592 = cirh.DotGeneral %591, %567 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc76)
    %593 = cirh.Transpose %592, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc77)
    %594 = cirh.Reshape %593 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc77)
    %595 = cirh.Reshape %594 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc193)
    %596 = cirh.Cast %arg154 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc22)
    %597 = cirh.MatMul %595, %6 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc193)
    %598 = cirh.BroadcastInDim %596 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc193)
    %599 = cirh.Add %598, %597 : tensor<245760x768xbf16> loc(#loc193)
    %600 = cirh.Reshape %599 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc193)
    %601 = cirh.Add %556, %600 : tensor<120x2048x768xbf16> loc(#loc79)
    %602 = cirh.Cast %601 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc194)
    %603 = cirh.LayerNorm %602, %arg12, %arg13 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc195)
    %604 = cirh.Cast %603 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc196)
    %605 = cirh.Reshape %604 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc197)
    %606 = cirh.Cast %arg155 {Truncate = false} : tensor<3072xf32> -> tensor<3072xbf16> loc(#loc21)
    %607 = cirh.MatMul %605, %5 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<3072x768xbf16>) -> tensor<245760x3072xbf16> loc(#loc197)
    %608 = cirh.BroadcastInDim %606 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc197)
    %609 = cirh.Add %608, %607 : tensor<245760x3072xbf16> loc(#loc197)
    %610 = cirh.Reshape %609 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc197)
    %611 = cirh.Gelu %610 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc84)
    %612 = cirh.Reshape %611 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc198)
    %613 = cirh.Cast %arg156 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc20)
    %614 = cirh.MatMul %612, %4 {transpose_a = false, transpose_b = true} : (tensor<245760x3072xbf16>, tensor<768x3072xbf16>) -> tensor<245760x768xbf16> loc(#loc198)
    %615 = cirh.BroadcastInDim %613 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc198)
    %616 = cirh.Add %615, %614 : tensor<245760x768xbf16> loc(#loc198)
    %617 = cirh.Reshape %616 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc198)
    %618 = cirh.Add %601, %617 : tensor<120x2048x768xbf16> loc(#loc86)
    %619 = cirh.Cast %618 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc199)
    %620 = cirh.LayerNorm %619, %arg8, %arg9 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc200)
    %621 = cirh.Cast %620 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc201)
    %622 = cirh.Reshape %621 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc202)
    %623 = cirh.Cast %arg157 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc19)
    %624 = cirh.MatMul %622, %3 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc202)
    %625 = cirh.BroadcastInDim %623 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc202)
    %626 = cirh.Add %625, %624 : tensor<245760x768xbf16> loc(#loc202)
    %627 = cirh.Reshape %626 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc202)
    %628 = cirh.Reshape %627 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc15)
    %629 = cirh.Transpose %628, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc15)
    %630 = cirh.Cast %arg158 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc203)
    %631 = cirh.Cast %arg159 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc203)
    %632 = cirh.MatMul %622, %630 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc204)
    %633 = cirh.BroadcastInDim %631 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc204)
    %634 = cirh.Add %633, %632 : tensor<245760x768xbf16> loc(#loc204)
    %635 = cirh.Reshape %634 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc204)
    %636 = cirh.Reshape %635 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc68)
    %637 = cirh.Transpose %636, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc68)
    %638 = cirh.Cast %arg160 {Truncate = false} : tensor<768x768xf32> -> tensor<768x768xbf16> loc(#loc205)
    %639 = cirh.Cast %arg161 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc205)
    %640 = cirh.MatMul %622, %638 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc206)
    %641 = cirh.BroadcastInDim %639 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc206)
    %642 = cirh.Add %641, %640 : tensor<245760x768xbf16> loc(#loc206)
    %643 = cirh.Reshape %642 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc206)
    %644 = cirh.Reshape %643 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc71)
    %645 = cirh.Transpose %644, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc71)
    %646 = cirh.Mul %645, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc11)
    %647 = cirh.DotGeneral %646, %637 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc72)
    %648 = cirh.Add %647, %89 : tensor<120x12x2048x2048xbf16> loc(#loc73)
    %649 = cirh.Reshape %648 : (tensor<120x12x2048x2048xbf16>) -> tensor<1440x2048x2048xbf16> loc(#loc73)
    %650 = cirh.Reshape %649 : (tensor<1440x2048x2048xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc73)
    %651 = cirh.Cast %650 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc74)
    %652 = cirh.Softmax %651 {axis = 3 : i64} : tensor<120x12x2048x2048xf32> loc(#loc75)
    %653 = cirh.Cast %652 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc74)
    %654 = cirh.DotGeneral %653, %629 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc76)
    %655 = cirh.Transpose %654, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc77)
    %656 = cirh.Reshape %655 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc77)
    %657 = cirh.Reshape %656 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc207)
    %658 = cirh.Cast %arg162 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc18)
    %659 = cirh.MatMul %657, %2 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc207)
    %660 = cirh.BroadcastInDim %658 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc207)
    %661 = cirh.Add %660, %659 : tensor<245760x768xbf16> loc(#loc207)
    %662 = cirh.Reshape %661 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc207)
    %663 = cirh.Add %618, %662 : tensor<120x2048x768xbf16> loc(#loc79)
    %664 = cirh.Cast %663 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc208)
    %665 = cirh.LayerNorm %664, %arg4, %arg5 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc209)
    %666 = cirh.Cast %665 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc210)
    %667 = cirh.Reshape %666 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc211)
    %668 = cirh.Cast %arg163 {Truncate = false} : tensor<3072xf32> -> tensor<3072xbf16> loc(#loc17)
    %669 = cirh.MatMul %667, %1 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<3072x768xbf16>) -> tensor<245760x3072xbf16> loc(#loc211)
    %670 = cirh.BroadcastInDim %668 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc211)
    %671 = cirh.Add %670, %669 : tensor<245760x3072xbf16> loc(#loc211)
    %672 = cirh.Reshape %671 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc211)
    %673 = cirh.Gelu %672 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc84)
    %674 = cirh.Reshape %673 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc212)
    %675 = cirh.Cast %arg164 {Truncate = false} : tensor<768xf32> -> tensor<768xbf16> loc(#loc16)
    %676 = cirh.MatMul %674, %0 {transpose_a = false, transpose_b = true} : (tensor<245760x3072xbf16>, tensor<768x3072xbf16>) -> tensor<245760x768xbf16> loc(#loc212)
    %677 = cirh.BroadcastInDim %675 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<245760x768xbf16> loc(#loc212)
    %678 = cirh.Add %677, %676 : tensor<245760x768xbf16> loc(#loc212)
    %679 = cirh.Reshape %678 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc212)
    %680 = cirh.Add %663, %679 : tensor<120x2048x768xbf16> loc(#loc86)
    %681 = cirh.Cast %680 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc213)
    %682 = cirh.LayerNorm %681, %arg0, %arg1 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> tensor<120x2048x768xf32> loc(#loc214)
    %683 = cirh.Cast %arg84 {Truncate = false} : tensor<50257x768xf32> -> tensor<50257x768xbf16> loc(#loc215)
    %684 = cirh.Cast %682 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc216)
    %685 = cirh.Reshape %684 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc217)
    %686 = cirh.MatMul %685, %683 {transpose_a = false, transpose_b = true} : (tensor<245760x768xbf16>, tensor<50257x768xbf16>) -> tensor<245760x50257xbf16> loc(#loc217)
    %687 = cirh.Reshape %686 : (tensor<245760x50257xbf16>) -> tensor<120x2048x50257xbf16> loc(#loc217)
    %688 = cirh.Reshape %687 : (tensor<120x2048x50257xbf16>) -> tensor<245760x50257xbf16> loc(#loc218)
    %689 = cirh.Cast %688 {Truncate = false} : tensor<245760x50257xbf16> -> tensor<245760x50257xf32> loc(#loc219)
    %690 = cirh.Reshape %arg165 : (tensor<120x2048xi32>) -> tensor<245760xi32> loc(#loc218)
    %691 = cirh.Cast %690 {Truncate = false} : tensor<245760xi32> -> tensor<245760xi64> loc(#loc218)
    %loss, %backprop = cirh.SparseSoftmaxCrossEntropyWithLogits %689, %691 {axis = 1 : i64} : (tensor<245760x50257xf32>, tensor<245760xi64>) -> (tensor<245760xf32>, tensor<245760x50257xf32>) loc(#loc6)
    %692 = cirh.Mul %backprop, %cst_51 : tensor<245760x50257xf32> loc(#loc6)
    %693 = cirh.Cast %692 {Truncate = false} : tensor<245760x50257xf32> -> tensor<245760x50257xbf16> loc(#loc220)
    %694 = cirh.Reshape %693 : (tensor<245760x50257xbf16>) -> tensor<120x2048x50257xbf16> loc(#loc220)
    %695 = cirh.Reshape %694 : (tensor<120x2048x50257xbf16>) -> tensor<245760x50257xbf16> loc(#loc221)
    %696 = cirh.MatMul %695, %683 {transpose_a = false, transpose_b = false} : (tensor<245760x50257xbf16>, tensor<50257x768xbf16>) -> tensor<245760x768xbf16> loc(#loc221)
    %697 = cirh.Reshape %696 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc221)
    %698 = cirh.Cast %697 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc222)
    %result, %beta_grad, %gamma_grad = cirh.LayerNormGrad %698, %681, %arg0, %arg1 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc222)
    %699 = cirh.L2Norm %beta_grad {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %700 = cirh.L2Norm %gamma_grad {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %701 = cirh.Cast %result {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc222)
    %702 = cirh.Reshape %701 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc224)
    %703 = cirh.Reduce %702 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc224)
    %704 = cirh.BroadcastInDim %703 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc224)
    %705 = cirh.Reshape %704 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc224)
    %706 = cirh.Cast %705 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc224)
    %707 = cirh.L2Norm %706 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %708 = cirh.MatMul %702, %0 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc224)
    %709 = cirh.Reshape %708 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc224)
    %710 = cirh.GeluGrad %709, %672 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc224)
    %711 = cirh.Reshape %710 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc225)
    %712 = cirh.Reduce %711 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x3072xbf16>) -> tensor<3072xbf16> loc(#loc225)
    %713 = cirh.BroadcastInDim %712 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<1x3072xbf16> loc(#loc225)
    %714 = cirh.Reshape %713 : (tensor<1x3072xbf16>) -> tensor<3072xbf16> loc(#loc225)
    %715 = cirh.Cast %714 {Truncate = false} : tensor<3072xbf16> -> tensor<3072xf32> loc(#loc225)
    %716 = cirh.L2Norm %715 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<3072xf32>) -> tensor<f32> loc(#loc223)
    %717 = cirh.MatMul %711, %1 {transpose_a = false, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<3072x768xbf16>) -> tensor<245760x768xbf16> loc(#loc225)
    %718 = cirh.Reshape %717 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc225)
    %719 = cirh.Cast %718 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc226)
    %result_72, %beta_grad_73, %gamma_grad_74 = cirh.LayerNormGrad %719, %664, %arg4, %arg5 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc226)
    %720 = cirh.L2Norm %beta_grad_73 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %721 = cirh.L2Norm %gamma_grad_74 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %722 = cirh.Cast %result_72 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc226)
    %723 = cirh.Add %701, %722 : tensor<120x2048x768xbf16> loc(#loc226)
    %724 = cirh.Reshape %723 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc227)
    %725 = cirh.MatMul %724, %2 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc227)
    %726 = cirh.Reshape %725 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc227)
    %727 = cirh.Reshape %726 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc227)
    %728 = cirh.Transpose %727, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc227)
    %729 = cirh.DotGeneral %728, %629 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc227)
    %730 = cirh.Cast %729 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc228)
    %731 = cirh.Mul %730, %652 : tensor<120x12x2048x2048xf32> loc(#loc228)
    %732 = cirh.Reduce %731 {dimensions = dense<3> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<120x12x2048x2048xf32>) -> tensor<120x12x2048xf32> loc(#loc228)
    %733 = cirh.BroadcastInDim %732 {broadcast_dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<120x12x2048xf32>) -> tensor<120x12x2048x1xf32> loc(#loc228)
    %734 = cirh.BroadcastInDim %733 {broadcast_dimensions = dense<[0, 1, 2, 3]> : tensor<4xi64>} : (tensor<120x12x2048x1xf32>) -> tensor<120x12x2048x2048xf32> loc(#loc228)
    %735 = cirh.Sub %730, %734 : tensor<120x12x2048x2048xf32> loc(#loc228)
    %736 = cirh.Mul %652, %735 : tensor<120x12x2048x2048xf32> loc(#loc228)
    %737 = cirh.Cast %736 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc228)
    %738 = cirh.DotGeneral %737, %637 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc228)
    %739 = cirh.Mul %738, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc228)
    %740 = cirh.Transpose %739, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc229)
    %741 = cirh.Reshape %740 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc229)
    %742 = cirh.Reshape %741 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc230)
    %743 = cirh.MatMul %742, %638 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc230)
    %744 = cirh.Reshape %743 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc230)
    %745 = cirh.DotGeneral %737, %646 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc228)
    %746 = cirh.Transpose %745, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc231)
    %747 = cirh.Reshape %746 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc231)
    %748 = cirh.Reshape %747 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc229)
    %749 = cirh.MatMul %748, %630 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc229)
    %750 = cirh.Reshape %749 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc229)
    %751 = cirh.DotGeneral %653, %728 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc227)
    %752 = cirh.Transpose %751, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc228)
    %753 = cirh.Reshape %752 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc228)
    %754 = cirh.Reshape %753 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc231)
    %755 = cirh.MatMul %754, %3 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc231)
    %756 = cirh.Reshape %755 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc231)
    %757 = cirh.Add %756, %750 : tensor<120x2048x768xbf16> loc(#loc229)
    %758 = cirh.Add %757, %744 : tensor<120x2048x768xbf16> loc(#loc230)
    %759 = cirh.Cast %758 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc232)
    %result_75, %beta_grad_76, %gamma_grad_77 = cirh.LayerNormGrad %759, %619, %arg8, %arg9 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc232)
    %760 = cirh.L2Norm %beta_grad_76 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %761 = cirh.L2Norm %gamma_grad_77 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %762 = cirh.Reduce %724 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc227)
    %763 = cirh.BroadcastInDim %762 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc227)
    %764 = cirh.Reshape %763 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc227)
    %765 = cirh.Cast %764 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc227)
    %766 = cirh.L2Norm %765 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %767 = cirh.Reduce %754 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc231)
    %768 = cirh.BroadcastInDim %767 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc231)
    %769 = cirh.Reshape %768 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc231)
    %770 = cirh.Cast %769 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc231)
    %771 = cirh.L2Norm %770 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %772 = cirh.Reduce %748 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc229)
    %773 = cirh.BroadcastInDim %772 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc229)
    %774 = cirh.Reshape %773 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc229)
    %775 = cirh.Cast %774 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc229)
    %776 = cirh.L2Norm %775 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %777 = cirh.Reduce %742 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc230)
    %778 = cirh.BroadcastInDim %777 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc230)
    %779 = cirh.Reshape %778 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc230)
    %780 = cirh.Cast %779 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc230)
    %781 = cirh.L2Norm %780 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %782 = cirh.Cast %result_75 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc232)
    %783 = cirh.Add %723, %782 : tensor<120x2048x768xbf16> loc(#loc232)
    %784 = cirh.Reshape %783 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc233)
    %785 = cirh.Reduce %784 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc233)
    %786 = cirh.BroadcastInDim %785 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc233)
    %787 = cirh.Reshape %786 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc233)
    %788 = cirh.Cast %787 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc233)
    %789 = cirh.L2Norm %788 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %790 = cirh.MatMul %784, %4 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc233)
    %791 = cirh.Reshape %790 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc233)
    %792 = cirh.GeluGrad %791, %610 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc233)
    %793 = cirh.Reshape %792 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc234)
    %794 = cirh.Reduce %793 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x3072xbf16>) -> tensor<3072xbf16> loc(#loc234)
    %795 = cirh.BroadcastInDim %794 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<1x3072xbf16> loc(#loc234)
    %796 = cirh.Reshape %795 : (tensor<1x3072xbf16>) -> tensor<3072xbf16> loc(#loc234)
    %797 = cirh.Cast %796 {Truncate = false} : tensor<3072xbf16> -> tensor<3072xf32> loc(#loc234)
    %798 = cirh.L2Norm %797 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<3072xf32>) -> tensor<f32> loc(#loc223)
    %799 = cirh.MatMul %793, %5 {transpose_a = false, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<3072x768xbf16>) -> tensor<245760x768xbf16> loc(#loc234)
    %800 = cirh.Reshape %799 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc234)
    %801 = cirh.Cast %800 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc235)
    %result_78, %beta_grad_79, %gamma_grad_80 = cirh.LayerNormGrad %801, %602, %arg12, %arg13 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc235)
    %802 = cirh.L2Norm %beta_grad_79 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %803 = cirh.L2Norm %gamma_grad_80 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %804 = cirh.Cast %result_78 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc235)
    %805 = cirh.Add %783, %804 : tensor<120x2048x768xbf16> loc(#loc235)
    %806 = cirh.Reshape %805 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc236)
    %807 = cirh.MatMul %806, %6 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc236)
    %808 = cirh.Reshape %807 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc236)
    %809 = cirh.Reshape %808 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc236)
    %810 = cirh.Transpose %809, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc236)
    %811 = cirh.DotGeneral %810, %567 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc236)
    %812 = cirh.Cast %811 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc237)
    %813 = cirh.Mul %812, %590 : tensor<120x12x2048x2048xf32> loc(#loc237)
    %814 = cirh.Reduce %813 {dimensions = dense<3> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<120x12x2048x2048xf32>) -> tensor<120x12x2048xf32> loc(#loc237)
    %815 = cirh.BroadcastInDim %814 {broadcast_dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<120x12x2048xf32>) -> tensor<120x12x2048x1xf32> loc(#loc237)
    %816 = cirh.BroadcastInDim %815 {broadcast_dimensions = dense<[0, 1, 2, 3]> : tensor<4xi64>} : (tensor<120x12x2048x1xf32>) -> tensor<120x12x2048x2048xf32> loc(#loc237)
    %817 = cirh.Sub %812, %816 : tensor<120x12x2048x2048xf32> loc(#loc237)
    %818 = cirh.Mul %590, %817 : tensor<120x12x2048x2048xf32> loc(#loc237)
    %819 = cirh.Cast %818 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc237)
    %820 = cirh.DotGeneral %819, %575 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc237)
    %821 = cirh.Mul %820, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc237)
    %822 = cirh.Transpose %821, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc238)
    %823 = cirh.Reshape %822 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc238)
    %824 = cirh.Reshape %823 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc239)
    %825 = cirh.MatMul %824, %576 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc239)
    %826 = cirh.Reshape %825 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc239)
    %827 = cirh.DotGeneral %819, %584 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc237)
    %828 = cirh.Transpose %827, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc240)
    %829 = cirh.Reshape %828 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc240)
    %830 = cirh.Reshape %829 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc238)
    %831 = cirh.MatMul %830, %568 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc238)
    %832 = cirh.Reshape %831 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc238)
    %833 = cirh.DotGeneral %591, %810 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc236)
    %834 = cirh.Transpose %833, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc237)
    %835 = cirh.Reshape %834 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc237)
    %836 = cirh.Reshape %835 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc240)
    %837 = cirh.MatMul %836, %7 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc240)
    %838 = cirh.Reshape %837 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc240)
    %839 = cirh.Add %838, %832 : tensor<120x2048x768xbf16> loc(#loc238)
    %840 = cirh.Add %839, %826 : tensor<120x2048x768xbf16> loc(#loc239)
    %841 = cirh.Cast %840 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc241)
    %result_81, %beta_grad_82, %gamma_grad_83 = cirh.LayerNormGrad %841, %557, %arg16, %arg17 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc241)
    %842 = cirh.L2Norm %beta_grad_82 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %843 = cirh.L2Norm %gamma_grad_83 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %844 = cirh.Reduce %806 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc236)
    %845 = cirh.BroadcastInDim %844 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc236)
    %846 = cirh.Reshape %845 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc236)
    %847 = cirh.Cast %846 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc236)
    %848 = cirh.L2Norm %847 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %849 = cirh.Reduce %836 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc240)
    %850 = cirh.BroadcastInDim %849 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc240)
    %851 = cirh.Reshape %850 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc240)
    %852 = cirh.Cast %851 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc240)
    %853 = cirh.L2Norm %852 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %854 = cirh.Reduce %830 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc238)
    %855 = cirh.BroadcastInDim %854 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc238)
    %856 = cirh.Reshape %855 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc238)
    %857 = cirh.Cast %856 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc238)
    %858 = cirh.L2Norm %857 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %859 = cirh.Reduce %824 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc239)
    %860 = cirh.BroadcastInDim %859 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc239)
    %861 = cirh.Reshape %860 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc239)
    %862 = cirh.Cast %861 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc239)
    %863 = cirh.L2Norm %862 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %864 = cirh.Cast %result_81 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc241)
    %865 = cirh.Add %805, %864 : tensor<120x2048x768xbf16> loc(#loc241)
    %866 = cirh.Reshape %865 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc242)
    %867 = cirh.Reduce %866 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc242)
    %868 = cirh.BroadcastInDim %867 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc242)
    %869 = cirh.Reshape %868 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc242)
    %870 = cirh.Cast %869 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc242)
    %871 = cirh.L2Norm %870 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %872 = cirh.MatMul %866, %8 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc242)
    %873 = cirh.Reshape %872 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc242)
    %874 = cirh.GeluGrad %873, %548 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc242)
    %875 = cirh.Reshape %874 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc243)
    %876 = cirh.Reduce %875 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x3072xbf16>) -> tensor<3072xbf16> loc(#loc243)
    %877 = cirh.BroadcastInDim %876 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<1x3072xbf16> loc(#loc243)
    %878 = cirh.Reshape %877 : (tensor<1x3072xbf16>) -> tensor<3072xbf16> loc(#loc243)
    %879 = cirh.Cast %878 {Truncate = false} : tensor<3072xbf16> -> tensor<3072xf32> loc(#loc243)
    %880 = cirh.L2Norm %879 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<3072xf32>) -> tensor<f32> loc(#loc223)
    %881 = cirh.MatMul %875, %9 {transpose_a = false, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<3072x768xbf16>) -> tensor<245760x768xbf16> loc(#loc243)
    %882 = cirh.Reshape %881 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc243)
    %883 = cirh.Cast %882 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc244)
    %result_84, %beta_grad_85, %gamma_grad_86 = cirh.LayerNormGrad %883, %540, %arg20, %arg21 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc244)
    %884 = cirh.L2Norm %beta_grad_85 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %885 = cirh.L2Norm %gamma_grad_86 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %886 = cirh.Cast %result_84 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc244)
    %887 = cirh.Add %865, %886 : tensor<120x2048x768xbf16> loc(#loc244)
    %888 = cirh.Reshape %887 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc245)
    %889 = cirh.MatMul %888, %10 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc245)
    %890 = cirh.Reshape %889 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc245)
    %891 = cirh.Reshape %890 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc245)
    %892 = cirh.Transpose %891, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc245)
    %893 = cirh.DotGeneral %892, %505 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc245)
    %894 = cirh.Cast %893 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc246)
    %895 = cirh.Mul %894, %528 : tensor<120x12x2048x2048xf32> loc(#loc246)
    %896 = cirh.Reduce %895 {dimensions = dense<3> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<120x12x2048x2048xf32>) -> tensor<120x12x2048xf32> loc(#loc246)
    %897 = cirh.BroadcastInDim %896 {broadcast_dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<120x12x2048xf32>) -> tensor<120x12x2048x1xf32> loc(#loc246)
    %898 = cirh.BroadcastInDim %897 {broadcast_dimensions = dense<[0, 1, 2, 3]> : tensor<4xi64>} : (tensor<120x12x2048x1xf32>) -> tensor<120x12x2048x2048xf32> loc(#loc246)
    %899 = cirh.Sub %894, %898 : tensor<120x12x2048x2048xf32> loc(#loc246)
    %900 = cirh.Mul %528, %899 : tensor<120x12x2048x2048xf32> loc(#loc246)
    %901 = cirh.Cast %900 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc246)
    %902 = cirh.DotGeneral %901, %513 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc246)
    %903 = cirh.Mul %902, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc246)
    %904 = cirh.Transpose %903, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc247)
    %905 = cirh.Reshape %904 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc247)
    %906 = cirh.Reshape %905 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc248)
    %907 = cirh.MatMul %906, %514 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc248)
    %908 = cirh.Reshape %907 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc248)
    %909 = cirh.DotGeneral %901, %522 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc246)
    %910 = cirh.Transpose %909, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc249)
    %911 = cirh.Reshape %910 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc249)
    %912 = cirh.Reshape %911 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc247)
    %913 = cirh.MatMul %912, %506 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc247)
    %914 = cirh.Reshape %913 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc247)
    %915 = cirh.DotGeneral %529, %892 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc245)
    %916 = cirh.Transpose %915, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc246)
    %917 = cirh.Reshape %916 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc246)
    %918 = cirh.Reshape %917 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc249)
    %919 = cirh.MatMul %918, %11 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc249)
    %920 = cirh.Reshape %919 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc249)
    %921 = cirh.Add %920, %914 : tensor<120x2048x768xbf16> loc(#loc247)
    %922 = cirh.Add %921, %908 : tensor<120x2048x768xbf16> loc(#loc248)
    %923 = cirh.Cast %922 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc250)
    %result_87, %beta_grad_88, %gamma_grad_89 = cirh.LayerNormGrad %923, %495, %arg24, %arg25 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc250)
    %924 = cirh.L2Norm %beta_grad_88 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %925 = cirh.L2Norm %gamma_grad_89 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %926 = cirh.Reduce %888 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc245)
    %927 = cirh.BroadcastInDim %926 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc245)
    %928 = cirh.Reshape %927 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc245)
    %929 = cirh.Cast %928 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc245)
    %930 = cirh.L2Norm %929 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %931 = cirh.Reduce %918 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc249)
    %932 = cirh.BroadcastInDim %931 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc249)
    %933 = cirh.Reshape %932 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc249)
    %934 = cirh.Cast %933 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc249)
    %935 = cirh.L2Norm %934 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %936 = cirh.Reduce %912 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc247)
    %937 = cirh.BroadcastInDim %936 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc247)
    %938 = cirh.Reshape %937 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc247)
    %939 = cirh.Cast %938 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc247)
    %940 = cirh.L2Norm %939 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %941 = cirh.Reduce %906 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc248)
    %942 = cirh.BroadcastInDim %941 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc248)
    %943 = cirh.Reshape %942 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc248)
    %944 = cirh.Cast %943 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc248)
    %945 = cirh.L2Norm %944 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %946 = cirh.Cast %result_87 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc250)
    %947 = cirh.Add %887, %946 : tensor<120x2048x768xbf16> loc(#loc250)
    %948 = cirh.Reshape %947 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc251)
    %949 = cirh.Reduce %948 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc251)
    %950 = cirh.BroadcastInDim %949 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc251)
    %951 = cirh.Reshape %950 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc251)
    %952 = cirh.Cast %951 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc251)
    %953 = cirh.L2Norm %952 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %954 = cirh.MatMul %948, %12 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc251)
    %955 = cirh.Reshape %954 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc251)
    %956 = cirh.GeluGrad %955, %486 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc251)
    %957 = cirh.Reshape %956 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc252)
    %958 = cirh.Reduce %957 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x3072xbf16>) -> tensor<3072xbf16> loc(#loc252)
    %959 = cirh.BroadcastInDim %958 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<1x3072xbf16> loc(#loc252)
    %960 = cirh.Reshape %959 : (tensor<1x3072xbf16>) -> tensor<3072xbf16> loc(#loc252)
    %961 = cirh.Cast %960 {Truncate = false} : tensor<3072xbf16> -> tensor<3072xf32> loc(#loc252)
    %962 = cirh.L2Norm %961 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<3072xf32>) -> tensor<f32> loc(#loc223)
    %963 = cirh.MatMul %957, %13 {transpose_a = false, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<3072x768xbf16>) -> tensor<245760x768xbf16> loc(#loc252)
    %964 = cirh.Reshape %963 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc252)
    %965 = cirh.Cast %964 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc253)
    %result_90, %beta_grad_91, %gamma_grad_92 = cirh.LayerNormGrad %965, %478, %arg28, %arg29 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc253)
    %966 = cirh.L2Norm %beta_grad_91 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %967 = cirh.L2Norm %gamma_grad_92 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %968 = cirh.Cast %result_90 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc253)
    %969 = cirh.Add %947, %968 : tensor<120x2048x768xbf16> loc(#loc253)
    %970 = cirh.Reshape %969 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc254)
    %971 = cirh.MatMul %970, %14 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc254)
    %972 = cirh.Reshape %971 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc254)
    %973 = cirh.Reshape %972 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc254)
    %974 = cirh.Transpose %973, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc254)
    %975 = cirh.DotGeneral %974, %443 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc254)
    %976 = cirh.Cast %975 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc255)
    %977 = cirh.Mul %976, %466 : tensor<120x12x2048x2048xf32> loc(#loc255)
    %978 = cirh.Reduce %977 {dimensions = dense<3> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<120x12x2048x2048xf32>) -> tensor<120x12x2048xf32> loc(#loc255)
    %979 = cirh.BroadcastInDim %978 {broadcast_dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<120x12x2048xf32>) -> tensor<120x12x2048x1xf32> loc(#loc255)
    %980 = cirh.BroadcastInDim %979 {broadcast_dimensions = dense<[0, 1, 2, 3]> : tensor<4xi64>} : (tensor<120x12x2048x1xf32>) -> tensor<120x12x2048x2048xf32> loc(#loc255)
    %981 = cirh.Sub %976, %980 : tensor<120x12x2048x2048xf32> loc(#loc255)
    %982 = cirh.Mul %466, %981 : tensor<120x12x2048x2048xf32> loc(#loc255)
    %983 = cirh.Cast %982 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc255)
    %984 = cirh.DotGeneral %983, %451 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc255)
    %985 = cirh.Mul %984, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc255)
    %986 = cirh.Transpose %985, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc256)
    %987 = cirh.Reshape %986 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc256)
    %988 = cirh.Reshape %987 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc257)
    %989 = cirh.MatMul %988, %452 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc257)
    %990 = cirh.Reshape %989 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc257)
    %991 = cirh.DotGeneral %983, %460 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc255)
    %992 = cirh.Transpose %991, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc258)
    %993 = cirh.Reshape %992 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc258)
    %994 = cirh.Reshape %993 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc256)
    %995 = cirh.MatMul %994, %444 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc256)
    %996 = cirh.Reshape %995 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc256)
    %997 = cirh.DotGeneral %467, %974 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc254)
    %998 = cirh.Transpose %997, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc255)
    %999 = cirh.Reshape %998 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc255)
    %1000 = cirh.Reshape %999 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc258)
    %1001 = cirh.MatMul %1000, %15 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc258)
    %1002 = cirh.Reshape %1001 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc258)
    %1003 = cirh.Add %1002, %996 : tensor<120x2048x768xbf16> loc(#loc256)
    %1004 = cirh.Add %1003, %990 : tensor<120x2048x768xbf16> loc(#loc257)
    %1005 = cirh.Cast %1004 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc259)
    %result_93, %beta_grad_94, %gamma_grad_95 = cirh.LayerNormGrad %1005, %433, %arg32, %arg33 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc259)
    %1006 = cirh.L2Norm %beta_grad_94 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1007 = cirh.L2Norm %gamma_grad_95 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1008 = cirh.Reduce %970 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc254)
    %1009 = cirh.BroadcastInDim %1008 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc254)
    %1010 = cirh.Reshape %1009 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc254)
    %1011 = cirh.Cast %1010 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc254)
    %1012 = cirh.L2Norm %1011 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1013 = cirh.Reduce %1000 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc258)
    %1014 = cirh.BroadcastInDim %1013 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc258)
    %1015 = cirh.Reshape %1014 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc258)
    %1016 = cirh.Cast %1015 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc258)
    %1017 = cirh.L2Norm %1016 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1018 = cirh.Reduce %994 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc256)
    %1019 = cirh.BroadcastInDim %1018 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc256)
    %1020 = cirh.Reshape %1019 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc256)
    %1021 = cirh.Cast %1020 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc256)
    %1022 = cirh.L2Norm %1021 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1023 = cirh.Reduce %988 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc257)
    %1024 = cirh.BroadcastInDim %1023 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc257)
    %1025 = cirh.Reshape %1024 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc257)
    %1026 = cirh.Cast %1025 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc257)
    %1027 = cirh.L2Norm %1026 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1028 = cirh.Cast %result_93 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc259)
    %1029 = cirh.Add %969, %1028 : tensor<120x2048x768xbf16> loc(#loc259)
    %1030 = cirh.Reshape %1029 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc260)
    %1031 = cirh.Reduce %1030 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc260)
    %1032 = cirh.BroadcastInDim %1031 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc260)
    %1033 = cirh.Reshape %1032 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc260)
    %1034 = cirh.Cast %1033 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc260)
    %1035 = cirh.L2Norm %1034 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1036 = cirh.MatMul %1030, %16 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc260)
    %1037 = cirh.Reshape %1036 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc260)
    %1038 = cirh.GeluGrad %1037, %424 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc260)
    %1039 = cirh.Reshape %1038 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc261)
    %1040 = cirh.Reduce %1039 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x3072xbf16>) -> tensor<3072xbf16> loc(#loc261)
    %1041 = cirh.BroadcastInDim %1040 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<1x3072xbf16> loc(#loc261)
    %1042 = cirh.Reshape %1041 : (tensor<1x3072xbf16>) -> tensor<3072xbf16> loc(#loc261)
    %1043 = cirh.Cast %1042 {Truncate = false} : tensor<3072xbf16> -> tensor<3072xf32> loc(#loc261)
    %1044 = cirh.L2Norm %1043 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<3072xf32>) -> tensor<f32> loc(#loc223)
    %1045 = cirh.MatMul %1039, %17 {transpose_a = false, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<3072x768xbf16>) -> tensor<245760x768xbf16> loc(#loc261)
    %1046 = cirh.Reshape %1045 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc261)
    %1047 = cirh.Cast %1046 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc262)
    %result_96, %beta_grad_97, %gamma_grad_98 = cirh.LayerNormGrad %1047, %416, %arg36, %arg37 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc262)
    %1048 = cirh.L2Norm %beta_grad_97 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1049 = cirh.L2Norm %gamma_grad_98 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1050 = cirh.Cast %result_96 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc262)
    %1051 = cirh.Add %1029, %1050 : tensor<120x2048x768xbf16> loc(#loc262)
    %1052 = cirh.Reshape %1051 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc263)
    %1053 = cirh.MatMul %1052, %18 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc263)
    %1054 = cirh.Reshape %1053 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc263)
    %1055 = cirh.Reshape %1054 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc263)
    %1056 = cirh.Transpose %1055, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc263)
    %1057 = cirh.DotGeneral %1056, %381 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc263)
    %1058 = cirh.Cast %1057 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc264)
    %1059 = cirh.Mul %1058, %404 : tensor<120x12x2048x2048xf32> loc(#loc264)
    %1060 = cirh.Reduce %1059 {dimensions = dense<3> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<120x12x2048x2048xf32>) -> tensor<120x12x2048xf32> loc(#loc264)
    %1061 = cirh.BroadcastInDim %1060 {broadcast_dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<120x12x2048xf32>) -> tensor<120x12x2048x1xf32> loc(#loc264)
    %1062 = cirh.BroadcastInDim %1061 {broadcast_dimensions = dense<[0, 1, 2, 3]> : tensor<4xi64>} : (tensor<120x12x2048x1xf32>) -> tensor<120x12x2048x2048xf32> loc(#loc264)
    %1063 = cirh.Sub %1058, %1062 : tensor<120x12x2048x2048xf32> loc(#loc264)
    %1064 = cirh.Mul %404, %1063 : tensor<120x12x2048x2048xf32> loc(#loc264)
    %1065 = cirh.Cast %1064 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc264)
    %1066 = cirh.DotGeneral %1065, %389 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc264)
    %1067 = cirh.Mul %1066, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc264)
    %1068 = cirh.Transpose %1067, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc265)
    %1069 = cirh.Reshape %1068 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc265)
    %1070 = cirh.Reshape %1069 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc266)
    %1071 = cirh.MatMul %1070, %390 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc266)
    %1072 = cirh.Reshape %1071 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc266)
    %1073 = cirh.DotGeneral %1065, %398 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc264)
    %1074 = cirh.Transpose %1073, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc267)
    %1075 = cirh.Reshape %1074 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc267)
    %1076 = cirh.Reshape %1075 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc265)
    %1077 = cirh.MatMul %1076, %382 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc265)
    %1078 = cirh.Reshape %1077 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc265)
    %1079 = cirh.DotGeneral %405, %1056 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc263)
    %1080 = cirh.Transpose %1079, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc264)
    %1081 = cirh.Reshape %1080 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc264)
    %1082 = cirh.Reshape %1081 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc267)
    %1083 = cirh.MatMul %1082, %19 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc267)
    %1084 = cirh.Reshape %1083 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc267)
    %1085 = cirh.Add %1084, %1078 : tensor<120x2048x768xbf16> loc(#loc265)
    %1086 = cirh.Add %1085, %1072 : tensor<120x2048x768xbf16> loc(#loc266)
    %1087 = cirh.Cast %1086 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc268)
    %result_99, %beta_grad_100, %gamma_grad_101 = cirh.LayerNormGrad %1087, %371, %arg40, %arg41 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc268)
    %1088 = cirh.L2Norm %beta_grad_100 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1089 = cirh.L2Norm %gamma_grad_101 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1090 = cirh.Reduce %1052 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc263)
    %1091 = cirh.BroadcastInDim %1090 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc263)
    %1092 = cirh.Reshape %1091 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc263)
    %1093 = cirh.Cast %1092 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc263)
    %1094 = cirh.L2Norm %1093 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1095 = cirh.Reduce %1082 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc267)
    %1096 = cirh.BroadcastInDim %1095 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc267)
    %1097 = cirh.Reshape %1096 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc267)
    %1098 = cirh.Cast %1097 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc267)
    %1099 = cirh.L2Norm %1098 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1100 = cirh.Reduce %1076 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc265)
    %1101 = cirh.BroadcastInDim %1100 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc265)
    %1102 = cirh.Reshape %1101 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc265)
    %1103 = cirh.Cast %1102 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc265)
    %1104 = cirh.L2Norm %1103 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1105 = cirh.Reduce %1070 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc266)
    %1106 = cirh.BroadcastInDim %1105 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc266)
    %1107 = cirh.Reshape %1106 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc266)
    %1108 = cirh.Cast %1107 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc266)
    %1109 = cirh.L2Norm %1108 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1110 = cirh.Cast %result_99 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc268)
    %1111 = cirh.Add %1051, %1110 : tensor<120x2048x768xbf16> loc(#loc268)
    %1112 = cirh.Reshape %1111 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc269)
    %1113 = cirh.Reduce %1112 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc269)
    %1114 = cirh.BroadcastInDim %1113 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc269)
    %1115 = cirh.Reshape %1114 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc269)
    %1116 = cirh.Cast %1115 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc269)
    %1117 = cirh.L2Norm %1116 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1118 = cirh.MatMul %1112, %20 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc269)
    %1119 = cirh.Reshape %1118 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc269)
    %1120 = cirh.GeluGrad %1119, %362 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc269)
    %1121 = cirh.Reshape %1120 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc270)
    %1122 = cirh.Reduce %1121 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x3072xbf16>) -> tensor<3072xbf16> loc(#loc270)
    %1123 = cirh.BroadcastInDim %1122 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<1x3072xbf16> loc(#loc270)
    %1124 = cirh.Reshape %1123 : (tensor<1x3072xbf16>) -> tensor<3072xbf16> loc(#loc270)
    %1125 = cirh.Cast %1124 {Truncate = false} : tensor<3072xbf16> -> tensor<3072xf32> loc(#loc270)
    %1126 = cirh.L2Norm %1125 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<3072xf32>) -> tensor<f32> loc(#loc223)
    %1127 = cirh.MatMul %1121, %21 {transpose_a = false, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<3072x768xbf16>) -> tensor<245760x768xbf16> loc(#loc270)
    %1128 = cirh.Reshape %1127 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc270)
    %1129 = cirh.Cast %1128 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc271)
    %result_102, %beta_grad_103, %gamma_grad_104 = cirh.LayerNormGrad %1129, %354, %arg44, %arg45 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc271)
    %1130 = cirh.L2Norm %beta_grad_103 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1131 = cirh.L2Norm %gamma_grad_104 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1132 = cirh.Cast %result_102 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc271)
    %1133 = cirh.Add %1111, %1132 : tensor<120x2048x768xbf16> loc(#loc271)
    %1134 = cirh.Reshape %1133 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc272)
    %1135 = cirh.MatMul %1134, %22 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc272)
    %1136 = cirh.Reshape %1135 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc272)
    %1137 = cirh.Reshape %1136 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc272)
    %1138 = cirh.Transpose %1137, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc272)
    %1139 = cirh.DotGeneral %1138, %319 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc272)
    %1140 = cirh.Cast %1139 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc273)
    %1141 = cirh.Mul %1140, %342 : tensor<120x12x2048x2048xf32> loc(#loc273)
    %1142 = cirh.Reduce %1141 {dimensions = dense<3> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<120x12x2048x2048xf32>) -> tensor<120x12x2048xf32> loc(#loc273)
    %1143 = cirh.BroadcastInDim %1142 {broadcast_dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<120x12x2048xf32>) -> tensor<120x12x2048x1xf32> loc(#loc273)
    %1144 = cirh.BroadcastInDim %1143 {broadcast_dimensions = dense<[0, 1, 2, 3]> : tensor<4xi64>} : (tensor<120x12x2048x1xf32>) -> tensor<120x12x2048x2048xf32> loc(#loc273)
    %1145 = cirh.Sub %1140, %1144 : tensor<120x12x2048x2048xf32> loc(#loc273)
    %1146 = cirh.Mul %342, %1145 : tensor<120x12x2048x2048xf32> loc(#loc273)
    %1147 = cirh.Cast %1146 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc273)
    %1148 = cirh.DotGeneral %1147, %327 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc273)
    %1149 = cirh.Mul %1148, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc273)
    %1150 = cirh.Transpose %1149, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc274)
    %1151 = cirh.Reshape %1150 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc274)
    %1152 = cirh.Reshape %1151 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc275)
    %1153 = cirh.MatMul %1152, %328 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc275)
    %1154 = cirh.Reshape %1153 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc275)
    %1155 = cirh.DotGeneral %1147, %336 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc273)
    %1156 = cirh.Transpose %1155, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc276)
    %1157 = cirh.Reshape %1156 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc276)
    %1158 = cirh.Reshape %1157 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc274)
    %1159 = cirh.MatMul %1158, %320 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc274)
    %1160 = cirh.Reshape %1159 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc274)
    %1161 = cirh.DotGeneral %343, %1138 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc272)
    %1162 = cirh.Transpose %1161, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc273)
    %1163 = cirh.Reshape %1162 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc273)
    %1164 = cirh.Reshape %1163 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc276)
    %1165 = cirh.MatMul %1164, %23 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc276)
    %1166 = cirh.Reshape %1165 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc276)
    %1167 = cirh.Add %1166, %1160 : tensor<120x2048x768xbf16> loc(#loc274)
    %1168 = cirh.Add %1167, %1154 : tensor<120x2048x768xbf16> loc(#loc275)
    %1169 = cirh.Cast %1168 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc277)
    %result_105, %beta_grad_106, %gamma_grad_107 = cirh.LayerNormGrad %1169, %309, %arg48, %arg49 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc277)
    %1170 = cirh.L2Norm %beta_grad_106 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1171 = cirh.L2Norm %gamma_grad_107 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1172 = cirh.Reduce %1134 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc272)
    %1173 = cirh.BroadcastInDim %1172 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc272)
    %1174 = cirh.Reshape %1173 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc272)
    %1175 = cirh.Cast %1174 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc272)
    %1176 = cirh.L2Norm %1175 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1177 = cirh.Reduce %1164 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc276)
    %1178 = cirh.BroadcastInDim %1177 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc276)
    %1179 = cirh.Reshape %1178 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc276)
    %1180 = cirh.Cast %1179 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc276)
    %1181 = cirh.L2Norm %1180 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1182 = cirh.Reduce %1158 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc274)
    %1183 = cirh.BroadcastInDim %1182 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc274)
    %1184 = cirh.Reshape %1183 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc274)
    %1185 = cirh.Cast %1184 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc274)
    %1186 = cirh.L2Norm %1185 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1187 = cirh.Reduce %1152 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc275)
    %1188 = cirh.BroadcastInDim %1187 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc275)
    %1189 = cirh.Reshape %1188 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc275)
    %1190 = cirh.Cast %1189 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc275)
    %1191 = cirh.L2Norm %1190 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1192 = cirh.Cast %result_105 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc277)
    %1193 = cirh.Add %1133, %1192 : tensor<120x2048x768xbf16> loc(#loc277)
    %1194 = cirh.Reshape %1193 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc278)
    %1195 = cirh.Reduce %1194 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc278)
    %1196 = cirh.BroadcastInDim %1195 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc278)
    %1197 = cirh.Reshape %1196 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc278)
    %1198 = cirh.Cast %1197 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc278)
    %1199 = cirh.L2Norm %1198 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1200 = cirh.MatMul %1194, %24 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc278)
    %1201 = cirh.Reshape %1200 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc278)
    %1202 = cirh.GeluGrad %1201, %300 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc278)
    %1203 = cirh.Reshape %1202 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc279)
    %1204 = cirh.Reduce %1203 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x3072xbf16>) -> tensor<3072xbf16> loc(#loc279)
    %1205 = cirh.BroadcastInDim %1204 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<1x3072xbf16> loc(#loc279)
    %1206 = cirh.Reshape %1205 : (tensor<1x3072xbf16>) -> tensor<3072xbf16> loc(#loc279)
    %1207 = cirh.Cast %1206 {Truncate = false} : tensor<3072xbf16> -> tensor<3072xf32> loc(#loc279)
    %1208 = cirh.L2Norm %1207 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<3072xf32>) -> tensor<f32> loc(#loc223)
    %1209 = cirh.MatMul %1203, %25 {transpose_a = false, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<3072x768xbf16>) -> tensor<245760x768xbf16> loc(#loc279)
    %1210 = cirh.Reshape %1209 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc279)
    %1211 = cirh.Cast %1210 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc280)
    %result_108, %beta_grad_109, %gamma_grad_110 = cirh.LayerNormGrad %1211, %292, %arg52, %arg53 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc280)
    %1212 = cirh.L2Norm %beta_grad_109 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1213 = cirh.L2Norm %gamma_grad_110 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1214 = cirh.Cast %result_108 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc280)
    %1215 = cirh.Add %1193, %1214 : tensor<120x2048x768xbf16> loc(#loc280)
    %1216 = cirh.Reshape %1215 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc281)
    %1217 = cirh.MatMul %1216, %26 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc281)
    %1218 = cirh.Reshape %1217 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc281)
    %1219 = cirh.Reshape %1218 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc281)
    %1220 = cirh.Transpose %1219, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc281)
    %1221 = cirh.DotGeneral %1220, %257 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc281)
    %1222 = cirh.Cast %1221 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc282)
    %1223 = cirh.Mul %1222, %280 : tensor<120x12x2048x2048xf32> loc(#loc282)
    %1224 = cirh.Reduce %1223 {dimensions = dense<3> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<120x12x2048x2048xf32>) -> tensor<120x12x2048xf32> loc(#loc282)
    %1225 = cirh.BroadcastInDim %1224 {broadcast_dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<120x12x2048xf32>) -> tensor<120x12x2048x1xf32> loc(#loc282)
    %1226 = cirh.BroadcastInDim %1225 {broadcast_dimensions = dense<[0, 1, 2, 3]> : tensor<4xi64>} : (tensor<120x12x2048x1xf32>) -> tensor<120x12x2048x2048xf32> loc(#loc282)
    %1227 = cirh.Sub %1222, %1226 : tensor<120x12x2048x2048xf32> loc(#loc282)
    %1228 = cirh.Mul %280, %1227 : tensor<120x12x2048x2048xf32> loc(#loc282)
    %1229 = cirh.Cast %1228 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc282)
    %1230 = cirh.DotGeneral %1229, %265 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc282)
    %1231 = cirh.Mul %1230, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc282)
    %1232 = cirh.Transpose %1231, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc283)
    %1233 = cirh.Reshape %1232 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc283)
    %1234 = cirh.Reshape %1233 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc284)
    %1235 = cirh.MatMul %1234, %266 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc284)
    %1236 = cirh.Reshape %1235 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc284)
    %1237 = cirh.DotGeneral %1229, %274 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc282)
    %1238 = cirh.Transpose %1237, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc285)
    %1239 = cirh.Reshape %1238 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc285)
    %1240 = cirh.Reshape %1239 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc283)
    %1241 = cirh.MatMul %1240, %258 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc283)
    %1242 = cirh.Reshape %1241 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc283)
    %1243 = cirh.DotGeneral %281, %1220 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc281)
    %1244 = cirh.Transpose %1243, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc282)
    %1245 = cirh.Reshape %1244 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc282)
    %1246 = cirh.Reshape %1245 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc285)
    %1247 = cirh.MatMul %1246, %27 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc285)
    %1248 = cirh.Reshape %1247 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc285)
    %1249 = cirh.Add %1248, %1242 : tensor<120x2048x768xbf16> loc(#loc283)
    %1250 = cirh.Add %1249, %1236 : tensor<120x2048x768xbf16> loc(#loc284)
    %1251 = cirh.Cast %1250 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc286)
    %result_111, %beta_grad_112, %gamma_grad_113 = cirh.LayerNormGrad %1251, %247, %arg56, %arg57 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc286)
    %1252 = cirh.L2Norm %beta_grad_112 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1253 = cirh.L2Norm %gamma_grad_113 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1254 = cirh.Reduce %1216 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc281)
    %1255 = cirh.BroadcastInDim %1254 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc281)
    %1256 = cirh.Reshape %1255 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc281)
    %1257 = cirh.Cast %1256 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc281)
    %1258 = cirh.L2Norm %1257 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1259 = cirh.Reduce %1246 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc285)
    %1260 = cirh.BroadcastInDim %1259 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc285)
    %1261 = cirh.Reshape %1260 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc285)
    %1262 = cirh.Cast %1261 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc285)
    %1263 = cirh.L2Norm %1262 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1264 = cirh.Reduce %1240 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc283)
    %1265 = cirh.BroadcastInDim %1264 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc283)
    %1266 = cirh.Reshape %1265 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc283)
    %1267 = cirh.Cast %1266 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc283)
    %1268 = cirh.L2Norm %1267 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1269 = cirh.Reduce %1234 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc284)
    %1270 = cirh.BroadcastInDim %1269 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc284)
    %1271 = cirh.Reshape %1270 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc284)
    %1272 = cirh.Cast %1271 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc284)
    %1273 = cirh.L2Norm %1272 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1274 = cirh.Cast %result_111 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc286)
    %1275 = cirh.Add %1215, %1274 : tensor<120x2048x768xbf16> loc(#loc286)
    %1276 = cirh.Reshape %1275 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc287)
    %1277 = cirh.Reduce %1276 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc287)
    %1278 = cirh.BroadcastInDim %1277 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc287)
    %1279 = cirh.Reshape %1278 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc287)
    %1280 = cirh.Cast %1279 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc287)
    %1281 = cirh.L2Norm %1280 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1282 = cirh.MatMul %1276, %28 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc287)
    %1283 = cirh.Reshape %1282 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc287)
    %1284 = cirh.GeluGrad %1283, %238 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc287)
    %1285 = cirh.Reshape %1284 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc288)
    %1286 = cirh.Reduce %1285 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x3072xbf16>) -> tensor<3072xbf16> loc(#loc288)
    %1287 = cirh.BroadcastInDim %1286 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<1x3072xbf16> loc(#loc288)
    %1288 = cirh.Reshape %1287 : (tensor<1x3072xbf16>) -> tensor<3072xbf16> loc(#loc288)
    %1289 = cirh.Cast %1288 {Truncate = false} : tensor<3072xbf16> -> tensor<3072xf32> loc(#loc288)
    %1290 = cirh.L2Norm %1289 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<3072xf32>) -> tensor<f32> loc(#loc223)
    %1291 = cirh.MatMul %1285, %29 {transpose_a = false, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<3072x768xbf16>) -> tensor<245760x768xbf16> loc(#loc288)
    %1292 = cirh.Reshape %1291 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc288)
    %1293 = cirh.Cast %1292 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc289)
    %result_114, %beta_grad_115, %gamma_grad_116 = cirh.LayerNormGrad %1293, %230, %arg60, %arg61 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc289)
    %1294 = cirh.L2Norm %beta_grad_115 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1295 = cirh.L2Norm %gamma_grad_116 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1296 = cirh.Cast %result_114 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc289)
    %1297 = cirh.Add %1275, %1296 : tensor<120x2048x768xbf16> loc(#loc289)
    %1298 = cirh.Reshape %1297 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc290)
    %1299 = cirh.MatMul %1298, %30 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc290)
    %1300 = cirh.Reshape %1299 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc290)
    %1301 = cirh.Reshape %1300 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc290)
    %1302 = cirh.Transpose %1301, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc290)
    %1303 = cirh.DotGeneral %1302, %195 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc290)
    %1304 = cirh.Cast %1303 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc291)
    %1305 = cirh.Mul %1304, %218 : tensor<120x12x2048x2048xf32> loc(#loc291)
    %1306 = cirh.Reduce %1305 {dimensions = dense<3> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<120x12x2048x2048xf32>) -> tensor<120x12x2048xf32> loc(#loc291)
    %1307 = cirh.BroadcastInDim %1306 {broadcast_dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<120x12x2048xf32>) -> tensor<120x12x2048x1xf32> loc(#loc291)
    %1308 = cirh.BroadcastInDim %1307 {broadcast_dimensions = dense<[0, 1, 2, 3]> : tensor<4xi64>} : (tensor<120x12x2048x1xf32>) -> tensor<120x12x2048x2048xf32> loc(#loc291)
    %1309 = cirh.Sub %1304, %1308 : tensor<120x12x2048x2048xf32> loc(#loc291)
    %1310 = cirh.Mul %218, %1309 : tensor<120x12x2048x2048xf32> loc(#loc291)
    %1311 = cirh.Cast %1310 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc291)
    %1312 = cirh.DotGeneral %1311, %203 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc291)
    %1313 = cirh.Mul %1312, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc291)
    %1314 = cirh.Transpose %1313, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc292)
    %1315 = cirh.Reshape %1314 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc292)
    %1316 = cirh.Reshape %1315 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc293)
    %1317 = cirh.MatMul %1316, %204 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc293)
    %1318 = cirh.Reshape %1317 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc293)
    %1319 = cirh.DotGeneral %1311, %212 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc291)
    %1320 = cirh.Transpose %1319, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc294)
    %1321 = cirh.Reshape %1320 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc294)
    %1322 = cirh.Reshape %1321 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc292)
    %1323 = cirh.MatMul %1322, %196 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc292)
    %1324 = cirh.Reshape %1323 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc292)
    %1325 = cirh.DotGeneral %219, %1302 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc290)
    %1326 = cirh.Transpose %1325, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc291)
    %1327 = cirh.Reshape %1326 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc291)
    %1328 = cirh.Reshape %1327 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc294)
    %1329 = cirh.MatMul %1328, %31 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc294)
    %1330 = cirh.Reshape %1329 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc294)
    %1331 = cirh.Add %1330, %1324 : tensor<120x2048x768xbf16> loc(#loc292)
    %1332 = cirh.Add %1331, %1318 : tensor<120x2048x768xbf16> loc(#loc293)
    %1333 = cirh.Cast %1332 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc295)
    %result_117, %beta_grad_118, %gamma_grad_119 = cirh.LayerNormGrad %1333, %185, %arg64, %arg65 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc295)
    %1334 = cirh.L2Norm %beta_grad_118 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1335 = cirh.L2Norm %gamma_grad_119 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1336 = cirh.Reduce %1298 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc290)
    %1337 = cirh.BroadcastInDim %1336 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc290)
    %1338 = cirh.Reshape %1337 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc290)
    %1339 = cirh.Cast %1338 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc290)
    %1340 = cirh.L2Norm %1339 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1341 = cirh.Reduce %1328 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc294)
    %1342 = cirh.BroadcastInDim %1341 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc294)
    %1343 = cirh.Reshape %1342 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc294)
    %1344 = cirh.Cast %1343 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc294)
    %1345 = cirh.L2Norm %1344 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1346 = cirh.Reduce %1322 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc292)
    %1347 = cirh.BroadcastInDim %1346 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc292)
    %1348 = cirh.Reshape %1347 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc292)
    %1349 = cirh.Cast %1348 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc292)
    %1350 = cirh.L2Norm %1349 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1351 = cirh.Reduce %1316 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc293)
    %1352 = cirh.BroadcastInDim %1351 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc293)
    %1353 = cirh.Reshape %1352 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc293)
    %1354 = cirh.Cast %1353 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc293)
    %1355 = cirh.L2Norm %1354 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1356 = cirh.Cast %result_117 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc295)
    %1357 = cirh.Add %1297, %1356 : tensor<120x2048x768xbf16> loc(#loc295)
    %1358 = cirh.Reshape %1357 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc296)
    %1359 = cirh.Reduce %1358 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc296)
    %1360 = cirh.BroadcastInDim %1359 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc296)
    %1361 = cirh.Reshape %1360 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc296)
    %1362 = cirh.Cast %1361 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc296)
    %1363 = cirh.L2Norm %1362 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1364 = cirh.MatMul %1358, %32 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc296)
    %1365 = cirh.Reshape %1364 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc296)
    %1366 = cirh.GeluGrad %1365, %176 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc296)
    %1367 = cirh.Reshape %1366 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc297)
    %1368 = cirh.Reduce %1367 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x3072xbf16>) -> tensor<3072xbf16> loc(#loc297)
    %1369 = cirh.BroadcastInDim %1368 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<1x3072xbf16> loc(#loc297)
    %1370 = cirh.Reshape %1369 : (tensor<1x3072xbf16>) -> tensor<3072xbf16> loc(#loc297)
    %1371 = cirh.Cast %1370 {Truncate = false} : tensor<3072xbf16> -> tensor<3072xf32> loc(#loc297)
    %1372 = cirh.L2Norm %1371 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<3072xf32>) -> tensor<f32> loc(#loc223)
    %1373 = cirh.MatMul %1367, %33 {transpose_a = false, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<3072x768xbf16>) -> tensor<245760x768xbf16> loc(#loc297)
    %1374 = cirh.Reshape %1373 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc297)
    %1375 = cirh.Cast %1374 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc298)
    %result_120, %beta_grad_121, %gamma_grad_122 = cirh.LayerNormGrad %1375, %168, %arg68, %arg69 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc298)
    %1376 = cirh.L2Norm %beta_grad_121 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1377 = cirh.L2Norm %gamma_grad_122 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1378 = cirh.Cast %result_120 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc298)
    %1379 = cirh.Add %1357, %1378 : tensor<120x2048x768xbf16> loc(#loc298)
    %1380 = cirh.Reshape %1379 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc299)
    %1381 = cirh.MatMul %1380, %34 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc299)
    %1382 = cirh.Reshape %1381 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc299)
    %1383 = cirh.Reshape %1382 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc299)
    %1384 = cirh.Transpose %1383, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc299)
    %1385 = cirh.DotGeneral %1384, %133 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc299)
    %1386 = cirh.Cast %1385 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc300)
    %1387 = cirh.Mul %1386, %156 : tensor<120x12x2048x2048xf32> loc(#loc300)
    %1388 = cirh.Reduce %1387 {dimensions = dense<3> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<120x12x2048x2048xf32>) -> tensor<120x12x2048xf32> loc(#loc300)
    %1389 = cirh.BroadcastInDim %1388 {broadcast_dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<120x12x2048xf32>) -> tensor<120x12x2048x1xf32> loc(#loc300)
    %1390 = cirh.BroadcastInDim %1389 {broadcast_dimensions = dense<[0, 1, 2, 3]> : tensor<4xi64>} : (tensor<120x12x2048x1xf32>) -> tensor<120x12x2048x2048xf32> loc(#loc300)
    %1391 = cirh.Sub %1386, %1390 : tensor<120x12x2048x2048xf32> loc(#loc300)
    %1392 = cirh.Mul %156, %1391 : tensor<120x12x2048x2048xf32> loc(#loc300)
    %1393 = cirh.Cast %1392 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc300)
    %1394 = cirh.DotGeneral %1393, %141 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc300)
    %1395 = cirh.Mul %1394, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc300)
    %1396 = cirh.Transpose %1395, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc301)
    %1397 = cirh.Reshape %1396 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc301)
    %1398 = cirh.Reshape %1397 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc302)
    %1399 = cirh.MatMul %1398, %142 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc302)
    %1400 = cirh.Reshape %1399 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc302)
    %1401 = cirh.DotGeneral %1393, %150 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc300)
    %1402 = cirh.Transpose %1401, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc303)
    %1403 = cirh.Reshape %1402 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc303)
    %1404 = cirh.Reshape %1403 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc301)
    %1405 = cirh.MatMul %1404, %134 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc301)
    %1406 = cirh.Reshape %1405 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc301)
    %1407 = cirh.DotGeneral %157, %1384 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc299)
    %1408 = cirh.Transpose %1407, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc300)
    %1409 = cirh.Reshape %1408 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc300)
    %1410 = cirh.Reshape %1409 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc303)
    %1411 = cirh.MatMul %1410, %35 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc303)
    %1412 = cirh.Reshape %1411 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc303)
    %1413 = cirh.Add %1412, %1406 : tensor<120x2048x768xbf16> loc(#loc301)
    %1414 = cirh.Add %1413, %1400 : tensor<120x2048x768xbf16> loc(#loc302)
    %1415 = cirh.Cast %1414 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc304)
    %result_123, %beta_grad_124, %gamma_grad_125 = cirh.LayerNormGrad %1415, %123, %arg72, %arg73 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc304)
    %1416 = cirh.L2Norm %beta_grad_124 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1417 = cirh.L2Norm %gamma_grad_125 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1418 = cirh.Reduce %1380 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc299)
    %1419 = cirh.BroadcastInDim %1418 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc299)
    %1420 = cirh.Reshape %1419 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc299)
    %1421 = cirh.Cast %1420 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc299)
    %1422 = cirh.L2Norm %1421 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1423 = cirh.Reduce %1410 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc303)
    %1424 = cirh.BroadcastInDim %1423 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc303)
    %1425 = cirh.Reshape %1424 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc303)
    %1426 = cirh.Cast %1425 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc303)
    %1427 = cirh.L2Norm %1426 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1428 = cirh.Reduce %1404 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc301)
    %1429 = cirh.BroadcastInDim %1428 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc301)
    %1430 = cirh.Reshape %1429 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc301)
    %1431 = cirh.Cast %1430 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc301)
    %1432 = cirh.L2Norm %1431 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1433 = cirh.Reduce %1398 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc302)
    %1434 = cirh.BroadcastInDim %1433 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc302)
    %1435 = cirh.Reshape %1434 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc302)
    %1436 = cirh.Cast %1435 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc302)
    %1437 = cirh.L2Norm %1436 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1438 = cirh.Cast %result_123 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc304)
    %1439 = cirh.Add %1379, %1438 : tensor<120x2048x768xbf16> loc(#loc304)
    %1440 = cirh.Reshape %1439 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc305)
    %1441 = cirh.Reduce %1440 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc305)
    %1442 = cirh.BroadcastInDim %1441 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc305)
    %1443 = cirh.Reshape %1442 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc305)
    %1444 = cirh.Cast %1443 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc305)
    %1445 = cirh.L2Norm %1444 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1446 = cirh.MatMul %1440, %36 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc305)
    %1447 = cirh.Reshape %1446 : (tensor<245760x3072xbf16>) -> tensor<120x2048x3072xbf16> loc(#loc305)
    %1448 = cirh.GeluGrad %1447, %114 {approximation = "NONE"} : tensor<120x2048x3072xbf16> loc(#loc305)
    %1449 = cirh.Reshape %1448 : (tensor<120x2048x3072xbf16>) -> tensor<245760x3072xbf16> loc(#loc306)
    %1450 = cirh.Reduce %1449 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x3072xbf16>) -> tensor<3072xbf16> loc(#loc306)
    %1451 = cirh.BroadcastInDim %1450 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<3072xbf16>) -> tensor<1x3072xbf16> loc(#loc306)
    %1452 = cirh.Reshape %1451 : (tensor<1x3072xbf16>) -> tensor<3072xbf16> loc(#loc306)
    %1453 = cirh.Cast %1452 {Truncate = false} : tensor<3072xbf16> -> tensor<3072xf32> loc(#loc306)
    %1454 = cirh.L2Norm %1453 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<3072xf32>) -> tensor<f32> loc(#loc223)
    %1455 = cirh.MatMul %1449, %37 {transpose_a = false, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<3072x768xbf16>) -> tensor<245760x768xbf16> loc(#loc306)
    %1456 = cirh.Reshape %1455 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc306)
    %1457 = cirh.Cast %1456 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc307)
    %result_126, %beta_grad_127, %gamma_grad_128 = cirh.LayerNormGrad %1457, %106, %arg76, %arg77 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc307)
    %1458 = cirh.L2Norm %beta_grad_127 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1459 = cirh.L2Norm %gamma_grad_128 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1460 = cirh.Cast %result_126 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc307)
    %1461 = cirh.Add %1439, %1460 : tensor<120x2048x768xbf16> loc(#loc307)
    %1462 = cirh.Reshape %1461 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc308)
    %1463 = cirh.MatMul %1462, %38 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc308)
    %1464 = cirh.Reshape %1463 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc308)
    %1465 = cirh.Reshape %1464 : (tensor<120x2048x768xbf16>) -> tensor<120x2048x12x64xbf16> loc(#loc308)
    %1466 = cirh.Transpose %1465, %cst_57 : (tensor<120x2048x12x64xbf16>, tensor<4xi64>) -> tensor<120x12x2048x64xbf16> loc(#loc308)
    %1467 = cirh.DotGeneral %1466, %61 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<3> : tensor<1xi64>} : (tensor<120x12x2048x64xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x2048xbf16> loc(#loc308)
    %1468 = cirh.Cast %1467 {Truncate = false} : tensor<120x12x2048x2048xbf16> -> tensor<120x12x2048x2048xf32> loc(#loc309)
    %1469 = cirh.Mul %1468, %94 : tensor<120x12x2048x2048xf32> loc(#loc309)
    %1470 = cirh.Reduce %1469 {dimensions = dense<3> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<120x12x2048x2048xf32>) -> tensor<120x12x2048xf32> loc(#loc309)
    %1471 = cirh.BroadcastInDim %1470 {broadcast_dimensions = dense<[0, 1, 2]> : tensor<3xi64>} : (tensor<120x12x2048xf32>) -> tensor<120x12x2048x1xf32> loc(#loc309)
    %1472 = cirh.BroadcastInDim %1471 {broadcast_dimensions = dense<[0, 1, 2, 3]> : tensor<4xi64>} : (tensor<120x12x2048x1xf32>) -> tensor<120x12x2048x2048xf32> loc(#loc309)
    %1473 = cirh.Sub %1468, %1472 : tensor<120x12x2048x2048xf32> loc(#loc309)
    %1474 = cirh.Mul %94, %1473 : tensor<120x12x2048x2048xf32> loc(#loc309)
    %1475 = cirh.Cast %1474 {Truncate = false} : tensor<120x12x2048x2048xf32> -> tensor<120x12x2048x2048xbf16> loc(#loc309)
    %1476 = cirh.DotGeneral %1475, %78 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<3> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc309)
    %1477 = cirh.Mul %1476, %cst_53 : tensor<120x12x2048x64xbf16> loc(#loc309)
    %1478 = cirh.Transpose %1477, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc310)
    %1479 = cirh.Reshape %1478 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc310)
    %1480 = cirh.Reshape %1479 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc311)
    %1481 = cirh.MatMul %1480, %79 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc311)
    %1482 = cirh.Reshape %1481 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc311)
    %1483 = cirh.DotGeneral %1475, %87 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc309)
    %1484 = cirh.Transpose %1483, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc312)
    %1485 = cirh.Reshape %1484 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc312)
    %1486 = cirh.Reshape %1485 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc310)
    %1487 = cirh.MatMul %1486, %71 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc310)
    %1488 = cirh.Reshape %1487 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc310)
    %1489 = cirh.DotGeneral %95, %1466 {lhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, lhs_contracting_dimensions = dense<2> : tensor<1xi64>, rhs_batching_dimensions = dense<[0, 1]> : tensor<2xi64>, rhs_contracting_dimensions = dense<2> : tensor<1xi64>} : (tensor<120x12x2048x2048xbf16>, tensor<120x12x2048x64xbf16>) -> tensor<120x12x2048x64xbf16> loc(#loc308)
    %1490 = cirh.Transpose %1489, %cst_57 : (tensor<120x12x2048x64xbf16>, tensor<4xi64>) -> tensor<120x2048x12x64xbf16> loc(#loc309)
    %1491 = cirh.Reshape %1490 : (tensor<120x2048x12x64xbf16>) -> tensor<120x2048x768xbf16> loc(#loc309)
    %1492 = cirh.Reshape %1491 : (tensor<120x2048x768xbf16>) -> tensor<245760x768xbf16> loc(#loc312)
    %1493 = cirh.MatMul %1492, %39 {transpose_a = false, transpose_b = false} : (tensor<245760x768xbf16>, tensor<768x768xbf16>) -> tensor<245760x768xbf16> loc(#loc312)
    %1494 = cirh.Reshape %1493 : (tensor<245760x768xbf16>) -> tensor<120x2048x768xbf16> loc(#loc312)
    %1495 = cirh.Add %1494, %1488 : tensor<120x2048x768xbf16> loc(#loc310)
    %1496 = cirh.Add %1495, %1482 : tensor<120x2048x768xbf16> loc(#loc311)
    %1497 = cirh.Cast %1496 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc313)
    %result_129, %beta_grad_130, %gamma_grad_131 = cirh.LayerNormGrad %1497, %51, %arg80, %arg81 {epsilon = 9.99999974E-6 : f32} : (tensor<120x2048x768xf32>, tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) -> (tensor<120x2048x768xf32>, tensor<768xf32>, tensor<768xf32>) loc(#loc313)
    %1498 = cirh.L2Norm %beta_grad_130 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1499 = cirh.L2Norm %gamma_grad_131 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1500 = cirh.Reduce %1462 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc308)
    %1501 = cirh.BroadcastInDim %1500 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc308)
    %1502 = cirh.Reshape %1501 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc308)
    %1503 = cirh.Cast %1502 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc308)
    %1504 = cirh.L2Norm %1503 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1505 = cirh.Reduce %1492 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc312)
    %1506 = cirh.BroadcastInDim %1505 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc312)
    %1507 = cirh.Reshape %1506 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc312)
    %1508 = cirh.Cast %1507 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc312)
    %1509 = cirh.L2Norm %1508 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1510 = cirh.Reduce %1486 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc310)
    %1511 = cirh.BroadcastInDim %1510 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc310)
    %1512 = cirh.Reshape %1511 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc310)
    %1513 = cirh.Cast %1512 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc310)
    %1514 = cirh.L2Norm %1513 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1515 = cirh.Reduce %1480 {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760x768xbf16>) -> tensor<768xbf16> loc(#loc311)
    %1516 = cirh.BroadcastInDim %1515 {broadcast_dimensions = dense<1> : tensor<1xi64>} : (tensor<768xbf16>) -> tensor<1x768xbf16> loc(#loc311)
    %1517 = cirh.Reshape %1516 : (tensor<1x768xbf16>) -> tensor<768xbf16> loc(#loc311)
    %1518 = cirh.Cast %1517 {Truncate = false} : tensor<768xbf16> -> tensor<768xf32> loc(#loc311)
    %1519 = cirh.L2Norm %1518 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<768xf32>) -> tensor<f32> loc(#loc223)
    %1520 = cirh.MatMul %702, %674 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc224)
    %1521 = cirh.Cast %1520 {Truncate = false} : tensor<768x3072xbf16> -> tensor<768x3072xf32> loc(#loc224)
    %1522 = cirh.L2Norm %1521 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x3072xf32>) -> tensor<f32> loc(#loc223)
    %1523 = cirh.MatMul %711, %667 {transpose_a = true, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<245760x768xbf16>) -> tensor<3072x768xbf16> loc(#loc225)
    %1524 = cirh.Cast %1523 {Truncate = false} : tensor<3072x768xbf16> -> tensor<3072x768xf32> loc(#loc225)
    %1525 = cirh.L2Norm %1524 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<3072x768xf32>) -> tensor<f32> loc(#loc223)
    %1526 = cirh.MatMul %724, %657 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc227)
    %1527 = cirh.Cast %1526 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc227)
    %1528 = cirh.L2Norm %1527 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1529 = cirh.MatMul %754, %622 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc231)
    %1530 = cirh.Cast %1529 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc231)
    %1531 = cirh.L2Norm %1530 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1532 = cirh.MatMul %748, %622 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc229)
    %1533 = cirh.Cast %1532 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc229)
    %1534 = cirh.L2Norm %1533 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1535 = cirh.MatMul %742, %622 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc230)
    %1536 = cirh.Cast %1535 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc230)
    %1537 = cirh.L2Norm %1536 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1538 = cirh.MatMul %784, %612 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc233)
    %1539 = cirh.Cast %1538 {Truncate = false} : tensor<768x3072xbf16> -> tensor<768x3072xf32> loc(#loc233)
    %1540 = cirh.L2Norm %1539 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x3072xf32>) -> tensor<f32> loc(#loc223)
    %1541 = cirh.MatMul %793, %605 {transpose_a = true, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<245760x768xbf16>) -> tensor<3072x768xbf16> loc(#loc234)
    %1542 = cirh.Cast %1541 {Truncate = false} : tensor<3072x768xbf16> -> tensor<3072x768xf32> loc(#loc234)
    %1543 = cirh.L2Norm %1542 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<3072x768xf32>) -> tensor<f32> loc(#loc223)
    %1544 = cirh.MatMul %806, %595 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc236)
    %1545 = cirh.Cast %1544 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc236)
    %1546 = cirh.L2Norm %1545 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1547 = cirh.MatMul %836, %560 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc240)
    %1548 = cirh.Cast %1547 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc240)
    %1549 = cirh.L2Norm %1548 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1550 = cirh.MatMul %830, %560 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc238)
    %1551 = cirh.Cast %1550 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc238)
    %1552 = cirh.L2Norm %1551 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1553 = cirh.MatMul %824, %560 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc239)
    %1554 = cirh.Cast %1553 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc239)
    %1555 = cirh.L2Norm %1554 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1556 = cirh.MatMul %866, %550 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc242)
    %1557 = cirh.Cast %1556 {Truncate = false} : tensor<768x3072xbf16> -> tensor<768x3072xf32> loc(#loc242)
    %1558 = cirh.L2Norm %1557 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x3072xf32>) -> tensor<f32> loc(#loc223)
    %1559 = cirh.MatMul %875, %543 {transpose_a = true, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<245760x768xbf16>) -> tensor<3072x768xbf16> loc(#loc243)
    %1560 = cirh.Cast %1559 {Truncate = false} : tensor<3072x768xbf16> -> tensor<3072x768xf32> loc(#loc243)
    %1561 = cirh.L2Norm %1560 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<3072x768xf32>) -> tensor<f32> loc(#loc223)
    %1562 = cirh.MatMul %888, %533 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc245)
    %1563 = cirh.Cast %1562 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc245)
    %1564 = cirh.L2Norm %1563 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1565 = cirh.MatMul %918, %498 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc249)
    %1566 = cirh.Cast %1565 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc249)
    %1567 = cirh.L2Norm %1566 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1568 = cirh.MatMul %912, %498 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc247)
    %1569 = cirh.Cast %1568 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc247)
    %1570 = cirh.L2Norm %1569 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1571 = cirh.MatMul %906, %498 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc248)
    %1572 = cirh.Cast %1571 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc248)
    %1573 = cirh.L2Norm %1572 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1574 = cirh.MatMul %948, %488 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc251)
    %1575 = cirh.Cast %1574 {Truncate = false} : tensor<768x3072xbf16> -> tensor<768x3072xf32> loc(#loc251)
    %1576 = cirh.L2Norm %1575 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x3072xf32>) -> tensor<f32> loc(#loc223)
    %1577 = cirh.MatMul %957, %481 {transpose_a = true, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<245760x768xbf16>) -> tensor<3072x768xbf16> loc(#loc252)
    %1578 = cirh.Cast %1577 {Truncate = false} : tensor<3072x768xbf16> -> tensor<3072x768xf32> loc(#loc252)
    %1579 = cirh.L2Norm %1578 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<3072x768xf32>) -> tensor<f32> loc(#loc223)
    %1580 = cirh.MatMul %970, %471 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc254)
    %1581 = cirh.Cast %1580 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc254)
    %1582 = cirh.L2Norm %1581 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1583 = cirh.MatMul %1000, %436 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc258)
    %1584 = cirh.Cast %1583 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc258)
    %1585 = cirh.L2Norm %1584 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1586 = cirh.MatMul %994, %436 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc256)
    %1587 = cirh.Cast %1586 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc256)
    %1588 = cirh.L2Norm %1587 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1589 = cirh.MatMul %988, %436 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc257)
    %1590 = cirh.Cast %1589 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc257)
    %1591 = cirh.L2Norm %1590 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1592 = cirh.MatMul %1030, %426 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc260)
    %1593 = cirh.Cast %1592 {Truncate = false} : tensor<768x3072xbf16> -> tensor<768x3072xf32> loc(#loc260)
    %1594 = cirh.L2Norm %1593 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x3072xf32>) -> tensor<f32> loc(#loc223)
    %1595 = cirh.MatMul %1039, %419 {transpose_a = true, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<245760x768xbf16>) -> tensor<3072x768xbf16> loc(#loc261)
    %1596 = cirh.Cast %1595 {Truncate = false} : tensor<3072x768xbf16> -> tensor<3072x768xf32> loc(#loc261)
    %1597 = cirh.L2Norm %1596 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<3072x768xf32>) -> tensor<f32> loc(#loc223)
    %1598 = cirh.MatMul %1052, %409 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc263)
    %1599 = cirh.Cast %1598 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc263)
    %1600 = cirh.L2Norm %1599 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1601 = cirh.MatMul %1082, %374 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc267)
    %1602 = cirh.Cast %1601 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc267)
    %1603 = cirh.L2Norm %1602 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1604 = cirh.MatMul %1076, %374 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc265)
    %1605 = cirh.Cast %1604 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc265)
    %1606 = cirh.L2Norm %1605 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1607 = cirh.MatMul %1070, %374 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc266)
    %1608 = cirh.Cast %1607 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc266)
    %1609 = cirh.L2Norm %1608 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1610 = cirh.MatMul %1112, %364 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc269)
    %1611 = cirh.Cast %1610 {Truncate = false} : tensor<768x3072xbf16> -> tensor<768x3072xf32> loc(#loc269)
    %1612 = cirh.L2Norm %1611 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x3072xf32>) -> tensor<f32> loc(#loc223)
    %1613 = cirh.MatMul %1121, %357 {transpose_a = true, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<245760x768xbf16>) -> tensor<3072x768xbf16> loc(#loc270)
    %1614 = cirh.Cast %1613 {Truncate = false} : tensor<3072x768xbf16> -> tensor<3072x768xf32> loc(#loc270)
    %1615 = cirh.L2Norm %1614 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<3072x768xf32>) -> tensor<f32> loc(#loc223)
    %1616 = cirh.MatMul %1134, %347 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc272)
    %1617 = cirh.Cast %1616 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc272)
    %1618 = cirh.L2Norm %1617 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1619 = cirh.MatMul %1164, %312 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc276)
    %1620 = cirh.Cast %1619 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc276)
    %1621 = cirh.L2Norm %1620 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1622 = cirh.MatMul %1158, %312 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc274)
    %1623 = cirh.Cast %1622 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc274)
    %1624 = cirh.L2Norm %1623 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1625 = cirh.MatMul %1152, %312 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc275)
    %1626 = cirh.Cast %1625 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc275)
    %1627 = cirh.L2Norm %1626 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1628 = cirh.MatMul %1194, %302 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc278)
    %1629 = cirh.Cast %1628 {Truncate = false} : tensor<768x3072xbf16> -> tensor<768x3072xf32> loc(#loc278)
    %1630 = cirh.L2Norm %1629 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x3072xf32>) -> tensor<f32> loc(#loc223)
    %1631 = cirh.MatMul %1203, %295 {transpose_a = true, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<245760x768xbf16>) -> tensor<3072x768xbf16> loc(#loc279)
    %1632 = cirh.Cast %1631 {Truncate = false} : tensor<3072x768xbf16> -> tensor<3072x768xf32> loc(#loc279)
    %1633 = cirh.L2Norm %1632 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<3072x768xf32>) -> tensor<f32> loc(#loc223)
    %1634 = cirh.MatMul %1216, %285 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc281)
    %1635 = cirh.Cast %1634 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc281)
    %1636 = cirh.L2Norm %1635 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1637 = cirh.MatMul %1246, %250 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc285)
    %1638 = cirh.Cast %1637 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc285)
    %1639 = cirh.L2Norm %1638 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1640 = cirh.MatMul %1240, %250 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc283)
    %1641 = cirh.Cast %1640 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc283)
    %1642 = cirh.L2Norm %1641 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1643 = cirh.MatMul %1234, %250 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc284)
    %1644 = cirh.Cast %1643 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc284)
    %1645 = cirh.L2Norm %1644 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1646 = cirh.MatMul %1276, %240 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc287)
    %1647 = cirh.Cast %1646 {Truncate = false} : tensor<768x3072xbf16> -> tensor<768x3072xf32> loc(#loc287)
    %1648 = cirh.L2Norm %1647 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x3072xf32>) -> tensor<f32> loc(#loc223)
    %1649 = cirh.MatMul %1285, %233 {transpose_a = true, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<245760x768xbf16>) -> tensor<3072x768xbf16> loc(#loc288)
    %1650 = cirh.Cast %1649 {Truncate = false} : tensor<3072x768xbf16> -> tensor<3072x768xf32> loc(#loc288)
    %1651 = cirh.L2Norm %1650 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<3072x768xf32>) -> tensor<f32> loc(#loc223)
    %1652 = cirh.MatMul %1298, %223 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc290)
    %1653 = cirh.Cast %1652 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc290)
    %1654 = cirh.L2Norm %1653 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1655 = cirh.MatMul %1328, %188 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc294)
    %1656 = cirh.Cast %1655 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc294)
    %1657 = cirh.L2Norm %1656 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1658 = cirh.MatMul %1322, %188 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc292)
    %1659 = cirh.Cast %1658 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc292)
    %1660 = cirh.L2Norm %1659 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1661 = cirh.MatMul %1316, %188 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc293)
    %1662 = cirh.Cast %1661 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc293)
    %1663 = cirh.L2Norm %1662 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1664 = cirh.MatMul %1358, %178 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc296)
    %1665 = cirh.Cast %1664 {Truncate = false} : tensor<768x3072xbf16> -> tensor<768x3072xf32> loc(#loc296)
    %1666 = cirh.L2Norm %1665 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x3072xf32>) -> tensor<f32> loc(#loc223)
    %1667 = cirh.MatMul %1367, %171 {transpose_a = true, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<245760x768xbf16>) -> tensor<3072x768xbf16> loc(#loc297)
    %1668 = cirh.Cast %1667 {Truncate = false} : tensor<3072x768xbf16> -> tensor<3072x768xf32> loc(#loc297)
    %1669 = cirh.L2Norm %1668 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<3072x768xf32>) -> tensor<f32> loc(#loc223)
    %1670 = cirh.MatMul %1380, %161 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc299)
    %1671 = cirh.Cast %1670 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc299)
    %1672 = cirh.L2Norm %1671 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1673 = cirh.MatMul %1410, %126 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc303)
    %1674 = cirh.Cast %1673 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc303)
    %1675 = cirh.L2Norm %1674 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1676 = cirh.MatMul %1404, %126 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc301)
    %1677 = cirh.Cast %1676 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc301)
    %1678 = cirh.L2Norm %1677 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1679 = cirh.MatMul %1398, %126 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc302)
    %1680 = cirh.Cast %1679 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc302)
    %1681 = cirh.L2Norm %1680 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1682 = cirh.MatMul %1440, %116 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x3072xbf16>) -> tensor<768x3072xbf16> loc(#loc305)
    %1683 = cirh.Cast %1682 {Truncate = false} : tensor<768x3072xbf16> -> tensor<768x3072xf32> loc(#loc305)
    %1684 = cirh.L2Norm %1683 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x3072xf32>) -> tensor<f32> loc(#loc223)
    %1685 = cirh.MatMul %1449, %109 {transpose_a = true, transpose_b = false} : (tensor<245760x3072xbf16>, tensor<245760x768xbf16>) -> tensor<3072x768xbf16> loc(#loc306)
    %1686 = cirh.Cast %1685 {Truncate = false} : tensor<3072x768xbf16> -> tensor<3072x768xf32> loc(#loc306)
    %1687 = cirh.L2Norm %1686 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<3072x768xf32>) -> tensor<f32> loc(#loc223)
    %1688 = cirh.MatMul %1462, %99 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc308)
    %1689 = cirh.Cast %1688 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc308)
    %1690 = cirh.L2Norm %1689 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1691 = cirh.MatMul %1492, %54 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc312)
    %1692 = cirh.Cast %1691 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc312)
    %1693 = cirh.L2Norm %1692 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1694 = cirh.MatMul %1486, %54 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc310)
    %1695 = cirh.Cast %1694 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc310)
    %1696 = cirh.L2Norm %1695 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1697 = cirh.MatMul %1480, %54 {transpose_a = true, transpose_b = false} : (tensor<245760x768xbf16>, tensor<245760x768xbf16>) -> tensor<768x768xbf16> loc(#loc311)
    %1698 = cirh.Cast %1697 {Truncate = false} : tensor<768x768xbf16> -> tensor<768x768xf32> loc(#loc311)
    %1699 = cirh.L2Norm %1698 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<768x768xf32>) -> tensor<f32> loc(#loc223)
    %1700 = cirh.Cast %result_129 {Truncate = false} : tensor<120x2048x768xf32> -> tensor<120x2048x768xbf16> loc(#loc313)
    %1701 = cirh.Add %1461, %1700 : tensor<120x2048x768xbf16> loc(#loc313)
    %1702 = cirh.Cast %1701 {Truncate = false} : tensor<120x2048x768xbf16> -> tensor<120x2048x768xf32> loc(#loc9)
    %1703 = cirh.Reshape %1702 : (tensor<120x2048x768xf32>) -> tensor<245760x768xf32> loc(#loc9)
    %1704 = cirh.Compare %42, %cst_50 {comparison_direction = "NE"} : tensor<245760xi64> -> tensor<245760xi1> loc(#loc9)
    %1705 = cirh.Reshape %1704 : (tensor<245760xi1>) -> tensor<245760x1xi1> loc(#loc9)
    %1706 = cirh.BroadcastInDim %1705 {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<245760x1xi1>) -> tensor<245760x768xi1> loc(#loc9)
    %1707 = cirh.Select %1706, %1703, %cst_49 : (tensor<245760x768xi1>, tensor<245760x768xf32>, tensor<245760x768xf32>) -> tensor<245760x768xf32> loc(#loc9)
    %1708 = cirh.Compare %42, %cst_47 {comparison_direction = "LT"} : tensor<245760xi64> -> tensor<245760xi1> loc(#loc9)
    %1709 = cirh.Add %42, %cst_46 : tensor<245760xi64> loc(#loc9)
    %1710 = cirh.Select %1708, %1709, %42 : (tensor<245760xi1>, tensor<245760xi64>, tensor<245760xi64>) -> tensor<245760xi64> loc(#loc9)
    %1711 = cirh.Reshape %1710 : (tensor<245760xi64>) -> tensor<245760x1xi64> loc(#loc9)
    %1712 = cirh.ScatterNd %1711, %1707, %cst_48 : (tensor<245760x1xi64>, tensor<245760x768xf32>, tensor<2xi64>) -> tensor<2048x768xf32> loc(#loc9)
    %1713 = cirh.L2Norm %1712 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<2048x768xf32>) -> tensor<f32> loc(#loc223)
    %1714 = cirh.Compare %46, %cst_45 {comparison_direction = "NE"} : tensor<245760xi32> -> tensor<245760xi1> loc(#loc8)
    %1715 = cirh.Reshape %1714 : (tensor<245760xi1>) -> tensor<245760x1xi1> loc(#loc8)
    %1716 = cirh.BroadcastInDim %1715 {broadcast_dimensions = dense<[0, 1]> : tensor<2xi64>} : (tensor<245760x1xi1>) -> tensor<245760x768xi1> loc(#loc8)
    %1717 = cirh.Select %1716, %1703, %cst_49 : (tensor<245760x768xi1>, tensor<245760x768xf32>, tensor<245760x768xf32>) -> tensor<245760x768xf32> loc(#loc8)
    %1718 = cirh.Compare %46, %cst_43 {comparison_direction = "LT"} : tensor<245760xi32> -> tensor<245760xi1> loc(#loc8)
    %1719 = cirh.Add %46, %cst_42 : tensor<245760xi32> loc(#loc8)
    %1720 = cirh.Select %1718, %1719, %46 : (tensor<245760xi1>, tensor<245760xi32>, tensor<245760xi32>) -> tensor<245760xi32> loc(#loc8)
    %1721 = cirh.Reshape %1720 : (tensor<245760xi32>) -> tensor<245760x1xi32> loc(#loc8)
    %1722 = cirh.ScatterNd %1721, %1717, %cst_44 : (tensor<245760x1xi32>, tensor<245760x768xf32>, tensor<2xi64>) -> tensor<50257x768xf32> loc(#loc8)
    %1723 = cirh.MatMul %695, %685 {transpose_a = true, transpose_b = false} : (tensor<245760x50257xbf16>, tensor<245760x768xbf16>) -> tensor<50257x768xbf16> loc(#loc221)
    %1724 = cirh.Cast %1723 {Truncate = false} : tensor<50257x768xbf16> -> tensor<50257x768xf32> loc(#loc221)
    %1725 = cirh.Add %1724, %1722 : tensor<50257x768xf32> loc(#loc8)
    %1726 = cirh.L2Norm %1725 {dims = dense<[0, 1]> : tensor<2xi64>, keepdim = false} : (tensor<50257x768xf32>) -> tensor<f32> loc(#loc223)
    %1727 = cirh.Reshape %1726 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1728 = cirh.Reshape %1713 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1729 = cirh.Reshape %1699 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1730 = cirh.Reshape %1696 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1731 = cirh.Reshape %1693 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1732 = cirh.Reshape %1690 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1733 = cirh.Reshape %1687 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1734 = cirh.Reshape %1684 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1735 = cirh.Reshape %1681 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1736 = cirh.Reshape %1678 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1737 = cirh.Reshape %1675 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1738 = cirh.Reshape %1672 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1739 = cirh.Reshape %1669 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1740 = cirh.Reshape %1666 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1741 = cirh.Reshape %1663 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1742 = cirh.Reshape %1660 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1743 = cirh.Reshape %1657 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1744 = cirh.Reshape %1654 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1745 = cirh.Reshape %1651 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1746 = cirh.Reshape %1648 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1747 = cirh.Reshape %1645 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1748 = cirh.Reshape %1642 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1749 = cirh.Reshape %1639 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1750 = cirh.Reshape %1636 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1751 = cirh.Reshape %1633 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1752 = cirh.Reshape %1630 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1753 = cirh.Reshape %1627 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1754 = cirh.Reshape %1624 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1755 = cirh.Reshape %1621 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1756 = cirh.Reshape %1618 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1757 = cirh.Reshape %1615 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1758 = cirh.Reshape %1612 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1759 = cirh.Reshape %1609 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1760 = cirh.Reshape %1606 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1761 = cirh.Reshape %1603 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1762 = cirh.Reshape %1600 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1763 = cirh.Reshape %1597 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1764 = cirh.Reshape %1594 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1765 = cirh.Reshape %1591 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1766 = cirh.Reshape %1588 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1767 = cirh.Reshape %1585 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1768 = cirh.Reshape %1582 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1769 = cirh.Reshape %1579 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1770 = cirh.Reshape %1576 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1771 = cirh.Reshape %1573 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1772 = cirh.Reshape %1570 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1773 = cirh.Reshape %1567 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1774 = cirh.Reshape %1564 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1775 = cirh.Reshape %1561 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1776 = cirh.Reshape %1558 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1777 = cirh.Reshape %1555 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1778 = cirh.Reshape %1552 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1779 = cirh.Reshape %1549 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1780 = cirh.Reshape %1546 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1781 = cirh.Reshape %1543 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1782 = cirh.Reshape %1540 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1783 = cirh.Reshape %1537 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1784 = cirh.Reshape %1534 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1785 = cirh.Reshape %1531 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1786 = cirh.Reshape %1528 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1787 = cirh.Reshape %1525 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1788 = cirh.Reshape %1522 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1789 = cirh.Reshape %1519 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1790 = cirh.Reshape %1514 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1791 = cirh.Reshape %1509 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1792 = cirh.Reshape %1504 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1793 = cirh.Reshape %1499 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1794 = cirh.Reshape %1498 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1795 = cirh.Reshape %1459 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1796 = cirh.Reshape %1458 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1797 = cirh.Reshape %1454 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1798 = cirh.Reshape %1445 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1799 = cirh.Reshape %1437 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1800 = cirh.Reshape %1432 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1801 = cirh.Reshape %1427 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1802 = cirh.Reshape %1422 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1803 = cirh.Reshape %1417 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1804 = cirh.Reshape %1416 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1805 = cirh.Reshape %1377 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1806 = cirh.Reshape %1376 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1807 = cirh.Reshape %1372 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1808 = cirh.Reshape %1363 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1809 = cirh.Reshape %1355 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1810 = cirh.Reshape %1350 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1811 = cirh.Reshape %1345 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1812 = cirh.Reshape %1340 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1813 = cirh.Reshape %1335 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1814 = cirh.Reshape %1334 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1815 = cirh.Reshape %1295 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1816 = cirh.Reshape %1294 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1817 = cirh.Reshape %1290 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1818 = cirh.Reshape %1281 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1819 = cirh.Reshape %1273 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1820 = cirh.Reshape %1268 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1821 = cirh.Reshape %1263 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1822 = cirh.Reshape %1258 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1823 = cirh.Reshape %1253 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1824 = cirh.Reshape %1252 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1825 = cirh.Reshape %1213 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1826 = cirh.Reshape %1212 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1827 = cirh.Reshape %1208 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1828 = cirh.Reshape %1199 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1829 = cirh.Reshape %1191 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1830 = cirh.Reshape %1186 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1831 = cirh.Reshape %1181 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1832 = cirh.Reshape %1176 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1833 = cirh.Reshape %1171 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1834 = cirh.Reshape %1170 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1835 = cirh.Reshape %1131 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1836 = cirh.Reshape %1130 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1837 = cirh.Reshape %1126 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1838 = cirh.Reshape %1117 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1839 = cirh.Reshape %1109 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1840 = cirh.Reshape %1104 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1841 = cirh.Reshape %1099 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1842 = cirh.Reshape %1094 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1843 = cirh.Reshape %1089 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1844 = cirh.Reshape %1088 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1845 = cirh.Reshape %1049 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1846 = cirh.Reshape %1048 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1847 = cirh.Reshape %1044 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1848 = cirh.Reshape %1035 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1849 = cirh.Reshape %1027 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1850 = cirh.Reshape %1022 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1851 = cirh.Reshape %1017 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1852 = cirh.Reshape %1012 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1853 = cirh.Reshape %1007 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1854 = cirh.Reshape %1006 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1855 = cirh.Reshape %967 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1856 = cirh.Reshape %966 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1857 = cirh.Reshape %962 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1858 = cirh.Reshape %953 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1859 = cirh.Reshape %945 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1860 = cirh.Reshape %940 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1861 = cirh.Reshape %935 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1862 = cirh.Reshape %930 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1863 = cirh.Reshape %925 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1864 = cirh.Reshape %924 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1865 = cirh.Reshape %885 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1866 = cirh.Reshape %884 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1867 = cirh.Reshape %880 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1868 = cirh.Reshape %871 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1869 = cirh.Reshape %863 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1870 = cirh.Reshape %858 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1871 = cirh.Reshape %853 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1872 = cirh.Reshape %848 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1873 = cirh.Reshape %843 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1874 = cirh.Reshape %842 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1875 = cirh.Reshape %803 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1876 = cirh.Reshape %802 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1877 = cirh.Reshape %798 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1878 = cirh.Reshape %789 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1879 = cirh.Reshape %781 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1880 = cirh.Reshape %776 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1881 = cirh.Reshape %771 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1882 = cirh.Reshape %766 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1883 = cirh.Reshape %761 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1884 = cirh.Reshape %760 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1885 = cirh.Reshape %721 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1886 = cirh.Reshape %720 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1887 = cirh.Reshape %716 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1888 = cirh.Reshape %707 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1889 = cirh.Reshape %700 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1890 = cirh.Reshape %699 : (tensor<f32>) -> tensor<1xf32> loc(#loc314)
    %1891 = cirh.Concat %1727, %1728, %1729, %1730, %1731, %1732, %1733, %1734, %1735, %1736, %1737, %1738, %1739, %1740, %1741, %1742, %1743, %1744, %1745, %1746, %1747, %1748, %1749, %1750, %1751, %1752, %1753, %1754, %1755, %1756, %1757, %1758, %1759, %1760, %1761, %1762, %1763, %1764, %1765, %1766, %1767, %1768, %1769, %1770, %1771, %1772, %1773, %1774, %1775, %1776, %1777, %1778, %1779, %1780, %1781, %1782, %1783, %1784, %1785, %1786, %1787, %1788, %1789, %1790, %1791, %1792, %1793, %1794, %1795, %1796, %1797, %1798, %1799, %1800, %1801, %1802, %1803, %1804, %1805, %1806, %1807, %1808, %1809, %1810, %1811, %1812, %1813, %1814, %1815, %1816, %1817, %1818, %1819, %1820, %1821, %1822, %1823, %1824, %1825, %1826, %1827, %1828, %1829, %1830, %1831, %1832, %1833, %1834, %1835, %1836, %1837, %1838, %1839, %1840, %1841, %1842, %1843, %1844, %1845, %1846, %1847, %1848, %1849, %1850, %1851, %1852, %1853, %1854, %1855, %1856, %1857, %1858, %1859, %1860, %1861, %1862, %1863, %1864, %1865, %1866, %1867, %1868, %1869, %1870, %1871, %1872, %1873, %1874, %1875, %1876, %1877, %1878, %1879, %1880, %1881, %1882, %1883, %1884, %1885, %1886, %1887, %1888, %1889, %1890 {axis = 0 : i64} : (tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<164xf32> loc(#loc314)
    %1892 = cirh.L2Norm %1891 {dims = dense<0> : tensor<1xi64>, keepdim = false} : (tensor<164xf32>) -> tensor<f32> loc(#loc315)
    %1893 = cirh.Add %1892, %cst_71 : tensor<f32> loc(#loc316)
    %1894 = cirh.Reciprocal %1893 : tensor<f32> loc(#loc317)
    %1895 = cirh.Clamp %1894, %cst_41, %cst_36 : (tensor<f32>, tensor<f32>, tensor<f32>) -> tensor<f32> loc(#loc7)
    %1896 = cirh.BroadcastInDim %1895 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<50257x768xf32> loc(#loc318)
    %1897 = cirh.Mul %1725, %1896 : tensor<50257x768xf32> loc(#loc318)
    %1898 = cirh.Mul %arg166, %cst_40 : tensor<50257x768xf32> loc(#loc3)
    %1899 = cirh.Mul %1897, %cst_39 : tensor<50257x768xf32> loc(#loc3)
    %1900 = cirh.Add %1898, %1899 : tensor<50257x768xf32> loc(#loc3)
    %1901 = cirh.Mul %arg167, %cst_38 : tensor<50257x768xf32> loc(#loc2)
    %1902 = cirh.Mul %1897, %1897 : tensor<50257x768xf32> loc(#loc2)
    %1903 = cirh.Mul %1902, %cst_37 : tensor<50257x768xf32> loc(#loc2)
    %1904 = cirh.Add %1901, %1903 : tensor<50257x768xf32> loc(#loc2)
    %1905 = cirh.Mul %arg168, %cst_69 : tensor<f32> loc(#loc319)
    %1906 = cirh.Mul %arg169, %cst_68 : tensor<f32> loc(#loc320)
    %1907 = cirh.Cast %arg170 {Truncate = false} : tensor<i64> -> tensor<f32> loc(#loc321)
    %1908 = cirh.Clamp %cst_64, %cst_41, %1907 : (tensor<f32>, tensor<f32>, tensor<f32>) -> tensor<f32> loc(#loc321)
    %1909 = cirh.Mul %1908, %cst_63 : tensor<f32> loc(#loc322)
    %1910 = cirh.Cos %1909 : tensor<f32> loc(#loc323)
    %1911 = cirh.Add %1910, %cst_36 : tensor<f32> loc(#loc322)
    %1912 = cirh.Mul %1911, %cst_65 : tensor<f32> loc(#loc322)
    %1913 = cirh.Mul %1912, %cst_66 : tensor<f32> loc(#loc324)
    %1914 = cirh.Add %1913, %cst_67 : tensor<f32> loc(#loc324)
    %1915 = cirh.Cast %arg171 {Truncate = false} : tensor<i64> -> tensor<f32> loc(#loc5)
    %1916 = cirh.Div %1915, %cst_35 : tensor<f32> loc(#loc5)
    %1917 = cirh.Sub %cst_36, %1916 : tensor<f32> loc(#loc325)
    %1918 = cirh.Mul %1917, %cst_61 : tensor<f32> loc(#loc326)
    %1919 = cirh.Add %1918, %cst_62 : tensor<f32> loc(#loc326)
    %1920 = cirh.Compare %arg171, %cst_60 {comparison_direction = "GE"} : tensor<i64> -> tensor<i1> loc(#loc327)
    %1921 = cirh.Select %1920, %cst_62, %1919 : (tensor<i1>, tensor<f32>, tensor<f32>) -> tensor<f32> loc(#loc328)
    %1922 = cirh.Compare %arg172, %cst_60 {comparison_direction = "LT"} : tensor<i64> -> tensor<i1> loc(#loc329)
    %1923 = cirh.Select %1922, %1921, %1914 : (tensor<i1>, tensor<f32>, tensor<f32>) -> tensor<f32> loc(#loc330)
    %1924 = cirh.Sub %cst_36, %arg168 : tensor<f32> loc(#loc331)
    %1925 = cirh.Sub %cst_36, %arg169 : tensor<f32> loc(#loc332)
    %1926 = cirh.Sqrt %1925 : tensor<f32> loc(#loc333)
    %1927 = cirh.Div %1926, %1924 : tensor<f32> loc(#loc334)
    %1928 = cirh.Sqrt %1904 : tensor<50257x768xf32> loc(#loc335)
    %1929 = cirh.Add %1928, %cst_34 : tensor<50257x768xf32> loc(#loc1)
    %1930 = cirh.Div %1900, %1929 : tensor<50257x768xf32> loc(#loc336)
    %1931 = cirh.BroadcastInDim %1927 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<50257x768xf32> loc(#loc337)
    %1932 = cirh.Mul %1930, %1931 : tensor<50257x768xf32> loc(#loc337)
    %1933 = cirh.Mul %arg84, %cst_33 : tensor<50257x768xf32> loc(#loc4)
    %1934 = cirh.Add %1932, %1933 : tensor<50257x768xf32> loc(#loc4)
    %1935 = cirh.BroadcastInDim %1923 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<50257x768xf32> loc(#loc338)
    %1936 = cirh.Mul %1934, %1935 : tensor<50257x768xf32> loc(#loc338)
    %1937 = cirh.Sub %arg84, %1936 : tensor<50257x768xf32> loc(#loc339)
    %1938 = cirh.BroadcastInDim %1895 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<2048x768xf32> loc(#loc318)
    %1939 = cirh.Mul %1712, %1938 : tensor<2048x768xf32> loc(#loc318)
    %1940 = cirh.Mul %arg173, %cst_32 : tensor<2048x768xf32> loc(#loc3)
    %1941 = cirh.Mul %1939, %cst_31 : tensor<2048x768xf32> loc(#loc3)
    %1942 = cirh.Add %1940, %1941 : tensor<2048x768xf32> loc(#loc3)
    %1943 = cirh.Mul %arg174, %cst_30 : tensor<2048x768xf32> loc(#loc2)
    %1944 = cirh.Mul %1939, %1939 : tensor<2048x768xf32> loc(#loc2)
    %1945 = cirh.Mul %1944, %cst_29 : tensor<2048x768xf32> loc(#loc2)
    %1946 = cirh.Add %1943, %1945 : tensor<2048x768xf32> loc(#loc2)
    %1947 = cirh.Mul %arg175, %cst_69 : tensor<f32> loc(#loc319)
    %1948 = cirh.Mul %arg176, %cst_68 : tensor<f32> loc(#loc320)
    %1949 = cirh.Sub %cst_36, %arg175 : tensor<f32> loc(#loc331)
    %1950 = cirh.Sub %cst_36, %arg176 : tensor<f32> loc(#loc332)
    %1951 = cirh.Sqrt %1950 : tensor<f32> loc(#loc333)
    %1952 = cirh.Div %1951, %1949 : tensor<f32> loc(#loc334)
    %1953 = cirh.Sqrt %1946 : tensor<2048x768xf32> loc(#loc335)
    %1954 = cirh.Add %1953, %cst_28 : tensor<2048x768xf32> loc(#loc1)
    %1955 = cirh.Div %1942, %1954 : tensor<2048x768xf32> loc(#loc336)
    %1956 = cirh.BroadcastInDim %1952 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<2048x768xf32> loc(#loc337)
    %1957 = cirh.Mul %1955, %1956 : tensor<2048x768xf32> loc(#loc337)
    %1958 = cirh.Mul %arg82, %cst_27 : tensor<2048x768xf32> loc(#loc4)
    %1959 = cirh.Add %1957, %1958 : tensor<2048x768xf32> loc(#loc4)
    %1960 = cirh.BroadcastInDim %1923 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<2048x768xf32> loc(#loc338)
    %1961 = cirh.Mul %1959, %1960 : tensor<2048x768xf32> loc(#loc338)
    %1962 = cirh.Sub %arg82, %1961 : tensor<2048x768xf32> loc(#loc339)
    %1963 = cirh.BroadcastInDim %1895 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc318)
    %1964 = cirh.Mul %1698, %1963 : tensor<768x768xf32> loc(#loc318)
    %1965 = cirh.Mul %arg177, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %1966 = cirh.Mul %1964, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %1967 = cirh.Add %1965, %1966 : tensor<768x768xf32> loc(#loc3)
    %1968 = cirh.Mul %arg178, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %1969 = cirh.Mul %1964, %1964 : tensor<768x768xf32> loc(#loc2)
    %1970 = cirh.Mul %1969, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %1971 = cirh.Add %1968, %1970 : tensor<768x768xf32> loc(#loc2)
    %1972 = cirh.Mul %arg179, %cst_69 : tensor<f32> loc(#loc319)
    %1973 = cirh.Mul %arg180, %cst_68 : tensor<f32> loc(#loc320)
    %1974 = cirh.Sub %cst_36, %arg179 : tensor<f32> loc(#loc331)
    %1975 = cirh.Sub %cst_36, %arg180 : tensor<f32> loc(#loc332)
    %1976 = cirh.Sqrt %1975 : tensor<f32> loc(#loc333)
    %1977 = cirh.Div %1976, %1974 : tensor<f32> loc(#loc334)
    %1978 = cirh.Sqrt %1971 : tensor<768x768xf32> loc(#loc335)
    %1979 = cirh.Add %1978, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %1980 = cirh.Div %1967, %1979 : tensor<768x768xf32> loc(#loc336)
    %1981 = cirh.BroadcastInDim %1977 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %1982 = cirh.Mul %1980, %1981 : tensor<768x768xf32> loc(#loc337)
    %1983 = cirh.Mul %arg88, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %1984 = cirh.Add %1982, %1983 : tensor<768x768xf32> loc(#loc4)
    %1985 = cirh.BroadcastInDim %1923 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc338)
    %1986 = cirh.Mul %1984, %1985 : tensor<768x768xf32> loc(#loc338)
    %1987 = cirh.Sub %arg88, %1986 : tensor<768x768xf32> loc(#loc339)
    %1988 = cirh.Mul %1695, %1963 : tensor<768x768xf32> loc(#loc318)
    %1989 = cirh.Mul %arg181, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %1990 = cirh.Mul %1988, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %1991 = cirh.Add %1989, %1990 : tensor<768x768xf32> loc(#loc3)
    %1992 = cirh.Mul %arg182, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %1993 = cirh.Mul %1988, %1988 : tensor<768x768xf32> loc(#loc2)
    %1994 = cirh.Mul %1993, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %1995 = cirh.Add %1992, %1994 : tensor<768x768xf32> loc(#loc2)
    %1996 = cirh.Mul %arg183, %cst_69 : tensor<f32> loc(#loc319)
    %1997 = cirh.Mul %arg184, %cst_68 : tensor<f32> loc(#loc320)
    %1998 = cirh.Sub %cst_36, %arg183 : tensor<f32> loc(#loc331)
    %1999 = cirh.Sub %cst_36, %arg184 : tensor<f32> loc(#loc332)
    %2000 = cirh.Sqrt %1999 : tensor<f32> loc(#loc333)
    %2001 = cirh.Div %2000, %1998 : tensor<f32> loc(#loc334)
    %2002 = cirh.Sqrt %1995 : tensor<768x768xf32> loc(#loc335)
    %2003 = cirh.Add %2002, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2004 = cirh.Div %1991, %2003 : tensor<768x768xf32> loc(#loc336)
    %2005 = cirh.BroadcastInDim %2001 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2006 = cirh.Mul %2004, %2005 : tensor<768x768xf32> loc(#loc337)
    %2007 = cirh.Mul %arg86, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2008 = cirh.Add %2006, %2007 : tensor<768x768xf32> loc(#loc4)
    %2009 = cirh.Mul %2008, %1985 : tensor<768x768xf32> loc(#loc338)
    %2010 = cirh.Sub %arg86, %2009 : tensor<768x768xf32> loc(#loc339)
    %2011 = cirh.Mul %1692, %1963 : tensor<768x768xf32> loc(#loc318)
    %2012 = cirh.Mul %arg185, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2013 = cirh.Mul %2011, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2014 = cirh.Add %2012, %2013 : tensor<768x768xf32> loc(#loc3)
    %2015 = cirh.Mul %arg186, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2016 = cirh.Mul %2011, %2011 : tensor<768x768xf32> loc(#loc2)
    %2017 = cirh.Mul %2016, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2018 = cirh.Add %2015, %2017 : tensor<768x768xf32> loc(#loc2)
    %2019 = cirh.Mul %arg187, %cst_69 : tensor<f32> loc(#loc319)
    %2020 = cirh.Mul %arg188, %cst_68 : tensor<f32> loc(#loc320)
    %2021 = cirh.Sub %cst_36, %arg187 : tensor<f32> loc(#loc331)
    %2022 = cirh.Sub %cst_36, %arg188 : tensor<f32> loc(#loc332)
    %2023 = cirh.Sqrt %2022 : tensor<f32> loc(#loc333)
    %2024 = cirh.Div %2023, %2021 : tensor<f32> loc(#loc334)
    %2025 = cirh.Sqrt %2018 : tensor<768x768xf32> loc(#loc335)
    %2026 = cirh.Add %2025, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2027 = cirh.Div %2014, %2026 : tensor<768x768xf32> loc(#loc336)
    %2028 = cirh.BroadcastInDim %2024 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2029 = cirh.Mul %2027, %2028 : tensor<768x768xf32> loc(#loc337)
    %2030 = cirh.Mul %arg79, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2031 = cirh.Add %2029, %2030 : tensor<768x768xf32> loc(#loc4)
    %2032 = cirh.Mul %2031, %1985 : tensor<768x768xf32> loc(#loc338)
    %2033 = cirh.Sub %arg79, %2032 : tensor<768x768xf32> loc(#loc339)
    %2034 = cirh.Mul %1689, %1963 : tensor<768x768xf32> loc(#loc318)
    %2035 = cirh.Mul %arg189, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2036 = cirh.Mul %2034, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2037 = cirh.Add %2035, %2036 : tensor<768x768xf32> loc(#loc3)
    %2038 = cirh.Mul %arg190, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2039 = cirh.Mul %2034, %2034 : tensor<768x768xf32> loc(#loc2)
    %2040 = cirh.Mul %2039, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2041 = cirh.Add %2038, %2040 : tensor<768x768xf32> loc(#loc2)
    %2042 = cirh.Mul %arg191, %cst_69 : tensor<f32> loc(#loc319)
    %2043 = cirh.Mul %arg192, %cst_68 : tensor<f32> loc(#loc320)
    %2044 = cirh.Sub %cst_36, %arg191 : tensor<f32> loc(#loc331)
    %2045 = cirh.Sub %cst_36, %arg192 : tensor<f32> loc(#loc332)
    %2046 = cirh.Sqrt %2045 : tensor<f32> loc(#loc333)
    %2047 = cirh.Div %2046, %2044 : tensor<f32> loc(#loc334)
    %2048 = cirh.Sqrt %2041 : tensor<768x768xf32> loc(#loc335)
    %2049 = cirh.Add %2048, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2050 = cirh.Div %2037, %2049 : tensor<768x768xf32> loc(#loc336)
    %2051 = cirh.BroadcastInDim %2047 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2052 = cirh.Mul %2050, %2051 : tensor<768x768xf32> loc(#loc337)
    %2053 = cirh.Mul %arg78, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2054 = cirh.Add %2052, %2053 : tensor<768x768xf32> loc(#loc4)
    %2055 = cirh.Mul %2054, %1985 : tensor<768x768xf32> loc(#loc338)
    %2056 = cirh.Sub %arg78, %2055 : tensor<768x768xf32> loc(#loc339)
    %2057 = cirh.BroadcastInDim %1895 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc318)
    %2058 = cirh.Mul %1686, %2057 : tensor<3072x768xf32> loc(#loc318)
    %2059 = cirh.Mul %arg193, %cst_20 : tensor<3072x768xf32> loc(#loc3)
    %2060 = cirh.Mul %2058, %cst_19 : tensor<3072x768xf32> loc(#loc3)
    %2061 = cirh.Add %2059, %2060 : tensor<3072x768xf32> loc(#loc3)
    %2062 = cirh.Mul %arg194, %cst_18 : tensor<3072x768xf32> loc(#loc2)
    %2063 = cirh.Mul %2058, %2058 : tensor<3072x768xf32> loc(#loc2)
    %2064 = cirh.Mul %2063, %cst_17 : tensor<3072x768xf32> loc(#loc2)
    %2065 = cirh.Add %2062, %2064 : tensor<3072x768xf32> loc(#loc2)
    %2066 = cirh.Mul %arg195, %cst_69 : tensor<f32> loc(#loc319)
    %2067 = cirh.Mul %arg196, %cst_68 : tensor<f32> loc(#loc320)
    %2068 = cirh.Sub %cst_36, %arg195 : tensor<f32> loc(#loc331)
    %2069 = cirh.Sub %cst_36, %arg196 : tensor<f32> loc(#loc332)
    %2070 = cirh.Sqrt %2069 : tensor<f32> loc(#loc333)
    %2071 = cirh.Div %2070, %2068 : tensor<f32> loc(#loc334)
    %2072 = cirh.Sqrt %2065 : tensor<3072x768xf32> loc(#loc335)
    %2073 = cirh.Add %2072, %cst_16 : tensor<3072x768xf32> loc(#loc1)
    %2074 = cirh.Div %2061, %2073 : tensor<3072x768xf32> loc(#loc336)
    %2075 = cirh.BroadcastInDim %2071 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc337)
    %2076 = cirh.Mul %2074, %2075 : tensor<3072x768xf32> loc(#loc337)
    %2077 = cirh.Mul %arg75, %cst_15 : tensor<3072x768xf32> loc(#loc4)
    %2078 = cirh.Add %2076, %2077 : tensor<3072x768xf32> loc(#loc4)
    %2079 = cirh.BroadcastInDim %1923 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc338)
    %2080 = cirh.Mul %2078, %2079 : tensor<3072x768xf32> loc(#loc338)
    %2081 = cirh.Sub %arg75, %2080 : tensor<3072x768xf32> loc(#loc339)
    %2082 = cirh.BroadcastInDim %1895 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc318)
    %2083 = cirh.Mul %1683, %2082 : tensor<768x3072xf32> loc(#loc318)
    %2084 = cirh.Mul %arg197, %cst_14 : tensor<768x3072xf32> loc(#loc3)
    %2085 = cirh.Mul %2083, %cst_13 : tensor<768x3072xf32> loc(#loc3)
    %2086 = cirh.Add %2084, %2085 : tensor<768x3072xf32> loc(#loc3)
    %2087 = cirh.Mul %arg198, %cst_12 : tensor<768x3072xf32> loc(#loc2)
    %2088 = cirh.Mul %2083, %2083 : tensor<768x3072xf32> loc(#loc2)
    %2089 = cirh.Mul %2088, %cst_11 : tensor<768x3072xf32> loc(#loc2)
    %2090 = cirh.Add %2087, %2089 : tensor<768x3072xf32> loc(#loc2)
    %2091 = cirh.Mul %arg199, %cst_69 : tensor<f32> loc(#loc319)
    %2092 = cirh.Mul %arg200, %cst_68 : tensor<f32> loc(#loc320)
    %2093 = cirh.Sub %cst_36, %arg199 : tensor<f32> loc(#loc331)
    %2094 = cirh.Sub %cst_36, %arg200 : tensor<f32> loc(#loc332)
    %2095 = cirh.Sqrt %2094 : tensor<f32> loc(#loc333)
    %2096 = cirh.Div %2095, %2093 : tensor<f32> loc(#loc334)
    %2097 = cirh.Sqrt %2090 : tensor<768x3072xf32> loc(#loc335)
    %2098 = cirh.Add %2097, %cst_10 : tensor<768x3072xf32> loc(#loc1)
    %2099 = cirh.Div %2086, %2098 : tensor<768x3072xf32> loc(#loc336)
    %2100 = cirh.BroadcastInDim %2096 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc337)
    %2101 = cirh.Mul %2099, %2100 : tensor<768x3072xf32> loc(#loc337)
    %2102 = cirh.Mul %arg74, %cst_9 : tensor<768x3072xf32> loc(#loc4)
    %2103 = cirh.Add %2101, %2102 : tensor<768x3072xf32> loc(#loc4)
    %2104 = cirh.BroadcastInDim %1923 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc338)
    %2105 = cirh.Mul %2103, %2104 : tensor<768x3072xf32> loc(#loc338)
    %2106 = cirh.Sub %arg74, %2105 : tensor<768x3072xf32> loc(#loc339)
    %2107 = cirh.Mul %1680, %1963 : tensor<768x768xf32> loc(#loc318)
    %2108 = cirh.Mul %arg201, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2109 = cirh.Mul %2107, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2110 = cirh.Add %2108, %2109 : tensor<768x768xf32> loc(#loc3)
    %2111 = cirh.Mul %arg202, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2112 = cirh.Mul %2107, %2107 : tensor<768x768xf32> loc(#loc2)
    %2113 = cirh.Mul %2112, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2114 = cirh.Add %2111, %2113 : tensor<768x768xf32> loc(#loc2)
    %2115 = cirh.Mul %arg203, %cst_69 : tensor<f32> loc(#loc319)
    %2116 = cirh.Mul %arg204, %cst_68 : tensor<f32> loc(#loc320)
    %2117 = cirh.Sub %cst_36, %arg203 : tensor<f32> loc(#loc331)
    %2118 = cirh.Sub %cst_36, %arg204 : tensor<f32> loc(#loc332)
    %2119 = cirh.Sqrt %2118 : tensor<f32> loc(#loc333)
    %2120 = cirh.Div %2119, %2117 : tensor<f32> loc(#loc334)
    %2121 = cirh.Sqrt %2114 : tensor<768x768xf32> loc(#loc335)
    %2122 = cirh.Add %2121, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2123 = cirh.Div %2110, %2122 : tensor<768x768xf32> loc(#loc336)
    %2124 = cirh.BroadcastInDim %2120 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2125 = cirh.Mul %2123, %2124 : tensor<768x768xf32> loc(#loc337)
    %2126 = cirh.Mul %arg96, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2127 = cirh.Add %2125, %2126 : tensor<768x768xf32> loc(#loc4)
    %2128 = cirh.Mul %2127, %1985 : tensor<768x768xf32> loc(#loc338)
    %2129 = cirh.Sub %arg96, %2128 : tensor<768x768xf32> loc(#loc339)
    %2130 = cirh.Mul %1677, %1963 : tensor<768x768xf32> loc(#loc318)
    %2131 = cirh.Mul %arg205, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2132 = cirh.Mul %2130, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2133 = cirh.Add %2131, %2132 : tensor<768x768xf32> loc(#loc3)
    %2134 = cirh.Mul %arg206, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2135 = cirh.Mul %2130, %2130 : tensor<768x768xf32> loc(#loc2)
    %2136 = cirh.Mul %2135, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2137 = cirh.Add %2134, %2136 : tensor<768x768xf32> loc(#loc2)
    %2138 = cirh.Mul %arg207, %cst_69 : tensor<f32> loc(#loc319)
    %2139 = cirh.Mul %arg208, %cst_68 : tensor<f32> loc(#loc320)
    %2140 = cirh.Sub %cst_36, %arg207 : tensor<f32> loc(#loc331)
    %2141 = cirh.Sub %cst_36, %arg208 : tensor<f32> loc(#loc332)
    %2142 = cirh.Sqrt %2141 : tensor<f32> loc(#loc333)
    %2143 = cirh.Div %2142, %2140 : tensor<f32> loc(#loc334)
    %2144 = cirh.Sqrt %2137 : tensor<768x768xf32> loc(#loc335)
    %2145 = cirh.Add %2144, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2146 = cirh.Div %2133, %2145 : tensor<768x768xf32> loc(#loc336)
    %2147 = cirh.BroadcastInDim %2143 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2148 = cirh.Mul %2146, %2147 : tensor<768x768xf32> loc(#loc337)
    %2149 = cirh.Mul %arg94, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2150 = cirh.Add %2148, %2149 : tensor<768x768xf32> loc(#loc4)
    %2151 = cirh.Mul %2150, %1985 : tensor<768x768xf32> loc(#loc338)
    %2152 = cirh.Sub %arg94, %2151 : tensor<768x768xf32> loc(#loc339)
    %2153 = cirh.Mul %1674, %1963 : tensor<768x768xf32> loc(#loc318)
    %2154 = cirh.Mul %arg209, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2155 = cirh.Mul %2153, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2156 = cirh.Add %2154, %2155 : tensor<768x768xf32> loc(#loc3)
    %2157 = cirh.Mul %arg210, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2158 = cirh.Mul %2153, %2153 : tensor<768x768xf32> loc(#loc2)
    %2159 = cirh.Mul %2158, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2160 = cirh.Add %2157, %2159 : tensor<768x768xf32> loc(#loc2)
    %2161 = cirh.Mul %arg211, %cst_69 : tensor<f32> loc(#loc319)
    %2162 = cirh.Mul %arg212, %cst_68 : tensor<f32> loc(#loc320)
    %2163 = cirh.Sub %cst_36, %arg211 : tensor<f32> loc(#loc331)
    %2164 = cirh.Sub %cst_36, %arg212 : tensor<f32> loc(#loc332)
    %2165 = cirh.Sqrt %2164 : tensor<f32> loc(#loc333)
    %2166 = cirh.Div %2165, %2163 : tensor<f32> loc(#loc334)
    %2167 = cirh.Sqrt %2160 : tensor<768x768xf32> loc(#loc335)
    %2168 = cirh.Add %2167, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2169 = cirh.Div %2156, %2168 : tensor<768x768xf32> loc(#loc336)
    %2170 = cirh.BroadcastInDim %2166 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2171 = cirh.Mul %2169, %2170 : tensor<768x768xf32> loc(#loc337)
    %2172 = cirh.Mul %arg71, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2173 = cirh.Add %2171, %2172 : tensor<768x768xf32> loc(#loc4)
    %2174 = cirh.Mul %2173, %1985 : tensor<768x768xf32> loc(#loc338)
    %2175 = cirh.Sub %arg71, %2174 : tensor<768x768xf32> loc(#loc339)
    %2176 = cirh.Mul %1671, %1963 : tensor<768x768xf32> loc(#loc318)
    %2177 = cirh.Mul %arg213, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2178 = cirh.Mul %2176, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2179 = cirh.Add %2177, %2178 : tensor<768x768xf32> loc(#loc3)
    %2180 = cirh.Mul %arg214, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2181 = cirh.Mul %2176, %2176 : tensor<768x768xf32> loc(#loc2)
    %2182 = cirh.Mul %2181, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2183 = cirh.Add %2180, %2182 : tensor<768x768xf32> loc(#loc2)
    %2184 = cirh.Mul %arg215, %cst_69 : tensor<f32> loc(#loc319)
    %2185 = cirh.Mul %arg216, %cst_68 : tensor<f32> loc(#loc320)
    %2186 = cirh.Sub %cst_36, %arg215 : tensor<f32> loc(#loc331)
    %2187 = cirh.Sub %cst_36, %arg216 : tensor<f32> loc(#loc332)
    %2188 = cirh.Sqrt %2187 : tensor<f32> loc(#loc333)
    %2189 = cirh.Div %2188, %2186 : tensor<f32> loc(#loc334)
    %2190 = cirh.Sqrt %2183 : tensor<768x768xf32> loc(#loc335)
    %2191 = cirh.Add %2190, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2192 = cirh.Div %2179, %2191 : tensor<768x768xf32> loc(#loc336)
    %2193 = cirh.BroadcastInDim %2189 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2194 = cirh.Mul %2192, %2193 : tensor<768x768xf32> loc(#loc337)
    %2195 = cirh.Mul %arg70, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2196 = cirh.Add %2194, %2195 : tensor<768x768xf32> loc(#loc4)
    %2197 = cirh.Mul %2196, %1985 : tensor<768x768xf32> loc(#loc338)
    %2198 = cirh.Sub %arg70, %2197 : tensor<768x768xf32> loc(#loc339)
    %2199 = cirh.Mul %1668, %2057 : tensor<3072x768xf32> loc(#loc318)
    %2200 = cirh.Mul %arg217, %cst_20 : tensor<3072x768xf32> loc(#loc3)
    %2201 = cirh.Mul %2199, %cst_19 : tensor<3072x768xf32> loc(#loc3)
    %2202 = cirh.Add %2200, %2201 : tensor<3072x768xf32> loc(#loc3)
    %2203 = cirh.Mul %arg218, %cst_18 : tensor<3072x768xf32> loc(#loc2)
    %2204 = cirh.Mul %2199, %2199 : tensor<3072x768xf32> loc(#loc2)
    %2205 = cirh.Mul %2204, %cst_17 : tensor<3072x768xf32> loc(#loc2)
    %2206 = cirh.Add %2203, %2205 : tensor<3072x768xf32> loc(#loc2)
    %2207 = cirh.Mul %arg219, %cst_69 : tensor<f32> loc(#loc319)
    %2208 = cirh.Mul %arg220, %cst_68 : tensor<f32> loc(#loc320)
    %2209 = cirh.Sub %cst_36, %arg219 : tensor<f32> loc(#loc331)
    %2210 = cirh.Sub %cst_36, %arg220 : tensor<f32> loc(#loc332)
    %2211 = cirh.Sqrt %2210 : tensor<f32> loc(#loc333)
    %2212 = cirh.Div %2211, %2209 : tensor<f32> loc(#loc334)
    %2213 = cirh.Sqrt %2206 : tensor<3072x768xf32> loc(#loc335)
    %2214 = cirh.Add %2213, %cst_16 : tensor<3072x768xf32> loc(#loc1)
    %2215 = cirh.Div %2202, %2214 : tensor<3072x768xf32> loc(#loc336)
    %2216 = cirh.BroadcastInDim %2212 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc337)
    %2217 = cirh.Mul %2215, %2216 : tensor<3072x768xf32> loc(#loc337)
    %2218 = cirh.Mul %arg67, %cst_15 : tensor<3072x768xf32> loc(#loc4)
    %2219 = cirh.Add %2217, %2218 : tensor<3072x768xf32> loc(#loc4)
    %2220 = cirh.Mul %2219, %2079 : tensor<3072x768xf32> loc(#loc338)
    %2221 = cirh.Sub %arg67, %2220 : tensor<3072x768xf32> loc(#loc339)
    %2222 = cirh.Mul %1665, %2082 : tensor<768x3072xf32> loc(#loc318)
    %2223 = cirh.Mul %arg221, %cst_14 : tensor<768x3072xf32> loc(#loc3)
    %2224 = cirh.Mul %2222, %cst_13 : tensor<768x3072xf32> loc(#loc3)
    %2225 = cirh.Add %2223, %2224 : tensor<768x3072xf32> loc(#loc3)
    %2226 = cirh.Mul %arg222, %cst_12 : tensor<768x3072xf32> loc(#loc2)
    %2227 = cirh.Mul %2222, %2222 : tensor<768x3072xf32> loc(#loc2)
    %2228 = cirh.Mul %2227, %cst_11 : tensor<768x3072xf32> loc(#loc2)
    %2229 = cirh.Add %2226, %2228 : tensor<768x3072xf32> loc(#loc2)
    %2230 = cirh.Mul %arg223, %cst_69 : tensor<f32> loc(#loc319)
    %2231 = cirh.Mul %arg224, %cst_68 : tensor<f32> loc(#loc320)
    %2232 = cirh.Sub %cst_36, %arg223 : tensor<f32> loc(#loc331)
    %2233 = cirh.Sub %cst_36, %arg224 : tensor<f32> loc(#loc332)
    %2234 = cirh.Sqrt %2233 : tensor<f32> loc(#loc333)
    %2235 = cirh.Div %2234, %2232 : tensor<f32> loc(#loc334)
    %2236 = cirh.Sqrt %2229 : tensor<768x3072xf32> loc(#loc335)
    %2237 = cirh.Add %2236, %cst_10 : tensor<768x3072xf32> loc(#loc1)
    %2238 = cirh.Div %2225, %2237 : tensor<768x3072xf32> loc(#loc336)
    %2239 = cirh.BroadcastInDim %2235 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc337)
    %2240 = cirh.Mul %2238, %2239 : tensor<768x3072xf32> loc(#loc337)
    %2241 = cirh.Mul %arg66, %cst_9 : tensor<768x3072xf32> loc(#loc4)
    %2242 = cirh.Add %2240, %2241 : tensor<768x3072xf32> loc(#loc4)
    %2243 = cirh.Mul %2242, %2104 : tensor<768x3072xf32> loc(#loc338)
    %2244 = cirh.Sub %arg66, %2243 : tensor<768x3072xf32> loc(#loc339)
    %2245 = cirh.Mul %1662, %1963 : tensor<768x768xf32> loc(#loc318)
    %2246 = cirh.Mul %arg225, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2247 = cirh.Mul %2245, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2248 = cirh.Add %2246, %2247 : tensor<768x768xf32> loc(#loc3)
    %2249 = cirh.Mul %arg226, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2250 = cirh.Mul %2245, %2245 : tensor<768x768xf32> loc(#loc2)
    %2251 = cirh.Mul %2250, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2252 = cirh.Add %2249, %2251 : tensor<768x768xf32> loc(#loc2)
    %2253 = cirh.Mul %arg227, %cst_69 : tensor<f32> loc(#loc319)
    %2254 = cirh.Mul %arg228, %cst_68 : tensor<f32> loc(#loc320)
    %2255 = cirh.Sub %cst_36, %arg227 : tensor<f32> loc(#loc331)
    %2256 = cirh.Sub %cst_36, %arg228 : tensor<f32> loc(#loc332)
    %2257 = cirh.Sqrt %2256 : tensor<f32> loc(#loc333)
    %2258 = cirh.Div %2257, %2255 : tensor<f32> loc(#loc334)
    %2259 = cirh.Sqrt %2252 : tensor<768x768xf32> loc(#loc335)
    %2260 = cirh.Add %2259, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2261 = cirh.Div %2248, %2260 : tensor<768x768xf32> loc(#loc336)
    %2262 = cirh.BroadcastInDim %2258 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2263 = cirh.Mul %2261, %2262 : tensor<768x768xf32> loc(#loc337)
    %2264 = cirh.Mul %arg104, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2265 = cirh.Add %2263, %2264 : tensor<768x768xf32> loc(#loc4)
    %2266 = cirh.Mul %2265, %1985 : tensor<768x768xf32> loc(#loc338)
    %2267 = cirh.Sub %arg104, %2266 : tensor<768x768xf32> loc(#loc339)
    %2268 = cirh.Mul %1659, %1963 : tensor<768x768xf32> loc(#loc318)
    %2269 = cirh.Mul %arg229, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2270 = cirh.Mul %2268, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2271 = cirh.Add %2269, %2270 : tensor<768x768xf32> loc(#loc3)
    %2272 = cirh.Mul %arg230, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2273 = cirh.Mul %2268, %2268 : tensor<768x768xf32> loc(#loc2)
    %2274 = cirh.Mul %2273, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2275 = cirh.Add %2272, %2274 : tensor<768x768xf32> loc(#loc2)
    %2276 = cirh.Mul %arg231, %cst_69 : tensor<f32> loc(#loc319)
    %2277 = cirh.Mul %arg232, %cst_68 : tensor<f32> loc(#loc320)
    %2278 = cirh.Sub %cst_36, %arg231 : tensor<f32> loc(#loc331)
    %2279 = cirh.Sub %cst_36, %arg232 : tensor<f32> loc(#loc332)
    %2280 = cirh.Sqrt %2279 : tensor<f32> loc(#loc333)
    %2281 = cirh.Div %2280, %2278 : tensor<f32> loc(#loc334)
    %2282 = cirh.Sqrt %2275 : tensor<768x768xf32> loc(#loc335)
    %2283 = cirh.Add %2282, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2284 = cirh.Div %2271, %2283 : tensor<768x768xf32> loc(#loc336)
    %2285 = cirh.BroadcastInDim %2281 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2286 = cirh.Mul %2284, %2285 : tensor<768x768xf32> loc(#loc337)
    %2287 = cirh.Mul %arg102, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2288 = cirh.Add %2286, %2287 : tensor<768x768xf32> loc(#loc4)
    %2289 = cirh.Mul %2288, %1985 : tensor<768x768xf32> loc(#loc338)
    %2290 = cirh.Sub %arg102, %2289 : tensor<768x768xf32> loc(#loc339)
    %2291 = cirh.Mul %1656, %1963 : tensor<768x768xf32> loc(#loc318)
    %2292 = cirh.Mul %arg233, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2293 = cirh.Mul %2291, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2294 = cirh.Add %2292, %2293 : tensor<768x768xf32> loc(#loc3)
    %2295 = cirh.Mul %arg234, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2296 = cirh.Mul %2291, %2291 : tensor<768x768xf32> loc(#loc2)
    %2297 = cirh.Mul %2296, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2298 = cirh.Add %2295, %2297 : tensor<768x768xf32> loc(#loc2)
    %2299 = cirh.Mul %arg235, %cst_69 : tensor<f32> loc(#loc319)
    %2300 = cirh.Mul %arg236, %cst_68 : tensor<f32> loc(#loc320)
    %2301 = cirh.Sub %cst_36, %arg235 : tensor<f32> loc(#loc331)
    %2302 = cirh.Sub %cst_36, %arg236 : tensor<f32> loc(#loc332)
    %2303 = cirh.Sqrt %2302 : tensor<f32> loc(#loc333)
    %2304 = cirh.Div %2303, %2301 : tensor<f32> loc(#loc334)
    %2305 = cirh.Sqrt %2298 : tensor<768x768xf32> loc(#loc335)
    %2306 = cirh.Add %2305, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2307 = cirh.Div %2294, %2306 : tensor<768x768xf32> loc(#loc336)
    %2308 = cirh.BroadcastInDim %2304 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2309 = cirh.Mul %2307, %2308 : tensor<768x768xf32> loc(#loc337)
    %2310 = cirh.Mul %arg63, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2311 = cirh.Add %2309, %2310 : tensor<768x768xf32> loc(#loc4)
    %2312 = cirh.Mul %2311, %1985 : tensor<768x768xf32> loc(#loc338)
    %2313 = cirh.Sub %arg63, %2312 : tensor<768x768xf32> loc(#loc339)
    %2314 = cirh.Mul %1653, %1963 : tensor<768x768xf32> loc(#loc318)
    %2315 = cirh.Mul %arg237, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2316 = cirh.Mul %2314, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2317 = cirh.Add %2315, %2316 : tensor<768x768xf32> loc(#loc3)
    %2318 = cirh.Mul %arg238, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2319 = cirh.Mul %2314, %2314 : tensor<768x768xf32> loc(#loc2)
    %2320 = cirh.Mul %2319, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2321 = cirh.Add %2318, %2320 : tensor<768x768xf32> loc(#loc2)
    %2322 = cirh.Mul %arg239, %cst_69 : tensor<f32> loc(#loc319)
    %2323 = cirh.Mul %arg240, %cst_68 : tensor<f32> loc(#loc320)
    %2324 = cirh.Sub %cst_36, %arg239 : tensor<f32> loc(#loc331)
    %2325 = cirh.Sub %cst_36, %arg240 : tensor<f32> loc(#loc332)
    %2326 = cirh.Sqrt %2325 : tensor<f32> loc(#loc333)
    %2327 = cirh.Div %2326, %2324 : tensor<f32> loc(#loc334)
    %2328 = cirh.Sqrt %2321 : tensor<768x768xf32> loc(#loc335)
    %2329 = cirh.Add %2328, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2330 = cirh.Div %2317, %2329 : tensor<768x768xf32> loc(#loc336)
    %2331 = cirh.BroadcastInDim %2327 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2332 = cirh.Mul %2330, %2331 : tensor<768x768xf32> loc(#loc337)
    %2333 = cirh.Mul %arg62, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2334 = cirh.Add %2332, %2333 : tensor<768x768xf32> loc(#loc4)
    %2335 = cirh.Mul %2334, %1985 : tensor<768x768xf32> loc(#loc338)
    %2336 = cirh.Sub %arg62, %2335 : tensor<768x768xf32> loc(#loc339)
    %2337 = cirh.Mul %1650, %2057 : tensor<3072x768xf32> loc(#loc318)
    %2338 = cirh.Mul %arg241, %cst_20 : tensor<3072x768xf32> loc(#loc3)
    %2339 = cirh.Mul %2337, %cst_19 : tensor<3072x768xf32> loc(#loc3)
    %2340 = cirh.Add %2338, %2339 : tensor<3072x768xf32> loc(#loc3)
    %2341 = cirh.Mul %arg242, %cst_18 : tensor<3072x768xf32> loc(#loc2)
    %2342 = cirh.Mul %2337, %2337 : tensor<3072x768xf32> loc(#loc2)
    %2343 = cirh.Mul %2342, %cst_17 : tensor<3072x768xf32> loc(#loc2)
    %2344 = cirh.Add %2341, %2343 : tensor<3072x768xf32> loc(#loc2)
    %2345 = cirh.Mul %arg243, %cst_69 : tensor<f32> loc(#loc319)
    %2346 = cirh.Mul %arg244, %cst_68 : tensor<f32> loc(#loc320)
    %2347 = cirh.Sub %cst_36, %arg243 : tensor<f32> loc(#loc331)
    %2348 = cirh.Sub %cst_36, %arg244 : tensor<f32> loc(#loc332)
    %2349 = cirh.Sqrt %2348 : tensor<f32> loc(#loc333)
    %2350 = cirh.Div %2349, %2347 : tensor<f32> loc(#loc334)
    %2351 = cirh.Sqrt %2344 : tensor<3072x768xf32> loc(#loc335)
    %2352 = cirh.Add %2351, %cst_16 : tensor<3072x768xf32> loc(#loc1)
    %2353 = cirh.Div %2340, %2352 : tensor<3072x768xf32> loc(#loc336)
    %2354 = cirh.BroadcastInDim %2350 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc337)
    %2355 = cirh.Mul %2353, %2354 : tensor<3072x768xf32> loc(#loc337)
    %2356 = cirh.Mul %arg59, %cst_15 : tensor<3072x768xf32> loc(#loc4)
    %2357 = cirh.Add %2355, %2356 : tensor<3072x768xf32> loc(#loc4)
    %2358 = cirh.Mul %2357, %2079 : tensor<3072x768xf32> loc(#loc338)
    %2359 = cirh.Sub %arg59, %2358 : tensor<3072x768xf32> loc(#loc339)
    %2360 = cirh.Mul %1647, %2082 : tensor<768x3072xf32> loc(#loc318)
    %2361 = cirh.Mul %arg245, %cst_14 : tensor<768x3072xf32> loc(#loc3)
    %2362 = cirh.Mul %2360, %cst_13 : tensor<768x3072xf32> loc(#loc3)
    %2363 = cirh.Add %2361, %2362 : tensor<768x3072xf32> loc(#loc3)
    %2364 = cirh.Mul %arg246, %cst_12 : tensor<768x3072xf32> loc(#loc2)
    %2365 = cirh.Mul %2360, %2360 : tensor<768x3072xf32> loc(#loc2)
    %2366 = cirh.Mul %2365, %cst_11 : tensor<768x3072xf32> loc(#loc2)
    %2367 = cirh.Add %2364, %2366 : tensor<768x3072xf32> loc(#loc2)
    %2368 = cirh.Mul %arg247, %cst_69 : tensor<f32> loc(#loc319)
    %2369 = cirh.Mul %arg248, %cst_68 : tensor<f32> loc(#loc320)
    %2370 = cirh.Sub %cst_36, %arg247 : tensor<f32> loc(#loc331)
    %2371 = cirh.Sub %cst_36, %arg248 : tensor<f32> loc(#loc332)
    %2372 = cirh.Sqrt %2371 : tensor<f32> loc(#loc333)
    %2373 = cirh.Div %2372, %2370 : tensor<f32> loc(#loc334)
    %2374 = cirh.Sqrt %2367 : tensor<768x3072xf32> loc(#loc335)
    %2375 = cirh.Add %2374, %cst_10 : tensor<768x3072xf32> loc(#loc1)
    %2376 = cirh.Div %2363, %2375 : tensor<768x3072xf32> loc(#loc336)
    %2377 = cirh.BroadcastInDim %2373 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc337)
    %2378 = cirh.Mul %2376, %2377 : tensor<768x3072xf32> loc(#loc337)
    %2379 = cirh.Mul %arg58, %cst_9 : tensor<768x3072xf32> loc(#loc4)
    %2380 = cirh.Add %2378, %2379 : tensor<768x3072xf32> loc(#loc4)
    %2381 = cirh.Mul %2380, %2104 : tensor<768x3072xf32> loc(#loc338)
    %2382 = cirh.Sub %arg58, %2381 : tensor<768x3072xf32> loc(#loc339)
    %2383 = cirh.Mul %1644, %1963 : tensor<768x768xf32> loc(#loc318)
    %2384 = cirh.Mul %arg249, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2385 = cirh.Mul %2383, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2386 = cirh.Add %2384, %2385 : tensor<768x768xf32> loc(#loc3)
    %2387 = cirh.Mul %arg250, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2388 = cirh.Mul %2383, %2383 : tensor<768x768xf32> loc(#loc2)
    %2389 = cirh.Mul %2388, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2390 = cirh.Add %2387, %2389 : tensor<768x768xf32> loc(#loc2)
    %2391 = cirh.Mul %arg251, %cst_69 : tensor<f32> loc(#loc319)
    %2392 = cirh.Mul %arg252, %cst_68 : tensor<f32> loc(#loc320)
    %2393 = cirh.Sub %cst_36, %arg251 : tensor<f32> loc(#loc331)
    %2394 = cirh.Sub %cst_36, %arg252 : tensor<f32> loc(#loc332)
    %2395 = cirh.Sqrt %2394 : tensor<f32> loc(#loc333)
    %2396 = cirh.Div %2395, %2393 : tensor<f32> loc(#loc334)
    %2397 = cirh.Sqrt %2390 : tensor<768x768xf32> loc(#loc335)
    %2398 = cirh.Add %2397, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2399 = cirh.Div %2386, %2398 : tensor<768x768xf32> loc(#loc336)
    %2400 = cirh.BroadcastInDim %2396 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2401 = cirh.Mul %2399, %2400 : tensor<768x768xf32> loc(#loc337)
    %2402 = cirh.Mul %arg112, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2403 = cirh.Add %2401, %2402 : tensor<768x768xf32> loc(#loc4)
    %2404 = cirh.Mul %2403, %1985 : tensor<768x768xf32> loc(#loc338)
    %2405 = cirh.Sub %arg112, %2404 : tensor<768x768xf32> loc(#loc339)
    %2406 = cirh.Mul %1641, %1963 : tensor<768x768xf32> loc(#loc318)
    %2407 = cirh.Mul %arg253, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2408 = cirh.Mul %2406, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2409 = cirh.Add %2407, %2408 : tensor<768x768xf32> loc(#loc3)
    %2410 = cirh.Mul %arg254, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2411 = cirh.Mul %2406, %2406 : tensor<768x768xf32> loc(#loc2)
    %2412 = cirh.Mul %2411, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2413 = cirh.Add %2410, %2412 : tensor<768x768xf32> loc(#loc2)
    %2414 = cirh.Mul %arg255, %cst_69 : tensor<f32> loc(#loc319)
    %2415 = cirh.Mul %arg256, %cst_68 : tensor<f32> loc(#loc320)
    %2416 = cirh.Sub %cst_36, %arg255 : tensor<f32> loc(#loc331)
    %2417 = cirh.Sub %cst_36, %arg256 : tensor<f32> loc(#loc332)
    %2418 = cirh.Sqrt %2417 : tensor<f32> loc(#loc333)
    %2419 = cirh.Div %2418, %2416 : tensor<f32> loc(#loc334)
    %2420 = cirh.Sqrt %2413 : tensor<768x768xf32> loc(#loc335)
    %2421 = cirh.Add %2420, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2422 = cirh.Div %2409, %2421 : tensor<768x768xf32> loc(#loc336)
    %2423 = cirh.BroadcastInDim %2419 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2424 = cirh.Mul %2422, %2423 : tensor<768x768xf32> loc(#loc337)
    %2425 = cirh.Mul %arg110, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2426 = cirh.Add %2424, %2425 : tensor<768x768xf32> loc(#loc4)
    %2427 = cirh.Mul %2426, %1985 : tensor<768x768xf32> loc(#loc338)
    %2428 = cirh.Sub %arg110, %2427 : tensor<768x768xf32> loc(#loc339)
    %2429 = cirh.Mul %1638, %1963 : tensor<768x768xf32> loc(#loc318)
    %2430 = cirh.Mul %arg257, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2431 = cirh.Mul %2429, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2432 = cirh.Add %2430, %2431 : tensor<768x768xf32> loc(#loc3)
    %2433 = cirh.Mul %arg258, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2434 = cirh.Mul %2429, %2429 : tensor<768x768xf32> loc(#loc2)
    %2435 = cirh.Mul %2434, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2436 = cirh.Add %2433, %2435 : tensor<768x768xf32> loc(#loc2)
    %2437 = cirh.Mul %arg259, %cst_69 : tensor<f32> loc(#loc319)
    %2438 = cirh.Mul %arg260, %cst_68 : tensor<f32> loc(#loc320)
    %2439 = cirh.Sub %cst_36, %arg259 : tensor<f32> loc(#loc331)
    %2440 = cirh.Sub %cst_36, %arg260 : tensor<f32> loc(#loc332)
    %2441 = cirh.Sqrt %2440 : tensor<f32> loc(#loc333)
    %2442 = cirh.Div %2441, %2439 : tensor<f32> loc(#loc334)
    %2443 = cirh.Sqrt %2436 : tensor<768x768xf32> loc(#loc335)
    %2444 = cirh.Add %2443, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2445 = cirh.Div %2432, %2444 : tensor<768x768xf32> loc(#loc336)
    %2446 = cirh.BroadcastInDim %2442 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2447 = cirh.Mul %2445, %2446 : tensor<768x768xf32> loc(#loc337)
    %2448 = cirh.Mul %arg55, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2449 = cirh.Add %2447, %2448 : tensor<768x768xf32> loc(#loc4)
    %2450 = cirh.Mul %2449, %1985 : tensor<768x768xf32> loc(#loc338)
    %2451 = cirh.Sub %arg55, %2450 : tensor<768x768xf32> loc(#loc339)
    %2452 = cirh.Mul %1635, %1963 : tensor<768x768xf32> loc(#loc318)
    %2453 = cirh.Mul %arg261, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2454 = cirh.Mul %2452, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2455 = cirh.Add %2453, %2454 : tensor<768x768xf32> loc(#loc3)
    %2456 = cirh.Mul %arg262, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2457 = cirh.Mul %2452, %2452 : tensor<768x768xf32> loc(#loc2)
    %2458 = cirh.Mul %2457, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2459 = cirh.Add %2456, %2458 : tensor<768x768xf32> loc(#loc2)
    %2460 = cirh.Mul %arg263, %cst_69 : tensor<f32> loc(#loc319)
    %2461 = cirh.Mul %arg264, %cst_68 : tensor<f32> loc(#loc320)
    %2462 = cirh.Sub %cst_36, %arg263 : tensor<f32> loc(#loc331)
    %2463 = cirh.Sub %cst_36, %arg264 : tensor<f32> loc(#loc332)
    %2464 = cirh.Sqrt %2463 : tensor<f32> loc(#loc333)
    %2465 = cirh.Div %2464, %2462 : tensor<f32> loc(#loc334)
    %2466 = cirh.Sqrt %2459 : tensor<768x768xf32> loc(#loc335)
    %2467 = cirh.Add %2466, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2468 = cirh.Div %2455, %2467 : tensor<768x768xf32> loc(#loc336)
    %2469 = cirh.BroadcastInDim %2465 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2470 = cirh.Mul %2468, %2469 : tensor<768x768xf32> loc(#loc337)
    %2471 = cirh.Mul %arg54, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2472 = cirh.Add %2470, %2471 : tensor<768x768xf32> loc(#loc4)
    %2473 = cirh.Mul %2472, %1985 : tensor<768x768xf32> loc(#loc338)
    %2474 = cirh.Sub %arg54, %2473 : tensor<768x768xf32> loc(#loc339)
    %2475 = cirh.Mul %1632, %2057 : tensor<3072x768xf32> loc(#loc318)
    %2476 = cirh.Mul %arg265, %cst_20 : tensor<3072x768xf32> loc(#loc3)
    %2477 = cirh.Mul %2475, %cst_19 : tensor<3072x768xf32> loc(#loc3)
    %2478 = cirh.Add %2476, %2477 : tensor<3072x768xf32> loc(#loc3)
    %2479 = cirh.Mul %arg266, %cst_18 : tensor<3072x768xf32> loc(#loc2)
    %2480 = cirh.Mul %2475, %2475 : tensor<3072x768xf32> loc(#loc2)
    %2481 = cirh.Mul %2480, %cst_17 : tensor<3072x768xf32> loc(#loc2)
    %2482 = cirh.Add %2479, %2481 : tensor<3072x768xf32> loc(#loc2)
    %2483 = cirh.Mul %arg267, %cst_69 : tensor<f32> loc(#loc319)
    %2484 = cirh.Mul %arg268, %cst_68 : tensor<f32> loc(#loc320)
    %2485 = cirh.Sub %cst_36, %arg267 : tensor<f32> loc(#loc331)
    %2486 = cirh.Sub %cst_36, %arg268 : tensor<f32> loc(#loc332)
    %2487 = cirh.Sqrt %2486 : tensor<f32> loc(#loc333)
    %2488 = cirh.Div %2487, %2485 : tensor<f32> loc(#loc334)
    %2489 = cirh.Sqrt %2482 : tensor<3072x768xf32> loc(#loc335)
    %2490 = cirh.Add %2489, %cst_16 : tensor<3072x768xf32> loc(#loc1)
    %2491 = cirh.Div %2478, %2490 : tensor<3072x768xf32> loc(#loc336)
    %2492 = cirh.BroadcastInDim %2488 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc337)
    %2493 = cirh.Mul %2491, %2492 : tensor<3072x768xf32> loc(#loc337)
    %2494 = cirh.Mul %arg51, %cst_15 : tensor<3072x768xf32> loc(#loc4)
    %2495 = cirh.Add %2493, %2494 : tensor<3072x768xf32> loc(#loc4)
    %2496 = cirh.Mul %2495, %2079 : tensor<3072x768xf32> loc(#loc338)
    %2497 = cirh.Sub %arg51, %2496 : tensor<3072x768xf32> loc(#loc339)
    %2498 = cirh.Mul %1629, %2082 : tensor<768x3072xf32> loc(#loc318)
    %2499 = cirh.Mul %arg269, %cst_14 : tensor<768x3072xf32> loc(#loc3)
    %2500 = cirh.Mul %2498, %cst_13 : tensor<768x3072xf32> loc(#loc3)
    %2501 = cirh.Add %2499, %2500 : tensor<768x3072xf32> loc(#loc3)
    %2502 = cirh.Mul %arg270, %cst_12 : tensor<768x3072xf32> loc(#loc2)
    %2503 = cirh.Mul %2498, %2498 : tensor<768x3072xf32> loc(#loc2)
    %2504 = cirh.Mul %2503, %cst_11 : tensor<768x3072xf32> loc(#loc2)
    %2505 = cirh.Add %2502, %2504 : tensor<768x3072xf32> loc(#loc2)
    %2506 = cirh.Mul %arg271, %cst_69 : tensor<f32> loc(#loc319)
    %2507 = cirh.Mul %arg272, %cst_68 : tensor<f32> loc(#loc320)
    %2508 = cirh.Sub %cst_36, %arg271 : tensor<f32> loc(#loc331)
    %2509 = cirh.Sub %cst_36, %arg272 : tensor<f32> loc(#loc332)
    %2510 = cirh.Sqrt %2509 : tensor<f32> loc(#loc333)
    %2511 = cirh.Div %2510, %2508 : tensor<f32> loc(#loc334)
    %2512 = cirh.Sqrt %2505 : tensor<768x3072xf32> loc(#loc335)
    %2513 = cirh.Add %2512, %cst_10 : tensor<768x3072xf32> loc(#loc1)
    %2514 = cirh.Div %2501, %2513 : tensor<768x3072xf32> loc(#loc336)
    %2515 = cirh.BroadcastInDim %2511 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc337)
    %2516 = cirh.Mul %2514, %2515 : tensor<768x3072xf32> loc(#loc337)
    %2517 = cirh.Mul %arg50, %cst_9 : tensor<768x3072xf32> loc(#loc4)
    %2518 = cirh.Add %2516, %2517 : tensor<768x3072xf32> loc(#loc4)
    %2519 = cirh.Mul %2518, %2104 : tensor<768x3072xf32> loc(#loc338)
    %2520 = cirh.Sub %arg50, %2519 : tensor<768x3072xf32> loc(#loc339)
    %2521 = cirh.Mul %1626, %1963 : tensor<768x768xf32> loc(#loc318)
    %2522 = cirh.Mul %arg273, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2523 = cirh.Mul %2521, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2524 = cirh.Add %2522, %2523 : tensor<768x768xf32> loc(#loc3)
    %2525 = cirh.Mul %arg274, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2526 = cirh.Mul %2521, %2521 : tensor<768x768xf32> loc(#loc2)
    %2527 = cirh.Mul %2526, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2528 = cirh.Add %2525, %2527 : tensor<768x768xf32> loc(#loc2)
    %2529 = cirh.Mul %arg275, %cst_69 : tensor<f32> loc(#loc319)
    %2530 = cirh.Mul %arg276, %cst_68 : tensor<f32> loc(#loc320)
    %2531 = cirh.Sub %cst_36, %arg275 : tensor<f32> loc(#loc331)
    %2532 = cirh.Sub %cst_36, %arg276 : tensor<f32> loc(#loc332)
    %2533 = cirh.Sqrt %2532 : tensor<f32> loc(#loc333)
    %2534 = cirh.Div %2533, %2531 : tensor<f32> loc(#loc334)
    %2535 = cirh.Sqrt %2528 : tensor<768x768xf32> loc(#loc335)
    %2536 = cirh.Add %2535, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2537 = cirh.Div %2524, %2536 : tensor<768x768xf32> loc(#loc336)
    %2538 = cirh.BroadcastInDim %2534 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2539 = cirh.Mul %2537, %2538 : tensor<768x768xf32> loc(#loc337)
    %2540 = cirh.Mul %arg120, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2541 = cirh.Add %2539, %2540 : tensor<768x768xf32> loc(#loc4)
    %2542 = cirh.Mul %2541, %1985 : tensor<768x768xf32> loc(#loc338)
    %2543 = cirh.Sub %arg120, %2542 : tensor<768x768xf32> loc(#loc339)
    %2544 = cirh.Mul %1623, %1963 : tensor<768x768xf32> loc(#loc318)
    %2545 = cirh.Mul %arg277, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2546 = cirh.Mul %2544, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2547 = cirh.Add %2545, %2546 : tensor<768x768xf32> loc(#loc3)
    %2548 = cirh.Mul %arg278, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2549 = cirh.Mul %2544, %2544 : tensor<768x768xf32> loc(#loc2)
    %2550 = cirh.Mul %2549, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2551 = cirh.Add %2548, %2550 : tensor<768x768xf32> loc(#loc2)
    %2552 = cirh.Mul %arg279, %cst_69 : tensor<f32> loc(#loc319)
    %2553 = cirh.Mul %arg280, %cst_68 : tensor<f32> loc(#loc320)
    %2554 = cirh.Sub %cst_36, %arg279 : tensor<f32> loc(#loc331)
    %2555 = cirh.Sub %cst_36, %arg280 : tensor<f32> loc(#loc332)
    %2556 = cirh.Sqrt %2555 : tensor<f32> loc(#loc333)
    %2557 = cirh.Div %2556, %2554 : tensor<f32> loc(#loc334)
    %2558 = cirh.Sqrt %2551 : tensor<768x768xf32> loc(#loc335)
    %2559 = cirh.Add %2558, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2560 = cirh.Div %2547, %2559 : tensor<768x768xf32> loc(#loc336)
    %2561 = cirh.BroadcastInDim %2557 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2562 = cirh.Mul %2560, %2561 : tensor<768x768xf32> loc(#loc337)
    %2563 = cirh.Mul %arg118, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2564 = cirh.Add %2562, %2563 : tensor<768x768xf32> loc(#loc4)
    %2565 = cirh.Mul %2564, %1985 : tensor<768x768xf32> loc(#loc338)
    %2566 = cirh.Sub %arg118, %2565 : tensor<768x768xf32> loc(#loc339)
    %2567 = cirh.Mul %1620, %1963 : tensor<768x768xf32> loc(#loc318)
    %2568 = cirh.Mul %arg281, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2569 = cirh.Mul %2567, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2570 = cirh.Add %2568, %2569 : tensor<768x768xf32> loc(#loc3)
    %2571 = cirh.Mul %arg282, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2572 = cirh.Mul %2567, %2567 : tensor<768x768xf32> loc(#loc2)
    %2573 = cirh.Mul %2572, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2574 = cirh.Add %2571, %2573 : tensor<768x768xf32> loc(#loc2)
    %2575 = cirh.Mul %arg283, %cst_69 : tensor<f32> loc(#loc319)
    %2576 = cirh.Mul %arg284, %cst_68 : tensor<f32> loc(#loc320)
    %2577 = cirh.Sub %cst_36, %arg283 : tensor<f32> loc(#loc331)
    %2578 = cirh.Sub %cst_36, %arg284 : tensor<f32> loc(#loc332)
    %2579 = cirh.Sqrt %2578 : tensor<f32> loc(#loc333)
    %2580 = cirh.Div %2579, %2577 : tensor<f32> loc(#loc334)
    %2581 = cirh.Sqrt %2574 : tensor<768x768xf32> loc(#loc335)
    %2582 = cirh.Add %2581, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2583 = cirh.Div %2570, %2582 : tensor<768x768xf32> loc(#loc336)
    %2584 = cirh.BroadcastInDim %2580 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2585 = cirh.Mul %2583, %2584 : tensor<768x768xf32> loc(#loc337)
    %2586 = cirh.Mul %arg47, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2587 = cirh.Add %2585, %2586 : tensor<768x768xf32> loc(#loc4)
    %2588 = cirh.Mul %2587, %1985 : tensor<768x768xf32> loc(#loc338)
    %2589 = cirh.Sub %arg47, %2588 : tensor<768x768xf32> loc(#loc339)
    %2590 = cirh.Mul %1617, %1963 : tensor<768x768xf32> loc(#loc318)
    %2591 = cirh.Mul %arg285, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2592 = cirh.Mul %2590, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2593 = cirh.Add %2591, %2592 : tensor<768x768xf32> loc(#loc3)
    %2594 = cirh.Mul %arg286, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2595 = cirh.Mul %2590, %2590 : tensor<768x768xf32> loc(#loc2)
    %2596 = cirh.Mul %2595, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2597 = cirh.Add %2594, %2596 : tensor<768x768xf32> loc(#loc2)
    %2598 = cirh.Mul %arg287, %cst_69 : tensor<f32> loc(#loc319)
    %2599 = cirh.Mul %arg288, %cst_68 : tensor<f32> loc(#loc320)
    %2600 = cirh.Sub %cst_36, %arg287 : tensor<f32> loc(#loc331)
    %2601 = cirh.Sub %cst_36, %arg288 : tensor<f32> loc(#loc332)
    %2602 = cirh.Sqrt %2601 : tensor<f32> loc(#loc333)
    %2603 = cirh.Div %2602, %2600 : tensor<f32> loc(#loc334)
    %2604 = cirh.Sqrt %2597 : tensor<768x768xf32> loc(#loc335)
    %2605 = cirh.Add %2604, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2606 = cirh.Div %2593, %2605 : tensor<768x768xf32> loc(#loc336)
    %2607 = cirh.BroadcastInDim %2603 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2608 = cirh.Mul %2606, %2607 : tensor<768x768xf32> loc(#loc337)
    %2609 = cirh.Mul %arg46, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2610 = cirh.Add %2608, %2609 : tensor<768x768xf32> loc(#loc4)
    %2611 = cirh.Mul %2610, %1985 : tensor<768x768xf32> loc(#loc338)
    %2612 = cirh.Sub %arg46, %2611 : tensor<768x768xf32> loc(#loc339)
    %2613 = cirh.Mul %1614, %2057 : tensor<3072x768xf32> loc(#loc318)
    %2614 = cirh.Mul %arg289, %cst_20 : tensor<3072x768xf32> loc(#loc3)
    %2615 = cirh.Mul %2613, %cst_19 : tensor<3072x768xf32> loc(#loc3)
    %2616 = cirh.Add %2614, %2615 : tensor<3072x768xf32> loc(#loc3)
    %2617 = cirh.Mul %arg290, %cst_18 : tensor<3072x768xf32> loc(#loc2)
    %2618 = cirh.Mul %2613, %2613 : tensor<3072x768xf32> loc(#loc2)
    %2619 = cirh.Mul %2618, %cst_17 : tensor<3072x768xf32> loc(#loc2)
    %2620 = cirh.Add %2617, %2619 : tensor<3072x768xf32> loc(#loc2)
    %2621 = cirh.Mul %arg291, %cst_69 : tensor<f32> loc(#loc319)
    %2622 = cirh.Mul %arg292, %cst_68 : tensor<f32> loc(#loc320)
    %2623 = cirh.Sub %cst_36, %arg291 : tensor<f32> loc(#loc331)
    %2624 = cirh.Sub %cst_36, %arg292 : tensor<f32> loc(#loc332)
    %2625 = cirh.Sqrt %2624 : tensor<f32> loc(#loc333)
    %2626 = cirh.Div %2625, %2623 : tensor<f32> loc(#loc334)
    %2627 = cirh.Sqrt %2620 : tensor<3072x768xf32> loc(#loc335)
    %2628 = cirh.Add %2627, %cst_16 : tensor<3072x768xf32> loc(#loc1)
    %2629 = cirh.Div %2616, %2628 : tensor<3072x768xf32> loc(#loc336)
    %2630 = cirh.BroadcastInDim %2626 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc337)
    %2631 = cirh.Mul %2629, %2630 : tensor<3072x768xf32> loc(#loc337)
    %2632 = cirh.Mul %arg43, %cst_15 : tensor<3072x768xf32> loc(#loc4)
    %2633 = cirh.Add %2631, %2632 : tensor<3072x768xf32> loc(#loc4)
    %2634 = cirh.Mul %2633, %2079 : tensor<3072x768xf32> loc(#loc338)
    %2635 = cirh.Sub %arg43, %2634 : tensor<3072x768xf32> loc(#loc339)
    %2636 = cirh.Mul %1611, %2082 : tensor<768x3072xf32> loc(#loc318)
    %2637 = cirh.Mul %arg293, %cst_14 : tensor<768x3072xf32> loc(#loc3)
    %2638 = cirh.Mul %2636, %cst_13 : tensor<768x3072xf32> loc(#loc3)
    %2639 = cirh.Add %2637, %2638 : tensor<768x3072xf32> loc(#loc3)
    %2640 = cirh.Mul %arg294, %cst_12 : tensor<768x3072xf32> loc(#loc2)
    %2641 = cirh.Mul %2636, %2636 : tensor<768x3072xf32> loc(#loc2)
    %2642 = cirh.Mul %2641, %cst_11 : tensor<768x3072xf32> loc(#loc2)
    %2643 = cirh.Add %2640, %2642 : tensor<768x3072xf32> loc(#loc2)
    %2644 = cirh.Mul %arg295, %cst_69 : tensor<f32> loc(#loc319)
    %2645 = cirh.Mul %arg296, %cst_68 : tensor<f32> loc(#loc320)
    %2646 = cirh.Sub %cst_36, %arg295 : tensor<f32> loc(#loc331)
    %2647 = cirh.Sub %cst_36, %arg296 : tensor<f32> loc(#loc332)
    %2648 = cirh.Sqrt %2647 : tensor<f32> loc(#loc333)
    %2649 = cirh.Div %2648, %2646 : tensor<f32> loc(#loc334)
    %2650 = cirh.Sqrt %2643 : tensor<768x3072xf32> loc(#loc335)
    %2651 = cirh.Add %2650, %cst_10 : tensor<768x3072xf32> loc(#loc1)
    %2652 = cirh.Div %2639, %2651 : tensor<768x3072xf32> loc(#loc336)
    %2653 = cirh.BroadcastInDim %2649 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc337)
    %2654 = cirh.Mul %2652, %2653 : tensor<768x3072xf32> loc(#loc337)
    %2655 = cirh.Mul %arg42, %cst_9 : tensor<768x3072xf32> loc(#loc4)
    %2656 = cirh.Add %2654, %2655 : tensor<768x3072xf32> loc(#loc4)
    %2657 = cirh.Mul %2656, %2104 : tensor<768x3072xf32> loc(#loc338)
    %2658 = cirh.Sub %arg42, %2657 : tensor<768x3072xf32> loc(#loc339)
    %2659 = cirh.Mul %1608, %1963 : tensor<768x768xf32> loc(#loc318)
    %2660 = cirh.Mul %arg297, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2661 = cirh.Mul %2659, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2662 = cirh.Add %2660, %2661 : tensor<768x768xf32> loc(#loc3)
    %2663 = cirh.Mul %arg298, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2664 = cirh.Mul %2659, %2659 : tensor<768x768xf32> loc(#loc2)
    %2665 = cirh.Mul %2664, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2666 = cirh.Add %2663, %2665 : tensor<768x768xf32> loc(#loc2)
    %2667 = cirh.Mul %arg299, %cst_69 : tensor<f32> loc(#loc319)
    %2668 = cirh.Mul %arg300, %cst_68 : tensor<f32> loc(#loc320)
    %2669 = cirh.Sub %cst_36, %arg299 : tensor<f32> loc(#loc331)
    %2670 = cirh.Sub %cst_36, %arg300 : tensor<f32> loc(#loc332)
    %2671 = cirh.Sqrt %2670 : tensor<f32> loc(#loc333)
    %2672 = cirh.Div %2671, %2669 : tensor<f32> loc(#loc334)
    %2673 = cirh.Sqrt %2666 : tensor<768x768xf32> loc(#loc335)
    %2674 = cirh.Add %2673, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2675 = cirh.Div %2662, %2674 : tensor<768x768xf32> loc(#loc336)
    %2676 = cirh.BroadcastInDim %2672 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2677 = cirh.Mul %2675, %2676 : tensor<768x768xf32> loc(#loc337)
    %2678 = cirh.Mul %arg128, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2679 = cirh.Add %2677, %2678 : tensor<768x768xf32> loc(#loc4)
    %2680 = cirh.Mul %2679, %1985 : tensor<768x768xf32> loc(#loc338)
    %2681 = cirh.Sub %arg128, %2680 : tensor<768x768xf32> loc(#loc339)
    %2682 = cirh.Mul %1605, %1963 : tensor<768x768xf32> loc(#loc318)
    %2683 = cirh.Mul %arg301, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2684 = cirh.Mul %2682, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2685 = cirh.Add %2683, %2684 : tensor<768x768xf32> loc(#loc3)
    %2686 = cirh.Mul %arg302, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2687 = cirh.Mul %2682, %2682 : tensor<768x768xf32> loc(#loc2)
    %2688 = cirh.Mul %2687, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2689 = cirh.Add %2686, %2688 : tensor<768x768xf32> loc(#loc2)
    %2690 = cirh.Mul %arg303, %cst_69 : tensor<f32> loc(#loc319)
    %2691 = cirh.Mul %arg304, %cst_68 : tensor<f32> loc(#loc320)
    %2692 = cirh.Sub %cst_36, %arg303 : tensor<f32> loc(#loc331)
    %2693 = cirh.Sub %cst_36, %arg304 : tensor<f32> loc(#loc332)
    %2694 = cirh.Sqrt %2693 : tensor<f32> loc(#loc333)
    %2695 = cirh.Div %2694, %2692 : tensor<f32> loc(#loc334)
    %2696 = cirh.Sqrt %2689 : tensor<768x768xf32> loc(#loc335)
    %2697 = cirh.Add %2696, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2698 = cirh.Div %2685, %2697 : tensor<768x768xf32> loc(#loc336)
    %2699 = cirh.BroadcastInDim %2695 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2700 = cirh.Mul %2698, %2699 : tensor<768x768xf32> loc(#loc337)
    %2701 = cirh.Mul %arg126, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2702 = cirh.Add %2700, %2701 : tensor<768x768xf32> loc(#loc4)
    %2703 = cirh.Mul %2702, %1985 : tensor<768x768xf32> loc(#loc338)
    %2704 = cirh.Sub %arg126, %2703 : tensor<768x768xf32> loc(#loc339)
    %2705 = cirh.Mul %1602, %1963 : tensor<768x768xf32> loc(#loc318)
    %2706 = cirh.Mul %arg305, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2707 = cirh.Mul %2705, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2708 = cirh.Add %2706, %2707 : tensor<768x768xf32> loc(#loc3)
    %2709 = cirh.Mul %arg306, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2710 = cirh.Mul %2705, %2705 : tensor<768x768xf32> loc(#loc2)
    %2711 = cirh.Mul %2710, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2712 = cirh.Add %2709, %2711 : tensor<768x768xf32> loc(#loc2)
    %2713 = cirh.Mul %arg307, %cst_69 : tensor<f32> loc(#loc319)
    %2714 = cirh.Mul %arg308, %cst_68 : tensor<f32> loc(#loc320)
    %2715 = cirh.Sub %cst_36, %arg307 : tensor<f32> loc(#loc331)
    %2716 = cirh.Sub %cst_36, %arg308 : tensor<f32> loc(#loc332)
    %2717 = cirh.Sqrt %2716 : tensor<f32> loc(#loc333)
    %2718 = cirh.Div %2717, %2715 : tensor<f32> loc(#loc334)
    %2719 = cirh.Sqrt %2712 : tensor<768x768xf32> loc(#loc335)
    %2720 = cirh.Add %2719, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2721 = cirh.Div %2708, %2720 : tensor<768x768xf32> loc(#loc336)
    %2722 = cirh.BroadcastInDim %2718 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2723 = cirh.Mul %2721, %2722 : tensor<768x768xf32> loc(#loc337)
    %2724 = cirh.Mul %arg39, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2725 = cirh.Add %2723, %2724 : tensor<768x768xf32> loc(#loc4)
    %2726 = cirh.Mul %2725, %1985 : tensor<768x768xf32> loc(#loc338)
    %2727 = cirh.Sub %arg39, %2726 : tensor<768x768xf32> loc(#loc339)
    %2728 = cirh.Mul %1599, %1963 : tensor<768x768xf32> loc(#loc318)
    %2729 = cirh.Mul %arg309, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2730 = cirh.Mul %2728, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2731 = cirh.Add %2729, %2730 : tensor<768x768xf32> loc(#loc3)
    %2732 = cirh.Mul %arg310, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2733 = cirh.Mul %2728, %2728 : tensor<768x768xf32> loc(#loc2)
    %2734 = cirh.Mul %2733, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2735 = cirh.Add %2732, %2734 : tensor<768x768xf32> loc(#loc2)
    %2736 = cirh.Mul %arg311, %cst_69 : tensor<f32> loc(#loc319)
    %2737 = cirh.Mul %arg312, %cst_68 : tensor<f32> loc(#loc320)
    %2738 = cirh.Sub %cst_36, %arg311 : tensor<f32> loc(#loc331)
    %2739 = cirh.Sub %cst_36, %arg312 : tensor<f32> loc(#loc332)
    %2740 = cirh.Sqrt %2739 : tensor<f32> loc(#loc333)
    %2741 = cirh.Div %2740, %2738 : tensor<f32> loc(#loc334)
    %2742 = cirh.Sqrt %2735 : tensor<768x768xf32> loc(#loc335)
    %2743 = cirh.Add %2742, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2744 = cirh.Div %2731, %2743 : tensor<768x768xf32> loc(#loc336)
    %2745 = cirh.BroadcastInDim %2741 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2746 = cirh.Mul %2744, %2745 : tensor<768x768xf32> loc(#loc337)
    %2747 = cirh.Mul %arg38, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2748 = cirh.Add %2746, %2747 : tensor<768x768xf32> loc(#loc4)
    %2749 = cirh.Mul %2748, %1985 : tensor<768x768xf32> loc(#loc338)
    %2750 = cirh.Sub %arg38, %2749 : tensor<768x768xf32> loc(#loc339)
    %2751 = cirh.Mul %1596, %2057 : tensor<3072x768xf32> loc(#loc318)
    %2752 = cirh.Mul %arg313, %cst_20 : tensor<3072x768xf32> loc(#loc3)
    %2753 = cirh.Mul %2751, %cst_19 : tensor<3072x768xf32> loc(#loc3)
    %2754 = cirh.Add %2752, %2753 : tensor<3072x768xf32> loc(#loc3)
    %2755 = cirh.Mul %arg314, %cst_18 : tensor<3072x768xf32> loc(#loc2)
    %2756 = cirh.Mul %2751, %2751 : tensor<3072x768xf32> loc(#loc2)
    %2757 = cirh.Mul %2756, %cst_17 : tensor<3072x768xf32> loc(#loc2)
    %2758 = cirh.Add %2755, %2757 : tensor<3072x768xf32> loc(#loc2)
    %2759 = cirh.Mul %arg315, %cst_69 : tensor<f32> loc(#loc319)
    %2760 = cirh.Mul %arg316, %cst_68 : tensor<f32> loc(#loc320)
    %2761 = cirh.Sub %cst_36, %arg315 : tensor<f32> loc(#loc331)
    %2762 = cirh.Sub %cst_36, %arg316 : tensor<f32> loc(#loc332)
    %2763 = cirh.Sqrt %2762 : tensor<f32> loc(#loc333)
    %2764 = cirh.Div %2763, %2761 : tensor<f32> loc(#loc334)
    %2765 = cirh.Sqrt %2758 : tensor<3072x768xf32> loc(#loc335)
    %2766 = cirh.Add %2765, %cst_16 : tensor<3072x768xf32> loc(#loc1)
    %2767 = cirh.Div %2754, %2766 : tensor<3072x768xf32> loc(#loc336)
    %2768 = cirh.BroadcastInDim %2764 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc337)
    %2769 = cirh.Mul %2767, %2768 : tensor<3072x768xf32> loc(#loc337)
    %2770 = cirh.Mul %arg35, %cst_15 : tensor<3072x768xf32> loc(#loc4)
    %2771 = cirh.Add %2769, %2770 : tensor<3072x768xf32> loc(#loc4)
    %2772 = cirh.Mul %2771, %2079 : tensor<3072x768xf32> loc(#loc338)
    %2773 = cirh.Sub %arg35, %2772 : tensor<3072x768xf32> loc(#loc339)
    %2774 = cirh.Mul %1593, %2082 : tensor<768x3072xf32> loc(#loc318)
    %2775 = cirh.Mul %arg317, %cst_14 : tensor<768x3072xf32> loc(#loc3)
    %2776 = cirh.Mul %2774, %cst_13 : tensor<768x3072xf32> loc(#loc3)
    %2777 = cirh.Add %2775, %2776 : tensor<768x3072xf32> loc(#loc3)
    %2778 = cirh.Mul %arg318, %cst_12 : tensor<768x3072xf32> loc(#loc2)
    %2779 = cirh.Mul %2774, %2774 : tensor<768x3072xf32> loc(#loc2)
    %2780 = cirh.Mul %2779, %cst_11 : tensor<768x3072xf32> loc(#loc2)
    %2781 = cirh.Add %2778, %2780 : tensor<768x3072xf32> loc(#loc2)
    %2782 = cirh.Mul %arg319, %cst_69 : tensor<f32> loc(#loc319)
    %2783 = cirh.Mul %arg320, %cst_68 : tensor<f32> loc(#loc320)
    %2784 = cirh.Sub %cst_36, %arg319 : tensor<f32> loc(#loc331)
    %2785 = cirh.Sub %cst_36, %arg320 : tensor<f32> loc(#loc332)
    %2786 = cirh.Sqrt %2785 : tensor<f32> loc(#loc333)
    %2787 = cirh.Div %2786, %2784 : tensor<f32> loc(#loc334)
    %2788 = cirh.Sqrt %2781 : tensor<768x3072xf32> loc(#loc335)
    %2789 = cirh.Add %2788, %cst_10 : tensor<768x3072xf32> loc(#loc1)
    %2790 = cirh.Div %2777, %2789 : tensor<768x3072xf32> loc(#loc336)
    %2791 = cirh.BroadcastInDim %2787 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc337)
    %2792 = cirh.Mul %2790, %2791 : tensor<768x3072xf32> loc(#loc337)
    %2793 = cirh.Mul %arg34, %cst_9 : tensor<768x3072xf32> loc(#loc4)
    %2794 = cirh.Add %2792, %2793 : tensor<768x3072xf32> loc(#loc4)
    %2795 = cirh.Mul %2794, %2104 : tensor<768x3072xf32> loc(#loc338)
    %2796 = cirh.Sub %arg34, %2795 : tensor<768x3072xf32> loc(#loc339)
    %2797 = cirh.Mul %1590, %1963 : tensor<768x768xf32> loc(#loc318)
    %2798 = cirh.Mul %arg321, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2799 = cirh.Mul %2797, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2800 = cirh.Add %2798, %2799 : tensor<768x768xf32> loc(#loc3)
    %2801 = cirh.Mul %arg322, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2802 = cirh.Mul %2797, %2797 : tensor<768x768xf32> loc(#loc2)
    %2803 = cirh.Mul %2802, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2804 = cirh.Add %2801, %2803 : tensor<768x768xf32> loc(#loc2)
    %2805 = cirh.Mul %arg323, %cst_69 : tensor<f32> loc(#loc319)
    %2806 = cirh.Mul %arg324, %cst_68 : tensor<f32> loc(#loc320)
    %2807 = cirh.Sub %cst_36, %arg323 : tensor<f32> loc(#loc331)
    %2808 = cirh.Sub %cst_36, %arg324 : tensor<f32> loc(#loc332)
    %2809 = cirh.Sqrt %2808 : tensor<f32> loc(#loc333)
    %2810 = cirh.Div %2809, %2807 : tensor<f32> loc(#loc334)
    %2811 = cirh.Sqrt %2804 : tensor<768x768xf32> loc(#loc335)
    %2812 = cirh.Add %2811, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2813 = cirh.Div %2800, %2812 : tensor<768x768xf32> loc(#loc336)
    %2814 = cirh.BroadcastInDim %2810 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2815 = cirh.Mul %2813, %2814 : tensor<768x768xf32> loc(#loc337)
    %2816 = cirh.Mul %arg136, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2817 = cirh.Add %2815, %2816 : tensor<768x768xf32> loc(#loc4)
    %2818 = cirh.Mul %2817, %1985 : tensor<768x768xf32> loc(#loc338)
    %2819 = cirh.Sub %arg136, %2818 : tensor<768x768xf32> loc(#loc339)
    %2820 = cirh.Mul %1587, %1963 : tensor<768x768xf32> loc(#loc318)
    %2821 = cirh.Mul %arg325, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2822 = cirh.Mul %2820, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2823 = cirh.Add %2821, %2822 : tensor<768x768xf32> loc(#loc3)
    %2824 = cirh.Mul %arg326, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2825 = cirh.Mul %2820, %2820 : tensor<768x768xf32> loc(#loc2)
    %2826 = cirh.Mul %2825, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2827 = cirh.Add %2824, %2826 : tensor<768x768xf32> loc(#loc2)
    %2828 = cirh.Mul %arg327, %cst_69 : tensor<f32> loc(#loc319)
    %2829 = cirh.Mul %arg328, %cst_68 : tensor<f32> loc(#loc320)
    %2830 = cirh.Sub %cst_36, %arg327 : tensor<f32> loc(#loc331)
    %2831 = cirh.Sub %cst_36, %arg328 : tensor<f32> loc(#loc332)
    %2832 = cirh.Sqrt %2831 : tensor<f32> loc(#loc333)
    %2833 = cirh.Div %2832, %2830 : tensor<f32> loc(#loc334)
    %2834 = cirh.Sqrt %2827 : tensor<768x768xf32> loc(#loc335)
    %2835 = cirh.Add %2834, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2836 = cirh.Div %2823, %2835 : tensor<768x768xf32> loc(#loc336)
    %2837 = cirh.BroadcastInDim %2833 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2838 = cirh.Mul %2836, %2837 : tensor<768x768xf32> loc(#loc337)
    %2839 = cirh.Mul %arg134, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2840 = cirh.Add %2838, %2839 : tensor<768x768xf32> loc(#loc4)
    %2841 = cirh.Mul %2840, %1985 : tensor<768x768xf32> loc(#loc338)
    %2842 = cirh.Sub %arg134, %2841 : tensor<768x768xf32> loc(#loc339)
    %2843 = cirh.Mul %1584, %1963 : tensor<768x768xf32> loc(#loc318)
    %2844 = cirh.Mul %arg329, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2845 = cirh.Mul %2843, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2846 = cirh.Add %2844, %2845 : tensor<768x768xf32> loc(#loc3)
    %2847 = cirh.Mul %arg330, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2848 = cirh.Mul %2843, %2843 : tensor<768x768xf32> loc(#loc2)
    %2849 = cirh.Mul %2848, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2850 = cirh.Add %2847, %2849 : tensor<768x768xf32> loc(#loc2)
    %2851 = cirh.Mul %arg331, %cst_69 : tensor<f32> loc(#loc319)
    %2852 = cirh.Mul %arg332, %cst_68 : tensor<f32> loc(#loc320)
    %2853 = cirh.Sub %cst_36, %arg331 : tensor<f32> loc(#loc331)
    %2854 = cirh.Sub %cst_36, %arg332 : tensor<f32> loc(#loc332)
    %2855 = cirh.Sqrt %2854 : tensor<f32> loc(#loc333)
    %2856 = cirh.Div %2855, %2853 : tensor<f32> loc(#loc334)
    %2857 = cirh.Sqrt %2850 : tensor<768x768xf32> loc(#loc335)
    %2858 = cirh.Add %2857, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2859 = cirh.Div %2846, %2858 : tensor<768x768xf32> loc(#loc336)
    %2860 = cirh.BroadcastInDim %2856 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2861 = cirh.Mul %2859, %2860 : tensor<768x768xf32> loc(#loc337)
    %2862 = cirh.Mul %arg31, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2863 = cirh.Add %2861, %2862 : tensor<768x768xf32> loc(#loc4)
    %2864 = cirh.Mul %2863, %1985 : tensor<768x768xf32> loc(#loc338)
    %2865 = cirh.Sub %arg31, %2864 : tensor<768x768xf32> loc(#loc339)
    %2866 = cirh.Mul %1581, %1963 : tensor<768x768xf32> loc(#loc318)
    %2867 = cirh.Mul %arg333, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2868 = cirh.Mul %2866, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2869 = cirh.Add %2867, %2868 : tensor<768x768xf32> loc(#loc3)
    %2870 = cirh.Mul %arg334, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2871 = cirh.Mul %2866, %2866 : tensor<768x768xf32> loc(#loc2)
    %2872 = cirh.Mul %2871, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2873 = cirh.Add %2870, %2872 : tensor<768x768xf32> loc(#loc2)
    %2874 = cirh.Mul %arg335, %cst_69 : tensor<f32> loc(#loc319)
    %2875 = cirh.Mul %arg336, %cst_68 : tensor<f32> loc(#loc320)
    %2876 = cirh.Sub %cst_36, %arg335 : tensor<f32> loc(#loc331)
    %2877 = cirh.Sub %cst_36, %arg336 : tensor<f32> loc(#loc332)
    %2878 = cirh.Sqrt %2877 : tensor<f32> loc(#loc333)
    %2879 = cirh.Div %2878, %2876 : tensor<f32> loc(#loc334)
    %2880 = cirh.Sqrt %2873 : tensor<768x768xf32> loc(#loc335)
    %2881 = cirh.Add %2880, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2882 = cirh.Div %2869, %2881 : tensor<768x768xf32> loc(#loc336)
    %2883 = cirh.BroadcastInDim %2879 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2884 = cirh.Mul %2882, %2883 : tensor<768x768xf32> loc(#loc337)
    %2885 = cirh.Mul %arg30, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2886 = cirh.Add %2884, %2885 : tensor<768x768xf32> loc(#loc4)
    %2887 = cirh.Mul %2886, %1985 : tensor<768x768xf32> loc(#loc338)
    %2888 = cirh.Sub %arg30, %2887 : tensor<768x768xf32> loc(#loc339)
    %2889 = cirh.Mul %1578, %2057 : tensor<3072x768xf32> loc(#loc318)
    %2890 = cirh.Mul %arg337, %cst_20 : tensor<3072x768xf32> loc(#loc3)
    %2891 = cirh.Mul %2889, %cst_19 : tensor<3072x768xf32> loc(#loc3)
    %2892 = cirh.Add %2890, %2891 : tensor<3072x768xf32> loc(#loc3)
    %2893 = cirh.Mul %arg338, %cst_18 : tensor<3072x768xf32> loc(#loc2)
    %2894 = cirh.Mul %2889, %2889 : tensor<3072x768xf32> loc(#loc2)
    %2895 = cirh.Mul %2894, %cst_17 : tensor<3072x768xf32> loc(#loc2)
    %2896 = cirh.Add %2893, %2895 : tensor<3072x768xf32> loc(#loc2)
    %2897 = cirh.Mul %arg339, %cst_69 : tensor<f32> loc(#loc319)
    %2898 = cirh.Mul %arg340, %cst_68 : tensor<f32> loc(#loc320)
    %2899 = cirh.Sub %cst_36, %arg339 : tensor<f32> loc(#loc331)
    %2900 = cirh.Sub %cst_36, %arg340 : tensor<f32> loc(#loc332)
    %2901 = cirh.Sqrt %2900 : tensor<f32> loc(#loc333)
    %2902 = cirh.Div %2901, %2899 : tensor<f32> loc(#loc334)
    %2903 = cirh.Sqrt %2896 : tensor<3072x768xf32> loc(#loc335)
    %2904 = cirh.Add %2903, %cst_16 : tensor<3072x768xf32> loc(#loc1)
    %2905 = cirh.Div %2892, %2904 : tensor<3072x768xf32> loc(#loc336)
    %2906 = cirh.BroadcastInDim %2902 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc337)
    %2907 = cirh.Mul %2905, %2906 : tensor<3072x768xf32> loc(#loc337)
    %2908 = cirh.Mul %arg27, %cst_15 : tensor<3072x768xf32> loc(#loc4)
    %2909 = cirh.Add %2907, %2908 : tensor<3072x768xf32> loc(#loc4)
    %2910 = cirh.Mul %2909, %2079 : tensor<3072x768xf32> loc(#loc338)
    %2911 = cirh.Sub %arg27, %2910 : tensor<3072x768xf32> loc(#loc339)
    %2912 = cirh.Mul %1575, %2082 : tensor<768x3072xf32> loc(#loc318)
    %2913 = cirh.Mul %arg341, %cst_14 : tensor<768x3072xf32> loc(#loc3)
    %2914 = cirh.Mul %2912, %cst_13 : tensor<768x3072xf32> loc(#loc3)
    %2915 = cirh.Add %2913, %2914 : tensor<768x3072xf32> loc(#loc3)
    %2916 = cirh.Mul %arg342, %cst_12 : tensor<768x3072xf32> loc(#loc2)
    %2917 = cirh.Mul %2912, %2912 : tensor<768x3072xf32> loc(#loc2)
    %2918 = cirh.Mul %2917, %cst_11 : tensor<768x3072xf32> loc(#loc2)
    %2919 = cirh.Add %2916, %2918 : tensor<768x3072xf32> loc(#loc2)
    %2920 = cirh.Mul %arg343, %cst_69 : tensor<f32> loc(#loc319)
    %2921 = cirh.Mul %arg344, %cst_68 : tensor<f32> loc(#loc320)
    %2922 = cirh.Sub %cst_36, %arg343 : tensor<f32> loc(#loc331)
    %2923 = cirh.Sub %cst_36, %arg344 : tensor<f32> loc(#loc332)
    %2924 = cirh.Sqrt %2923 : tensor<f32> loc(#loc333)
    %2925 = cirh.Div %2924, %2922 : tensor<f32> loc(#loc334)
    %2926 = cirh.Sqrt %2919 : tensor<768x3072xf32> loc(#loc335)
    %2927 = cirh.Add %2926, %cst_10 : tensor<768x3072xf32> loc(#loc1)
    %2928 = cirh.Div %2915, %2927 : tensor<768x3072xf32> loc(#loc336)
    %2929 = cirh.BroadcastInDim %2925 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc337)
    %2930 = cirh.Mul %2928, %2929 : tensor<768x3072xf32> loc(#loc337)
    %2931 = cirh.Mul %arg26, %cst_9 : tensor<768x3072xf32> loc(#loc4)
    %2932 = cirh.Add %2930, %2931 : tensor<768x3072xf32> loc(#loc4)
    %2933 = cirh.Mul %2932, %2104 : tensor<768x3072xf32> loc(#loc338)
    %2934 = cirh.Sub %arg26, %2933 : tensor<768x3072xf32> loc(#loc339)
    %2935 = cirh.Mul %1572, %1963 : tensor<768x768xf32> loc(#loc318)
    %2936 = cirh.Mul %arg345, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2937 = cirh.Mul %2935, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2938 = cirh.Add %2936, %2937 : tensor<768x768xf32> loc(#loc3)
    %2939 = cirh.Mul %arg346, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2940 = cirh.Mul %2935, %2935 : tensor<768x768xf32> loc(#loc2)
    %2941 = cirh.Mul %2940, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2942 = cirh.Add %2939, %2941 : tensor<768x768xf32> loc(#loc2)
    %2943 = cirh.Mul %arg347, %cst_69 : tensor<f32> loc(#loc319)
    %2944 = cirh.Mul %arg348, %cst_68 : tensor<f32> loc(#loc320)
    %2945 = cirh.Sub %cst_36, %arg347 : tensor<f32> loc(#loc331)
    %2946 = cirh.Sub %cst_36, %arg348 : tensor<f32> loc(#loc332)
    %2947 = cirh.Sqrt %2946 : tensor<f32> loc(#loc333)
    %2948 = cirh.Div %2947, %2945 : tensor<f32> loc(#loc334)
    %2949 = cirh.Sqrt %2942 : tensor<768x768xf32> loc(#loc335)
    %2950 = cirh.Add %2949, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2951 = cirh.Div %2938, %2950 : tensor<768x768xf32> loc(#loc336)
    %2952 = cirh.BroadcastInDim %2948 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2953 = cirh.Mul %2951, %2952 : tensor<768x768xf32> loc(#loc337)
    %2954 = cirh.Mul %arg144, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2955 = cirh.Add %2953, %2954 : tensor<768x768xf32> loc(#loc4)
    %2956 = cirh.Mul %2955, %1985 : tensor<768x768xf32> loc(#loc338)
    %2957 = cirh.Sub %arg144, %2956 : tensor<768x768xf32> loc(#loc339)
    %2958 = cirh.Mul %1569, %1963 : tensor<768x768xf32> loc(#loc318)
    %2959 = cirh.Mul %arg349, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2960 = cirh.Mul %2958, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2961 = cirh.Add %2959, %2960 : tensor<768x768xf32> loc(#loc3)
    %2962 = cirh.Mul %arg350, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2963 = cirh.Mul %2958, %2958 : tensor<768x768xf32> loc(#loc2)
    %2964 = cirh.Mul %2963, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2965 = cirh.Add %2962, %2964 : tensor<768x768xf32> loc(#loc2)
    %2966 = cirh.Mul %arg351, %cst_69 : tensor<f32> loc(#loc319)
    %2967 = cirh.Mul %arg352, %cst_68 : tensor<f32> loc(#loc320)
    %2968 = cirh.Sub %cst_36, %arg351 : tensor<f32> loc(#loc331)
    %2969 = cirh.Sub %cst_36, %arg352 : tensor<f32> loc(#loc332)
    %2970 = cirh.Sqrt %2969 : tensor<f32> loc(#loc333)
    %2971 = cirh.Div %2970, %2968 : tensor<f32> loc(#loc334)
    %2972 = cirh.Sqrt %2965 : tensor<768x768xf32> loc(#loc335)
    %2973 = cirh.Add %2972, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2974 = cirh.Div %2961, %2973 : tensor<768x768xf32> loc(#loc336)
    %2975 = cirh.BroadcastInDim %2971 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2976 = cirh.Mul %2974, %2975 : tensor<768x768xf32> loc(#loc337)
    %2977 = cirh.Mul %arg142, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %2978 = cirh.Add %2976, %2977 : tensor<768x768xf32> loc(#loc4)
    %2979 = cirh.Mul %2978, %1985 : tensor<768x768xf32> loc(#loc338)
    %2980 = cirh.Sub %arg142, %2979 : tensor<768x768xf32> loc(#loc339)
    %2981 = cirh.Mul %1566, %1963 : tensor<768x768xf32> loc(#loc318)
    %2982 = cirh.Mul %arg353, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %2983 = cirh.Mul %2981, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %2984 = cirh.Add %2982, %2983 : tensor<768x768xf32> loc(#loc3)
    %2985 = cirh.Mul %arg354, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %2986 = cirh.Mul %2981, %2981 : tensor<768x768xf32> loc(#loc2)
    %2987 = cirh.Mul %2986, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %2988 = cirh.Add %2985, %2987 : tensor<768x768xf32> loc(#loc2)
    %2989 = cirh.Mul %arg355, %cst_69 : tensor<f32> loc(#loc319)
    %2990 = cirh.Mul %arg356, %cst_68 : tensor<f32> loc(#loc320)
    %2991 = cirh.Sub %cst_36, %arg355 : tensor<f32> loc(#loc331)
    %2992 = cirh.Sub %cst_36, %arg356 : tensor<f32> loc(#loc332)
    %2993 = cirh.Sqrt %2992 : tensor<f32> loc(#loc333)
    %2994 = cirh.Div %2993, %2991 : tensor<f32> loc(#loc334)
    %2995 = cirh.Sqrt %2988 : tensor<768x768xf32> loc(#loc335)
    %2996 = cirh.Add %2995, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %2997 = cirh.Div %2984, %2996 : tensor<768x768xf32> loc(#loc336)
    %2998 = cirh.BroadcastInDim %2994 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %2999 = cirh.Mul %2997, %2998 : tensor<768x768xf32> loc(#loc337)
    %3000 = cirh.Mul %arg23, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %3001 = cirh.Add %2999, %3000 : tensor<768x768xf32> loc(#loc4)
    %3002 = cirh.Mul %3001, %1985 : tensor<768x768xf32> loc(#loc338)
    %3003 = cirh.Sub %arg23, %3002 : tensor<768x768xf32> loc(#loc339)
    %3004 = cirh.Mul %1563, %1963 : tensor<768x768xf32> loc(#loc318)
    %3005 = cirh.Mul %arg357, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %3006 = cirh.Mul %3004, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %3007 = cirh.Add %3005, %3006 : tensor<768x768xf32> loc(#loc3)
    %3008 = cirh.Mul %arg358, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %3009 = cirh.Mul %3004, %3004 : tensor<768x768xf32> loc(#loc2)
    %3010 = cirh.Mul %3009, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %3011 = cirh.Add %3008, %3010 : tensor<768x768xf32> loc(#loc2)
    %3012 = cirh.Mul %arg359, %cst_69 : tensor<f32> loc(#loc319)
    %3013 = cirh.Mul %arg360, %cst_68 : tensor<f32> loc(#loc320)
    %3014 = cirh.Sub %cst_36, %arg359 : tensor<f32> loc(#loc331)
    %3015 = cirh.Sub %cst_36, %arg360 : tensor<f32> loc(#loc332)
    %3016 = cirh.Sqrt %3015 : tensor<f32> loc(#loc333)
    %3017 = cirh.Div %3016, %3014 : tensor<f32> loc(#loc334)
    %3018 = cirh.Sqrt %3011 : tensor<768x768xf32> loc(#loc335)
    %3019 = cirh.Add %3018, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %3020 = cirh.Div %3007, %3019 : tensor<768x768xf32> loc(#loc336)
    %3021 = cirh.BroadcastInDim %3017 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %3022 = cirh.Mul %3020, %3021 : tensor<768x768xf32> loc(#loc337)
    %3023 = cirh.Mul %arg22, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %3024 = cirh.Add %3022, %3023 : tensor<768x768xf32> loc(#loc4)
    %3025 = cirh.Mul %3024, %1985 : tensor<768x768xf32> loc(#loc338)
    %3026 = cirh.Sub %arg22, %3025 : tensor<768x768xf32> loc(#loc339)
    %3027 = cirh.Mul %1560, %2057 : tensor<3072x768xf32> loc(#loc318)
    %3028 = cirh.Mul %arg361, %cst_20 : tensor<3072x768xf32> loc(#loc3)
    %3029 = cirh.Mul %3027, %cst_19 : tensor<3072x768xf32> loc(#loc3)
    %3030 = cirh.Add %3028, %3029 : tensor<3072x768xf32> loc(#loc3)
    %3031 = cirh.Mul %arg362, %cst_18 : tensor<3072x768xf32> loc(#loc2)
    %3032 = cirh.Mul %3027, %3027 : tensor<3072x768xf32> loc(#loc2)
    %3033 = cirh.Mul %3032, %cst_17 : tensor<3072x768xf32> loc(#loc2)
    %3034 = cirh.Add %3031, %3033 : tensor<3072x768xf32> loc(#loc2)
    %3035 = cirh.Mul %arg363, %cst_69 : tensor<f32> loc(#loc319)
    %3036 = cirh.Mul %arg364, %cst_68 : tensor<f32> loc(#loc320)
    %3037 = cirh.Sub %cst_36, %arg363 : tensor<f32> loc(#loc331)
    %3038 = cirh.Sub %cst_36, %arg364 : tensor<f32> loc(#loc332)
    %3039 = cirh.Sqrt %3038 : tensor<f32> loc(#loc333)
    %3040 = cirh.Div %3039, %3037 : tensor<f32> loc(#loc334)
    %3041 = cirh.Sqrt %3034 : tensor<3072x768xf32> loc(#loc335)
    %3042 = cirh.Add %3041, %cst_16 : tensor<3072x768xf32> loc(#loc1)
    %3043 = cirh.Div %3030, %3042 : tensor<3072x768xf32> loc(#loc336)
    %3044 = cirh.BroadcastInDim %3040 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc337)
    %3045 = cirh.Mul %3043, %3044 : tensor<3072x768xf32> loc(#loc337)
    %3046 = cirh.Mul %arg19, %cst_15 : tensor<3072x768xf32> loc(#loc4)
    %3047 = cirh.Add %3045, %3046 : tensor<3072x768xf32> loc(#loc4)
    %3048 = cirh.Mul %3047, %2079 : tensor<3072x768xf32> loc(#loc338)
    %3049 = cirh.Sub %arg19, %3048 : tensor<3072x768xf32> loc(#loc339)
    %3050 = cirh.Mul %1557, %2082 : tensor<768x3072xf32> loc(#loc318)
    %3051 = cirh.Mul %arg365, %cst_14 : tensor<768x3072xf32> loc(#loc3)
    %3052 = cirh.Mul %3050, %cst_13 : tensor<768x3072xf32> loc(#loc3)
    %3053 = cirh.Add %3051, %3052 : tensor<768x3072xf32> loc(#loc3)
    %3054 = cirh.Mul %arg366, %cst_12 : tensor<768x3072xf32> loc(#loc2)
    %3055 = cirh.Mul %3050, %3050 : tensor<768x3072xf32> loc(#loc2)
    %3056 = cirh.Mul %3055, %cst_11 : tensor<768x3072xf32> loc(#loc2)
    %3057 = cirh.Add %3054, %3056 : tensor<768x3072xf32> loc(#loc2)
    %3058 = cirh.Mul %arg367, %cst_69 : tensor<f32> loc(#loc319)
    %3059 = cirh.Mul %arg368, %cst_68 : tensor<f32> loc(#loc320)
    %3060 = cirh.Sub %cst_36, %arg367 : tensor<f32> loc(#loc331)
    %3061 = cirh.Sub %cst_36, %arg368 : tensor<f32> loc(#loc332)
    %3062 = cirh.Sqrt %3061 : tensor<f32> loc(#loc333)
    %3063 = cirh.Div %3062, %3060 : tensor<f32> loc(#loc334)
    %3064 = cirh.Sqrt %3057 : tensor<768x3072xf32> loc(#loc335)
    %3065 = cirh.Add %3064, %cst_10 : tensor<768x3072xf32> loc(#loc1)
    %3066 = cirh.Div %3053, %3065 : tensor<768x3072xf32> loc(#loc336)
    %3067 = cirh.BroadcastInDim %3063 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc337)
    %3068 = cirh.Mul %3066, %3067 : tensor<768x3072xf32> loc(#loc337)
    %3069 = cirh.Mul %arg18, %cst_9 : tensor<768x3072xf32> loc(#loc4)
    %3070 = cirh.Add %3068, %3069 : tensor<768x3072xf32> loc(#loc4)
    %3071 = cirh.Mul %3070, %2104 : tensor<768x3072xf32> loc(#loc338)
    %3072 = cirh.Sub %arg18, %3071 : tensor<768x3072xf32> loc(#loc339)
    %3073 = cirh.Mul %1554, %1963 : tensor<768x768xf32> loc(#loc318)
    %3074 = cirh.Mul %arg369, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %3075 = cirh.Mul %3073, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %3076 = cirh.Add %3074, %3075 : tensor<768x768xf32> loc(#loc3)
    %3077 = cirh.Mul %arg370, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %3078 = cirh.Mul %3073, %3073 : tensor<768x768xf32> loc(#loc2)
    %3079 = cirh.Mul %3078, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %3080 = cirh.Add %3077, %3079 : tensor<768x768xf32> loc(#loc2)
    %3081 = cirh.Mul %arg371, %cst_69 : tensor<f32> loc(#loc319)
    %3082 = cirh.Mul %arg372, %cst_68 : tensor<f32> loc(#loc320)
    %3083 = cirh.Sub %cst_36, %arg371 : tensor<f32> loc(#loc331)
    %3084 = cirh.Sub %cst_36, %arg372 : tensor<f32> loc(#loc332)
    %3085 = cirh.Sqrt %3084 : tensor<f32> loc(#loc333)
    %3086 = cirh.Div %3085, %3083 : tensor<f32> loc(#loc334)
    %3087 = cirh.Sqrt %3080 : tensor<768x768xf32> loc(#loc335)
    %3088 = cirh.Add %3087, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %3089 = cirh.Div %3076, %3088 : tensor<768x768xf32> loc(#loc336)
    %3090 = cirh.BroadcastInDim %3086 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %3091 = cirh.Mul %3089, %3090 : tensor<768x768xf32> loc(#loc337)
    %3092 = cirh.Mul %arg152, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %3093 = cirh.Add %3091, %3092 : tensor<768x768xf32> loc(#loc4)
    %3094 = cirh.Mul %3093, %1985 : tensor<768x768xf32> loc(#loc338)
    %3095 = cirh.Sub %arg152, %3094 : tensor<768x768xf32> loc(#loc339)
    %3096 = cirh.Mul %1551, %1963 : tensor<768x768xf32> loc(#loc318)
    %3097 = cirh.Mul %arg373, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %3098 = cirh.Mul %3096, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %3099 = cirh.Add %3097, %3098 : tensor<768x768xf32> loc(#loc3)
    %3100 = cirh.Mul %arg374, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %3101 = cirh.Mul %3096, %3096 : tensor<768x768xf32> loc(#loc2)
    %3102 = cirh.Mul %3101, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %3103 = cirh.Add %3100, %3102 : tensor<768x768xf32> loc(#loc2)
    %3104 = cirh.Mul %arg375, %cst_69 : tensor<f32> loc(#loc319)
    %3105 = cirh.Mul %arg376, %cst_68 : tensor<f32> loc(#loc320)
    %3106 = cirh.Sub %cst_36, %arg375 : tensor<f32> loc(#loc331)
    %3107 = cirh.Sub %cst_36, %arg376 : tensor<f32> loc(#loc332)
    %3108 = cirh.Sqrt %3107 : tensor<f32> loc(#loc333)
    %3109 = cirh.Div %3108, %3106 : tensor<f32> loc(#loc334)
    %3110 = cirh.Sqrt %3103 : tensor<768x768xf32> loc(#loc335)
    %3111 = cirh.Add %3110, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %3112 = cirh.Div %3099, %3111 : tensor<768x768xf32> loc(#loc336)
    %3113 = cirh.BroadcastInDim %3109 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %3114 = cirh.Mul %3112, %3113 : tensor<768x768xf32> loc(#loc337)
    %3115 = cirh.Mul %arg150, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %3116 = cirh.Add %3114, %3115 : tensor<768x768xf32> loc(#loc4)
    %3117 = cirh.Mul %3116, %1985 : tensor<768x768xf32> loc(#loc338)
    %3118 = cirh.Sub %arg150, %3117 : tensor<768x768xf32> loc(#loc339)
    %3119 = cirh.Mul %1548, %1963 : tensor<768x768xf32> loc(#loc318)
    %3120 = cirh.Mul %arg377, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %3121 = cirh.Mul %3119, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %3122 = cirh.Add %3120, %3121 : tensor<768x768xf32> loc(#loc3)
    %3123 = cirh.Mul %arg378, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %3124 = cirh.Mul %3119, %3119 : tensor<768x768xf32> loc(#loc2)
    %3125 = cirh.Mul %3124, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %3126 = cirh.Add %3123, %3125 : tensor<768x768xf32> loc(#loc2)
    %3127 = cirh.Mul %arg379, %cst_69 : tensor<f32> loc(#loc319)
    %3128 = cirh.Mul %arg380, %cst_68 : tensor<f32> loc(#loc320)
    %3129 = cirh.Sub %cst_36, %arg379 : tensor<f32> loc(#loc331)
    %3130 = cirh.Sub %cst_36, %arg380 : tensor<f32> loc(#loc332)
    %3131 = cirh.Sqrt %3130 : tensor<f32> loc(#loc333)
    %3132 = cirh.Div %3131, %3129 : tensor<f32> loc(#loc334)
    %3133 = cirh.Sqrt %3126 : tensor<768x768xf32> loc(#loc335)
    %3134 = cirh.Add %3133, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %3135 = cirh.Div %3122, %3134 : tensor<768x768xf32> loc(#loc336)
    %3136 = cirh.BroadcastInDim %3132 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %3137 = cirh.Mul %3135, %3136 : tensor<768x768xf32> loc(#loc337)
    %3138 = cirh.Mul %arg15, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %3139 = cirh.Add %3137, %3138 : tensor<768x768xf32> loc(#loc4)
    %3140 = cirh.Mul %3139, %1985 : tensor<768x768xf32> loc(#loc338)
    %3141 = cirh.Sub %arg15, %3140 : tensor<768x768xf32> loc(#loc339)
    %3142 = cirh.Mul %1545, %1963 : tensor<768x768xf32> loc(#loc318)
    %3143 = cirh.Mul %arg381, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %3144 = cirh.Mul %3142, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %3145 = cirh.Add %3143, %3144 : tensor<768x768xf32> loc(#loc3)
    %3146 = cirh.Mul %arg382, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %3147 = cirh.Mul %3142, %3142 : tensor<768x768xf32> loc(#loc2)
    %3148 = cirh.Mul %3147, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %3149 = cirh.Add %3146, %3148 : tensor<768x768xf32> loc(#loc2)
    %3150 = cirh.Mul %arg383, %cst_69 : tensor<f32> loc(#loc319)
    %3151 = cirh.Mul %arg384, %cst_68 : tensor<f32> loc(#loc320)
    %3152 = cirh.Sub %cst_36, %arg383 : tensor<f32> loc(#loc331)
    %3153 = cirh.Sub %cst_36, %arg384 : tensor<f32> loc(#loc332)
    %3154 = cirh.Sqrt %3153 : tensor<f32> loc(#loc333)
    %3155 = cirh.Div %3154, %3152 : tensor<f32> loc(#loc334)
    %3156 = cirh.Sqrt %3149 : tensor<768x768xf32> loc(#loc335)
    %3157 = cirh.Add %3156, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %3158 = cirh.Div %3145, %3157 : tensor<768x768xf32> loc(#loc336)
    %3159 = cirh.BroadcastInDim %3155 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %3160 = cirh.Mul %3158, %3159 : tensor<768x768xf32> loc(#loc337)
    %3161 = cirh.Mul %arg14, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %3162 = cirh.Add %3160, %3161 : tensor<768x768xf32> loc(#loc4)
    %3163 = cirh.Mul %3162, %1985 : tensor<768x768xf32> loc(#loc338)
    %3164 = cirh.Sub %arg14, %3163 : tensor<768x768xf32> loc(#loc339)
    %3165 = cirh.Mul %1542, %2057 : tensor<3072x768xf32> loc(#loc318)
    %3166 = cirh.Mul %arg385, %cst_20 : tensor<3072x768xf32> loc(#loc3)
    %3167 = cirh.Mul %3165, %cst_19 : tensor<3072x768xf32> loc(#loc3)
    %3168 = cirh.Add %3166, %3167 : tensor<3072x768xf32> loc(#loc3)
    %3169 = cirh.Mul %arg386, %cst_18 : tensor<3072x768xf32> loc(#loc2)
    %3170 = cirh.Mul %3165, %3165 : tensor<3072x768xf32> loc(#loc2)
    %3171 = cirh.Mul %3170, %cst_17 : tensor<3072x768xf32> loc(#loc2)
    %3172 = cirh.Add %3169, %3171 : tensor<3072x768xf32> loc(#loc2)
    %3173 = cirh.Mul %arg387, %cst_69 : tensor<f32> loc(#loc319)
    %3174 = cirh.Mul %arg388, %cst_68 : tensor<f32> loc(#loc320)
    %3175 = cirh.Sub %cst_36, %arg387 : tensor<f32> loc(#loc331)
    %3176 = cirh.Sub %cst_36, %arg388 : tensor<f32> loc(#loc332)
    %3177 = cirh.Sqrt %3176 : tensor<f32> loc(#loc333)
    %3178 = cirh.Div %3177, %3175 : tensor<f32> loc(#loc334)
    %3179 = cirh.Sqrt %3172 : tensor<3072x768xf32> loc(#loc335)
    %3180 = cirh.Add %3179, %cst_16 : tensor<3072x768xf32> loc(#loc1)
    %3181 = cirh.Div %3168, %3180 : tensor<3072x768xf32> loc(#loc336)
    %3182 = cirh.BroadcastInDim %3178 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc337)
    %3183 = cirh.Mul %3181, %3182 : tensor<3072x768xf32> loc(#loc337)
    %3184 = cirh.Mul %arg11, %cst_15 : tensor<3072x768xf32> loc(#loc4)
    %3185 = cirh.Add %3183, %3184 : tensor<3072x768xf32> loc(#loc4)
    %3186 = cirh.Mul %3185, %2079 : tensor<3072x768xf32> loc(#loc338)
    %3187 = cirh.Sub %arg11, %3186 : tensor<3072x768xf32> loc(#loc339)
    %3188 = cirh.Mul %1539, %2082 : tensor<768x3072xf32> loc(#loc318)
    %3189 = cirh.Mul %arg389, %cst_14 : tensor<768x3072xf32> loc(#loc3)
    %3190 = cirh.Mul %3188, %cst_13 : tensor<768x3072xf32> loc(#loc3)
    %3191 = cirh.Add %3189, %3190 : tensor<768x3072xf32> loc(#loc3)
    %3192 = cirh.Mul %arg390, %cst_12 : tensor<768x3072xf32> loc(#loc2)
    %3193 = cirh.Mul %3188, %3188 : tensor<768x3072xf32> loc(#loc2)
    %3194 = cirh.Mul %3193, %cst_11 : tensor<768x3072xf32> loc(#loc2)
    %3195 = cirh.Add %3192, %3194 : tensor<768x3072xf32> loc(#loc2)
    %3196 = cirh.Mul %arg391, %cst_69 : tensor<f32> loc(#loc319)
    %3197 = cirh.Mul %arg392, %cst_68 : tensor<f32> loc(#loc320)
    %3198 = cirh.Sub %cst_36, %arg391 : tensor<f32> loc(#loc331)
    %3199 = cirh.Sub %cst_36, %arg392 : tensor<f32> loc(#loc332)
    %3200 = cirh.Sqrt %3199 : tensor<f32> loc(#loc333)
    %3201 = cirh.Div %3200, %3198 : tensor<f32> loc(#loc334)
    %3202 = cirh.Sqrt %3195 : tensor<768x3072xf32> loc(#loc335)
    %3203 = cirh.Add %3202, %cst_10 : tensor<768x3072xf32> loc(#loc1)
    %3204 = cirh.Div %3191, %3203 : tensor<768x3072xf32> loc(#loc336)
    %3205 = cirh.BroadcastInDim %3201 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc337)
    %3206 = cirh.Mul %3204, %3205 : tensor<768x3072xf32> loc(#loc337)
    %3207 = cirh.Mul %arg10, %cst_9 : tensor<768x3072xf32> loc(#loc4)
    %3208 = cirh.Add %3206, %3207 : tensor<768x3072xf32> loc(#loc4)
    %3209 = cirh.Mul %3208, %2104 : tensor<768x3072xf32> loc(#loc338)
    %3210 = cirh.Sub %arg10, %3209 : tensor<768x3072xf32> loc(#loc339)
    %3211 = cirh.Mul %1536, %1963 : tensor<768x768xf32> loc(#loc318)
    %3212 = cirh.Mul %arg393, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %3213 = cirh.Mul %3211, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %3214 = cirh.Add %3212, %3213 : tensor<768x768xf32> loc(#loc3)
    %3215 = cirh.Mul %arg394, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %3216 = cirh.Mul %3211, %3211 : tensor<768x768xf32> loc(#loc2)
    %3217 = cirh.Mul %3216, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %3218 = cirh.Add %3215, %3217 : tensor<768x768xf32> loc(#loc2)
    %3219 = cirh.Mul %arg395, %cst_69 : tensor<f32> loc(#loc319)
    %3220 = cirh.Mul %arg396, %cst_68 : tensor<f32> loc(#loc320)
    %3221 = cirh.Sub %cst_36, %arg395 : tensor<f32> loc(#loc331)
    %3222 = cirh.Sub %cst_36, %arg396 : tensor<f32> loc(#loc332)
    %3223 = cirh.Sqrt %3222 : tensor<f32> loc(#loc333)
    %3224 = cirh.Div %3223, %3221 : tensor<f32> loc(#loc334)
    %3225 = cirh.Sqrt %3218 : tensor<768x768xf32> loc(#loc335)
    %3226 = cirh.Add %3225, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %3227 = cirh.Div %3214, %3226 : tensor<768x768xf32> loc(#loc336)
    %3228 = cirh.BroadcastInDim %3224 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %3229 = cirh.Mul %3227, %3228 : tensor<768x768xf32> loc(#loc337)
    %3230 = cirh.Mul %arg160, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %3231 = cirh.Add %3229, %3230 : tensor<768x768xf32> loc(#loc4)
    %3232 = cirh.Mul %3231, %1985 : tensor<768x768xf32> loc(#loc338)
    %3233 = cirh.Sub %arg160, %3232 : tensor<768x768xf32> loc(#loc339)
    %3234 = cirh.Mul %1533, %1963 : tensor<768x768xf32> loc(#loc318)
    %3235 = cirh.Mul %arg397, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %3236 = cirh.Mul %3234, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %3237 = cirh.Add %3235, %3236 : tensor<768x768xf32> loc(#loc3)
    %3238 = cirh.Mul %arg398, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %3239 = cirh.Mul %3234, %3234 : tensor<768x768xf32> loc(#loc2)
    %3240 = cirh.Mul %3239, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %3241 = cirh.Add %3238, %3240 : tensor<768x768xf32> loc(#loc2)
    %3242 = cirh.Mul %arg399, %cst_69 : tensor<f32> loc(#loc319)
    %3243 = cirh.Mul %arg400, %cst_68 : tensor<f32> loc(#loc320)
    %3244 = cirh.Sub %cst_36, %arg399 : tensor<f32> loc(#loc331)
    %3245 = cirh.Sub %cst_36, %arg400 : tensor<f32> loc(#loc332)
    %3246 = cirh.Sqrt %3245 : tensor<f32> loc(#loc333)
    %3247 = cirh.Div %3246, %3244 : tensor<f32> loc(#loc334)
    %3248 = cirh.Sqrt %3241 : tensor<768x768xf32> loc(#loc335)
    %3249 = cirh.Add %3248, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %3250 = cirh.Div %3237, %3249 : tensor<768x768xf32> loc(#loc336)
    %3251 = cirh.BroadcastInDim %3247 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %3252 = cirh.Mul %3250, %3251 : tensor<768x768xf32> loc(#loc337)
    %3253 = cirh.Mul %arg158, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %3254 = cirh.Add %3252, %3253 : tensor<768x768xf32> loc(#loc4)
    %3255 = cirh.Mul %3254, %1985 : tensor<768x768xf32> loc(#loc338)
    %3256 = cirh.Sub %arg158, %3255 : tensor<768x768xf32> loc(#loc339)
    %3257 = cirh.Mul %1530, %1963 : tensor<768x768xf32> loc(#loc318)
    %3258 = cirh.Mul %arg401, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %3259 = cirh.Mul %3257, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %3260 = cirh.Add %3258, %3259 : tensor<768x768xf32> loc(#loc3)
    %3261 = cirh.Mul %arg402, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %3262 = cirh.Mul %3257, %3257 : tensor<768x768xf32> loc(#loc2)
    %3263 = cirh.Mul %3262, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %3264 = cirh.Add %3261, %3263 : tensor<768x768xf32> loc(#loc2)
    %3265 = cirh.Mul %arg403, %cst_69 : tensor<f32> loc(#loc319)
    %3266 = cirh.Mul %arg404, %cst_68 : tensor<f32> loc(#loc320)
    %3267 = cirh.Sub %cst_36, %arg403 : tensor<f32> loc(#loc331)
    %3268 = cirh.Sub %cst_36, %arg404 : tensor<f32> loc(#loc332)
    %3269 = cirh.Sqrt %3268 : tensor<f32> loc(#loc333)
    %3270 = cirh.Div %3269, %3267 : tensor<f32> loc(#loc334)
    %3271 = cirh.Sqrt %3264 : tensor<768x768xf32> loc(#loc335)
    %3272 = cirh.Add %3271, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %3273 = cirh.Div %3260, %3272 : tensor<768x768xf32> loc(#loc336)
    %3274 = cirh.BroadcastInDim %3270 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %3275 = cirh.Mul %3273, %3274 : tensor<768x768xf32> loc(#loc337)
    %3276 = cirh.Mul %arg7, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %3277 = cirh.Add %3275, %3276 : tensor<768x768xf32> loc(#loc4)
    %3278 = cirh.Mul %3277, %1985 : tensor<768x768xf32> loc(#loc338)
    %3279 = cirh.Sub %arg7, %3278 : tensor<768x768xf32> loc(#loc339)
    %3280 = cirh.Mul %1527, %1963 : tensor<768x768xf32> loc(#loc318)
    %3281 = cirh.Mul %arg405, %cst_26 : tensor<768x768xf32> loc(#loc3)
    %3282 = cirh.Mul %3280, %cst_25 : tensor<768x768xf32> loc(#loc3)
    %3283 = cirh.Add %3281, %3282 : tensor<768x768xf32> loc(#loc3)
    %3284 = cirh.Mul %arg406, %cst_24 : tensor<768x768xf32> loc(#loc2)
    %3285 = cirh.Mul %3280, %3280 : tensor<768x768xf32> loc(#loc2)
    %3286 = cirh.Mul %3285, %cst_23 : tensor<768x768xf32> loc(#loc2)
    %3287 = cirh.Add %3284, %3286 : tensor<768x768xf32> loc(#loc2)
    %3288 = cirh.Mul %arg407, %cst_69 : tensor<f32> loc(#loc319)
    %3289 = cirh.Mul %arg408, %cst_68 : tensor<f32> loc(#loc320)
    %3290 = cirh.Sub %cst_36, %arg407 : tensor<f32> loc(#loc331)
    %3291 = cirh.Sub %cst_36, %arg408 : tensor<f32> loc(#loc332)
    %3292 = cirh.Sqrt %3291 : tensor<f32> loc(#loc333)
    %3293 = cirh.Div %3292, %3290 : tensor<f32> loc(#loc334)
    %3294 = cirh.Sqrt %3287 : tensor<768x768xf32> loc(#loc335)
    %3295 = cirh.Add %3294, %cst_22 : tensor<768x768xf32> loc(#loc1)
    %3296 = cirh.Div %3283, %3295 : tensor<768x768xf32> loc(#loc336)
    %3297 = cirh.BroadcastInDim %3293 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x768xf32> loc(#loc337)
    %3298 = cirh.Mul %3296, %3297 : tensor<768x768xf32> loc(#loc337)
    %3299 = cirh.Mul %arg6, %cst_21 : tensor<768x768xf32> loc(#loc4)
    %3300 = cirh.Add %3298, %3299 : tensor<768x768xf32> loc(#loc4)
    %3301 = cirh.Mul %3300, %1985 : tensor<768x768xf32> loc(#loc338)
    %3302 = cirh.Sub %arg6, %3301 : tensor<768x768xf32> loc(#loc339)
    %3303 = cirh.Mul %1524, %2057 : tensor<3072x768xf32> loc(#loc318)
    %3304 = cirh.Mul %arg409, %cst_20 : tensor<3072x768xf32> loc(#loc3)
    %3305 = cirh.Mul %3303, %cst_19 : tensor<3072x768xf32> loc(#loc3)
    %3306 = cirh.Add %3304, %3305 : tensor<3072x768xf32> loc(#loc3)
    %3307 = cirh.Mul %arg410, %cst_18 : tensor<3072x768xf32> loc(#loc2)
    %3308 = cirh.Mul %3303, %3303 : tensor<3072x768xf32> loc(#loc2)
    %3309 = cirh.Mul %3308, %cst_17 : tensor<3072x768xf32> loc(#loc2)
    %3310 = cirh.Add %3307, %3309 : tensor<3072x768xf32> loc(#loc2)
    %3311 = cirh.Mul %arg411, %cst_69 : tensor<f32> loc(#loc319)
    %3312 = cirh.Mul %arg412, %cst_68 : tensor<f32> loc(#loc320)
    %3313 = cirh.Sub %cst_36, %arg411 : tensor<f32> loc(#loc331)
    %3314 = cirh.Sub %cst_36, %arg412 : tensor<f32> loc(#loc332)
    %3315 = cirh.Sqrt %3314 : tensor<f32> loc(#loc333)
    %3316 = cirh.Div %3315, %3313 : tensor<f32> loc(#loc334)
    %3317 = cirh.Sqrt %3310 : tensor<3072x768xf32> loc(#loc335)
    %3318 = cirh.Add %3317, %cst_16 : tensor<3072x768xf32> loc(#loc1)
    %3319 = cirh.Div %3306, %3318 : tensor<3072x768xf32> loc(#loc336)
    %3320 = cirh.BroadcastInDim %3316 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072x768xf32> loc(#loc337)
    %3321 = cirh.Mul %3319, %3320 : tensor<3072x768xf32> loc(#loc337)
    %3322 = cirh.Mul %arg3, %cst_15 : tensor<3072x768xf32> loc(#loc4)
    %3323 = cirh.Add %3321, %3322 : tensor<3072x768xf32> loc(#loc4)
    %3324 = cirh.Mul %3323, %2079 : tensor<3072x768xf32> loc(#loc338)
    %3325 = cirh.Sub %arg3, %3324 : tensor<3072x768xf32> loc(#loc339)
    %3326 = cirh.Mul %1521, %2082 : tensor<768x3072xf32> loc(#loc318)
    %3327 = cirh.Mul %arg413, %cst_14 : tensor<768x3072xf32> loc(#loc3)
    %3328 = cirh.Mul %3326, %cst_13 : tensor<768x3072xf32> loc(#loc3)
    %3329 = cirh.Add %3327, %3328 : tensor<768x3072xf32> loc(#loc3)
    %3330 = cirh.Mul %arg414, %cst_12 : tensor<768x3072xf32> loc(#loc2)
    %3331 = cirh.Mul %3326, %3326 : tensor<768x3072xf32> loc(#loc2)
    %3332 = cirh.Mul %3331, %cst_11 : tensor<768x3072xf32> loc(#loc2)
    %3333 = cirh.Add %3330, %3332 : tensor<768x3072xf32> loc(#loc2)
    %3334 = cirh.Mul %arg415, %cst_69 : tensor<f32> loc(#loc319)
    %3335 = cirh.Mul %arg416, %cst_68 : tensor<f32> loc(#loc320)
    %3336 = cirh.Sub %cst_36, %arg415 : tensor<f32> loc(#loc331)
    %3337 = cirh.Sub %cst_36, %arg416 : tensor<f32> loc(#loc332)
    %3338 = cirh.Sqrt %3337 : tensor<f32> loc(#loc333)
    %3339 = cirh.Div %3338, %3336 : tensor<f32> loc(#loc334)
    %3340 = cirh.Sqrt %3333 : tensor<768x3072xf32> loc(#loc335)
    %3341 = cirh.Add %3340, %cst_10 : tensor<768x3072xf32> loc(#loc1)
    %3342 = cirh.Div %3329, %3341 : tensor<768x3072xf32> loc(#loc336)
    %3343 = cirh.BroadcastInDim %3339 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768x3072xf32> loc(#loc337)
    %3344 = cirh.Mul %3342, %3343 : tensor<768x3072xf32> loc(#loc337)
    %3345 = cirh.Mul %arg2, %cst_9 : tensor<768x3072xf32> loc(#loc4)
    %3346 = cirh.Add %3344, %3345 : tensor<768x3072xf32> loc(#loc4)
    %3347 = cirh.Mul %3346, %2104 : tensor<768x3072xf32> loc(#loc338)
    %3348 = cirh.Sub %arg2, %3347 : tensor<768x3072xf32> loc(#loc339)
    %3349 = cirh.BroadcastInDim %1895 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc318)
    %3350 = cirh.Mul %1518, %3349 : tensor<768xf32> loc(#loc318)
    %3351 = cirh.Mul %arg417, %cst_8 : tensor<768xf32> loc(#loc3)
    %3352 = cirh.Mul %3350, %cst_7 : tensor<768xf32> loc(#loc3)
    %3353 = cirh.Add %3351, %3352 : tensor<768xf32> loc(#loc3)
    %3354 = cirh.Mul %arg418, %cst_6 : tensor<768xf32> loc(#loc2)
    %3355 = cirh.Mul %3350, %3350 : tensor<768xf32> loc(#loc2)
    %3356 = cirh.Mul %3355, %cst_5 : tensor<768xf32> loc(#loc2)
    %3357 = cirh.Add %3354, %3356 : tensor<768xf32> loc(#loc2)
    %3358 = cirh.Mul %arg419, %cst_69 : tensor<f32> loc(#loc319)
    %3359 = cirh.Mul %arg420, %cst_68 : tensor<f32> loc(#loc320)
    %3360 = cirh.Sub %cst_36, %arg419 : tensor<f32> loc(#loc331)
    %3361 = cirh.Sub %cst_36, %arg420 : tensor<f32> loc(#loc332)
    %3362 = cirh.Sqrt %3361 : tensor<f32> loc(#loc333)
    %3363 = cirh.Div %3362, %3360 : tensor<f32> loc(#loc334)
    %3364 = cirh.Sqrt %3357 : tensor<768xf32> loc(#loc335)
    %3365 = cirh.Add %3364, %cst_4 : tensor<768xf32> loc(#loc1)
    %3366 = cirh.Div %3353, %3365 : tensor<768xf32> loc(#loc336)
    %3367 = cirh.BroadcastInDim %3363 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3368 = cirh.Mul %3366, %3367 : tensor<768xf32> loc(#loc337)
    %3369 = cirh.BroadcastInDim %1923 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc338)
    %3370 = cirh.Mul %3368, %3369 : tensor<768xf32> loc(#loc338)
    %3371 = cirh.Sub %arg89, %3370 : tensor<768xf32> loc(#loc339)
    %3372 = cirh.Mul %1513, %3349 : tensor<768xf32> loc(#loc318)
    %3373 = cirh.Mul %arg421, %cst_8 : tensor<768xf32> loc(#loc3)
    %3374 = cirh.Mul %3372, %cst_7 : tensor<768xf32> loc(#loc3)
    %3375 = cirh.Add %3373, %3374 : tensor<768xf32> loc(#loc3)
    %3376 = cirh.Mul %arg422, %cst_6 : tensor<768xf32> loc(#loc2)
    %3377 = cirh.Mul %3372, %3372 : tensor<768xf32> loc(#loc2)
    %3378 = cirh.Mul %3377, %cst_5 : tensor<768xf32> loc(#loc2)
    %3379 = cirh.Add %3376, %3378 : tensor<768xf32> loc(#loc2)
    %3380 = cirh.Mul %arg423, %cst_69 : tensor<f32> loc(#loc319)
    %3381 = cirh.Mul %arg424, %cst_68 : tensor<f32> loc(#loc320)
    %3382 = cirh.Sub %cst_36, %arg423 : tensor<f32> loc(#loc331)
    %3383 = cirh.Sub %cst_36, %arg424 : tensor<f32> loc(#loc332)
    %3384 = cirh.Sqrt %3383 : tensor<f32> loc(#loc333)
    %3385 = cirh.Div %3384, %3382 : tensor<f32> loc(#loc334)
    %3386 = cirh.Sqrt %3379 : tensor<768xf32> loc(#loc335)
    %3387 = cirh.Add %3386, %cst_4 : tensor<768xf32> loc(#loc1)
    %3388 = cirh.Div %3375, %3387 : tensor<768xf32> loc(#loc336)
    %3389 = cirh.BroadcastInDim %3385 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3390 = cirh.Mul %3388, %3389 : tensor<768xf32> loc(#loc337)
    %3391 = cirh.Mul %3390, %3369 : tensor<768xf32> loc(#loc338)
    %3392 = cirh.Sub %arg87, %3391 : tensor<768xf32> loc(#loc339)
    %3393 = cirh.Mul %1508, %3349 : tensor<768xf32> loc(#loc318)
    %3394 = cirh.Mul %arg425, %cst_8 : tensor<768xf32> loc(#loc3)
    %3395 = cirh.Mul %3393, %cst_7 : tensor<768xf32> loc(#loc3)
    %3396 = cirh.Add %3394, %3395 : tensor<768xf32> loc(#loc3)
    %3397 = cirh.Mul %arg426, %cst_6 : tensor<768xf32> loc(#loc2)
    %3398 = cirh.Mul %3393, %3393 : tensor<768xf32> loc(#loc2)
    %3399 = cirh.Mul %3398, %cst_5 : tensor<768xf32> loc(#loc2)
    %3400 = cirh.Add %3397, %3399 : tensor<768xf32> loc(#loc2)
    %3401 = cirh.Mul %arg427, %cst_69 : tensor<f32> loc(#loc319)
    %3402 = cirh.Mul %arg428, %cst_68 : tensor<f32> loc(#loc320)
    %3403 = cirh.Sub %cst_36, %arg427 : tensor<f32> loc(#loc331)
    %3404 = cirh.Sub %cst_36, %arg428 : tensor<f32> loc(#loc332)
    %3405 = cirh.Sqrt %3404 : tensor<f32> loc(#loc333)
    %3406 = cirh.Div %3405, %3403 : tensor<f32> loc(#loc334)
    %3407 = cirh.Sqrt %3400 : tensor<768xf32> loc(#loc335)
    %3408 = cirh.Add %3407, %cst_4 : tensor<768xf32> loc(#loc1)
    %3409 = cirh.Div %3396, %3408 : tensor<768xf32> loc(#loc336)
    %3410 = cirh.BroadcastInDim %3406 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3411 = cirh.Mul %3409, %3410 : tensor<768xf32> loc(#loc337)
    %3412 = cirh.Mul %3411, %3369 : tensor<768xf32> loc(#loc338)
    %3413 = cirh.Sub %arg85, %3412 : tensor<768xf32> loc(#loc339)
    %3414 = cirh.Mul %1503, %3349 : tensor<768xf32> loc(#loc318)
    %3415 = cirh.Mul %arg429, %cst_8 : tensor<768xf32> loc(#loc3)
    %3416 = cirh.Mul %3414, %cst_7 : tensor<768xf32> loc(#loc3)
    %3417 = cirh.Add %3415, %3416 : tensor<768xf32> loc(#loc3)
    %3418 = cirh.Mul %arg430, %cst_6 : tensor<768xf32> loc(#loc2)
    %3419 = cirh.Mul %3414, %3414 : tensor<768xf32> loc(#loc2)
    %3420 = cirh.Mul %3419, %cst_5 : tensor<768xf32> loc(#loc2)
    %3421 = cirh.Add %3418, %3420 : tensor<768xf32> loc(#loc2)
    %3422 = cirh.Mul %arg431, %cst_69 : tensor<f32> loc(#loc319)
    %3423 = cirh.Mul %arg432, %cst_68 : tensor<f32> loc(#loc320)
    %3424 = cirh.Sub %cst_36, %arg431 : tensor<f32> loc(#loc331)
    %3425 = cirh.Sub %cst_36, %arg432 : tensor<f32> loc(#loc332)
    %3426 = cirh.Sqrt %3425 : tensor<f32> loc(#loc333)
    %3427 = cirh.Div %3426, %3424 : tensor<f32> loc(#loc334)
    %3428 = cirh.Sqrt %3421 : tensor<768xf32> loc(#loc335)
    %3429 = cirh.Add %3428, %cst_4 : tensor<768xf32> loc(#loc1)
    %3430 = cirh.Div %3417, %3429 : tensor<768xf32> loc(#loc336)
    %3431 = cirh.BroadcastInDim %3427 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3432 = cirh.Mul %3430, %3431 : tensor<768xf32> loc(#loc337)
    %3433 = cirh.Mul %3432, %3369 : tensor<768xf32> loc(#loc338)
    %3434 = cirh.Sub %arg90, %3433 : tensor<768xf32> loc(#loc339)
    %3435 = cirh.Mul %gamma_grad_131, %3349 : tensor<768xf32> loc(#loc318)
    %3436 = cirh.Mul %arg433, %cst_8 : tensor<768xf32> loc(#loc3)
    %3437 = cirh.Mul %3435, %cst_7 : tensor<768xf32> loc(#loc3)
    %3438 = cirh.Add %3436, %3437 : tensor<768xf32> loc(#loc3)
    %3439 = cirh.Mul %arg434, %cst_6 : tensor<768xf32> loc(#loc2)
    %3440 = cirh.Mul %3435, %3435 : tensor<768xf32> loc(#loc2)
    %3441 = cirh.Mul %3440, %cst_5 : tensor<768xf32> loc(#loc2)
    %3442 = cirh.Add %3439, %3441 : tensor<768xf32> loc(#loc2)
    %3443 = cirh.Mul %arg435, %cst_69 : tensor<f32> loc(#loc319)
    %3444 = cirh.Mul %arg436, %cst_68 : tensor<f32> loc(#loc320)
    %3445 = cirh.Sub %cst_36, %arg435 : tensor<f32> loc(#loc331)
    %3446 = cirh.Sub %cst_36, %arg436 : tensor<f32> loc(#loc332)
    %3447 = cirh.Sqrt %3446 : tensor<f32> loc(#loc333)
    %3448 = cirh.Div %3447, %3445 : tensor<f32> loc(#loc334)
    %3449 = cirh.Sqrt %3442 : tensor<768xf32> loc(#loc335)
    %3450 = cirh.Add %3449, %cst_4 : tensor<768xf32> loc(#loc1)
    %3451 = cirh.Div %3438, %3450 : tensor<768xf32> loc(#loc336)
    %3452 = cirh.BroadcastInDim %3448 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3453 = cirh.Mul %3451, %3452 : tensor<768xf32> loc(#loc337)
    %3454 = cirh.Mul %3453, %3369 : tensor<768xf32> loc(#loc338)
    %3455 = cirh.Sub %arg81, %3454 : tensor<768xf32> loc(#loc339)
    %3456 = cirh.Mul %beta_grad_130, %3349 : tensor<768xf32> loc(#loc318)
    %3457 = cirh.Mul %arg437, %cst_8 : tensor<768xf32> loc(#loc3)
    %3458 = cirh.Mul %3456, %cst_7 : tensor<768xf32> loc(#loc3)
    %3459 = cirh.Add %3457, %3458 : tensor<768xf32> loc(#loc3)
    %3460 = cirh.Mul %arg438, %cst_6 : tensor<768xf32> loc(#loc2)
    %3461 = cirh.Mul %3456, %3456 : tensor<768xf32> loc(#loc2)
    %3462 = cirh.Mul %3461, %cst_5 : tensor<768xf32> loc(#loc2)
    %3463 = cirh.Add %3460, %3462 : tensor<768xf32> loc(#loc2)
    %3464 = cirh.Mul %arg439, %cst_69 : tensor<f32> loc(#loc319)
    %3465 = cirh.Mul %arg440, %cst_68 : tensor<f32> loc(#loc320)
    %3466 = cirh.Sub %cst_36, %arg439 : tensor<f32> loc(#loc331)
    %3467 = cirh.Sub %cst_36, %arg440 : tensor<f32> loc(#loc332)
    %3468 = cirh.Sqrt %3467 : tensor<f32> loc(#loc333)
    %3469 = cirh.Div %3468, %3466 : tensor<f32> loc(#loc334)
    %3470 = cirh.Sqrt %3463 : tensor<768xf32> loc(#loc335)
    %3471 = cirh.Add %3470, %cst_4 : tensor<768xf32> loc(#loc1)
    %3472 = cirh.Div %3459, %3471 : tensor<768xf32> loc(#loc336)
    %3473 = cirh.BroadcastInDim %3469 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3474 = cirh.Mul %3472, %3473 : tensor<768xf32> loc(#loc337)
    %3475 = cirh.Mul %3474, %3369 : tensor<768xf32> loc(#loc338)
    %3476 = cirh.Sub %arg80, %3475 : tensor<768xf32> loc(#loc339)
    %3477 = cirh.Mul %gamma_grad_128, %3349 : tensor<768xf32> loc(#loc318)
    %3478 = cirh.Mul %arg441, %cst_8 : tensor<768xf32> loc(#loc3)
    %3479 = cirh.Mul %3477, %cst_7 : tensor<768xf32> loc(#loc3)
    %3480 = cirh.Add %3478, %3479 : tensor<768xf32> loc(#loc3)
    %3481 = cirh.Mul %arg442, %cst_6 : tensor<768xf32> loc(#loc2)
    %3482 = cirh.Mul %3477, %3477 : tensor<768xf32> loc(#loc2)
    %3483 = cirh.Mul %3482, %cst_5 : tensor<768xf32> loc(#loc2)
    %3484 = cirh.Add %3481, %3483 : tensor<768xf32> loc(#loc2)
    %3485 = cirh.Mul %arg443, %cst_69 : tensor<f32> loc(#loc319)
    %3486 = cirh.Mul %arg444, %cst_68 : tensor<f32> loc(#loc320)
    %3487 = cirh.Sub %cst_36, %arg443 : tensor<f32> loc(#loc331)
    %3488 = cirh.Sub %cst_36, %arg444 : tensor<f32> loc(#loc332)
    %3489 = cirh.Sqrt %3488 : tensor<f32> loc(#loc333)
    %3490 = cirh.Div %3489, %3487 : tensor<f32> loc(#loc334)
    %3491 = cirh.Sqrt %3484 : tensor<768xf32> loc(#loc335)
    %3492 = cirh.Add %3491, %cst_4 : tensor<768xf32> loc(#loc1)
    %3493 = cirh.Div %3480, %3492 : tensor<768xf32> loc(#loc336)
    %3494 = cirh.BroadcastInDim %3490 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3495 = cirh.Mul %3493, %3494 : tensor<768xf32> loc(#loc337)
    %3496 = cirh.Mul %3495, %3369 : tensor<768xf32> loc(#loc338)
    %3497 = cirh.Sub %arg77, %3496 : tensor<768xf32> loc(#loc339)
    %3498 = cirh.Mul %beta_grad_127, %3349 : tensor<768xf32> loc(#loc318)
    %3499 = cirh.Mul %arg445, %cst_8 : tensor<768xf32> loc(#loc3)
    %3500 = cirh.Mul %3498, %cst_7 : tensor<768xf32> loc(#loc3)
    %3501 = cirh.Add %3499, %3500 : tensor<768xf32> loc(#loc3)
    %3502 = cirh.Mul %arg446, %cst_6 : tensor<768xf32> loc(#loc2)
    %3503 = cirh.Mul %3498, %3498 : tensor<768xf32> loc(#loc2)
    %3504 = cirh.Mul %3503, %cst_5 : tensor<768xf32> loc(#loc2)
    %3505 = cirh.Add %3502, %3504 : tensor<768xf32> loc(#loc2)
    %3506 = cirh.Mul %arg447, %cst_69 : tensor<f32> loc(#loc319)
    %3507 = cirh.Mul %arg448, %cst_68 : tensor<f32> loc(#loc320)
    %3508 = cirh.Sub %cst_36, %arg447 : tensor<f32> loc(#loc331)
    %3509 = cirh.Sub %cst_36, %arg448 : tensor<f32> loc(#loc332)
    %3510 = cirh.Sqrt %3509 : tensor<f32> loc(#loc333)
    %3511 = cirh.Div %3510, %3508 : tensor<f32> loc(#loc334)
    %3512 = cirh.Sqrt %3505 : tensor<768xf32> loc(#loc335)
    %3513 = cirh.Add %3512, %cst_4 : tensor<768xf32> loc(#loc1)
    %3514 = cirh.Div %3501, %3513 : tensor<768xf32> loc(#loc336)
    %3515 = cirh.BroadcastInDim %3511 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3516 = cirh.Mul %3514, %3515 : tensor<768xf32> loc(#loc337)
    %3517 = cirh.Mul %3516, %3369 : tensor<768xf32> loc(#loc338)
    %3518 = cirh.Sub %arg76, %3517 : tensor<768xf32> loc(#loc339)
    %3519 = cirh.BroadcastInDim %1895 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc318)
    %3520 = cirh.Mul %1453, %3519 : tensor<3072xf32> loc(#loc318)
    %3521 = cirh.Mul %arg449, %cst_3 : tensor<3072xf32> loc(#loc3)
    %3522 = cirh.Mul %3520, %cst_2 : tensor<3072xf32> loc(#loc3)
    %3523 = cirh.Add %3521, %3522 : tensor<3072xf32> loc(#loc3)
    %3524 = cirh.Mul %arg450, %cst_1 : tensor<3072xf32> loc(#loc2)
    %3525 = cirh.Mul %3520, %3520 : tensor<3072xf32> loc(#loc2)
    %3526 = cirh.Mul %3525, %cst_0 : tensor<3072xf32> loc(#loc2)
    %3527 = cirh.Add %3524, %3526 : tensor<3072xf32> loc(#loc2)
    %3528 = cirh.Mul %arg451, %cst_69 : tensor<f32> loc(#loc319)
    %3529 = cirh.Mul %arg452, %cst_68 : tensor<f32> loc(#loc320)
    %3530 = cirh.Sub %cst_36, %arg451 : tensor<f32> loc(#loc331)
    %3531 = cirh.Sub %cst_36, %arg452 : tensor<f32> loc(#loc332)
    %3532 = cirh.Sqrt %3531 : tensor<f32> loc(#loc333)
    %3533 = cirh.Div %3532, %3530 : tensor<f32> loc(#loc334)
    %3534 = cirh.Sqrt %3527 : tensor<3072xf32> loc(#loc335)
    %3535 = cirh.Add %3534, %cst : tensor<3072xf32> loc(#loc1)
    %3536 = cirh.Div %3523, %3535 : tensor<3072xf32> loc(#loc336)
    %3537 = cirh.BroadcastInDim %3533 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc337)
    %3538 = cirh.Mul %3536, %3537 : tensor<3072xf32> loc(#loc337)
    %3539 = cirh.BroadcastInDim %1923 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc338)
    %3540 = cirh.Mul %3538, %3539 : tensor<3072xf32> loc(#loc338)
    %3541 = cirh.Sub %arg91, %3540 : tensor<3072xf32> loc(#loc339)
    %3542 = cirh.Mul %1444, %3349 : tensor<768xf32> loc(#loc318)
    %3543 = cirh.Mul %arg453, %cst_8 : tensor<768xf32> loc(#loc3)
    %3544 = cirh.Mul %3542, %cst_7 : tensor<768xf32> loc(#loc3)
    %3545 = cirh.Add %3543, %3544 : tensor<768xf32> loc(#loc3)
    %3546 = cirh.Mul %arg454, %cst_6 : tensor<768xf32> loc(#loc2)
    %3547 = cirh.Mul %3542, %3542 : tensor<768xf32> loc(#loc2)
    %3548 = cirh.Mul %3547, %cst_5 : tensor<768xf32> loc(#loc2)
    %3549 = cirh.Add %3546, %3548 : tensor<768xf32> loc(#loc2)
    %3550 = cirh.Mul %arg455, %cst_69 : tensor<f32> loc(#loc319)
    %3551 = cirh.Mul %arg456, %cst_68 : tensor<f32> loc(#loc320)
    %3552 = cirh.Sub %cst_36, %arg455 : tensor<f32> loc(#loc331)
    %3553 = cirh.Sub %cst_36, %arg456 : tensor<f32> loc(#loc332)
    %3554 = cirh.Sqrt %3553 : tensor<f32> loc(#loc333)
    %3555 = cirh.Div %3554, %3552 : tensor<f32> loc(#loc334)
    %3556 = cirh.Sqrt %3549 : tensor<768xf32> loc(#loc335)
    %3557 = cirh.Add %3556, %cst_4 : tensor<768xf32> loc(#loc1)
    %3558 = cirh.Div %3545, %3557 : tensor<768xf32> loc(#loc336)
    %3559 = cirh.BroadcastInDim %3555 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3560 = cirh.Mul %3558, %3559 : tensor<768xf32> loc(#loc337)
    %3561 = cirh.Mul %3560, %3369 : tensor<768xf32> loc(#loc338)
    %3562 = cirh.Sub %arg92, %3561 : tensor<768xf32> loc(#loc339)
    %3563 = cirh.Mul %1436, %3349 : tensor<768xf32> loc(#loc318)
    %3564 = cirh.Mul %arg457, %cst_8 : tensor<768xf32> loc(#loc3)
    %3565 = cirh.Mul %3563, %cst_7 : tensor<768xf32> loc(#loc3)
    %3566 = cirh.Add %3564, %3565 : tensor<768xf32> loc(#loc3)
    %3567 = cirh.Mul %arg458, %cst_6 : tensor<768xf32> loc(#loc2)
    %3568 = cirh.Mul %3563, %3563 : tensor<768xf32> loc(#loc2)
    %3569 = cirh.Mul %3568, %cst_5 : tensor<768xf32> loc(#loc2)
    %3570 = cirh.Add %3567, %3569 : tensor<768xf32> loc(#loc2)
    %3571 = cirh.Mul %arg459, %cst_69 : tensor<f32> loc(#loc319)
    %3572 = cirh.Mul %arg460, %cst_68 : tensor<f32> loc(#loc320)
    %3573 = cirh.Sub %cst_36, %arg459 : tensor<f32> loc(#loc331)
    %3574 = cirh.Sub %cst_36, %arg460 : tensor<f32> loc(#loc332)
    %3575 = cirh.Sqrt %3574 : tensor<f32> loc(#loc333)
    %3576 = cirh.Div %3575, %3573 : tensor<f32> loc(#loc334)
    %3577 = cirh.Sqrt %3570 : tensor<768xf32> loc(#loc335)
    %3578 = cirh.Add %3577, %cst_4 : tensor<768xf32> loc(#loc1)
    %3579 = cirh.Div %3566, %3578 : tensor<768xf32> loc(#loc336)
    %3580 = cirh.BroadcastInDim %3576 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3581 = cirh.Mul %3579, %3580 : tensor<768xf32> loc(#loc337)
    %3582 = cirh.Mul %3581, %3369 : tensor<768xf32> loc(#loc338)
    %3583 = cirh.Sub %arg97, %3582 : tensor<768xf32> loc(#loc339)
    %3584 = cirh.Mul %1431, %3349 : tensor<768xf32> loc(#loc318)
    %3585 = cirh.Mul %arg461, %cst_8 : tensor<768xf32> loc(#loc3)
    %3586 = cirh.Mul %3584, %cst_7 : tensor<768xf32> loc(#loc3)
    %3587 = cirh.Add %3585, %3586 : tensor<768xf32> loc(#loc3)
    %3588 = cirh.Mul %arg462, %cst_6 : tensor<768xf32> loc(#loc2)
    %3589 = cirh.Mul %3584, %3584 : tensor<768xf32> loc(#loc2)
    %3590 = cirh.Mul %3589, %cst_5 : tensor<768xf32> loc(#loc2)
    %3591 = cirh.Add %3588, %3590 : tensor<768xf32> loc(#loc2)
    %3592 = cirh.Mul %arg463, %cst_69 : tensor<f32> loc(#loc319)
    %3593 = cirh.Mul %arg464, %cst_68 : tensor<f32> loc(#loc320)
    %3594 = cirh.Sub %cst_36, %arg463 : tensor<f32> loc(#loc331)
    %3595 = cirh.Sub %cst_36, %arg464 : tensor<f32> loc(#loc332)
    %3596 = cirh.Sqrt %3595 : tensor<f32> loc(#loc333)
    %3597 = cirh.Div %3596, %3594 : tensor<f32> loc(#loc334)
    %3598 = cirh.Sqrt %3591 : tensor<768xf32> loc(#loc335)
    %3599 = cirh.Add %3598, %cst_4 : tensor<768xf32> loc(#loc1)
    %3600 = cirh.Div %3587, %3599 : tensor<768xf32> loc(#loc336)
    %3601 = cirh.BroadcastInDim %3597 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3602 = cirh.Mul %3600, %3601 : tensor<768xf32> loc(#loc337)
    %3603 = cirh.Mul %3602, %3369 : tensor<768xf32> loc(#loc338)
    %3604 = cirh.Sub %arg95, %3603 : tensor<768xf32> loc(#loc339)
    %3605 = cirh.Mul %1426, %3349 : tensor<768xf32> loc(#loc318)
    %3606 = cirh.Mul %arg465, %cst_8 : tensor<768xf32> loc(#loc3)
    %3607 = cirh.Mul %3605, %cst_7 : tensor<768xf32> loc(#loc3)
    %3608 = cirh.Add %3606, %3607 : tensor<768xf32> loc(#loc3)
    %3609 = cirh.Mul %arg466, %cst_6 : tensor<768xf32> loc(#loc2)
    %3610 = cirh.Mul %3605, %3605 : tensor<768xf32> loc(#loc2)
    %3611 = cirh.Mul %3610, %cst_5 : tensor<768xf32> loc(#loc2)
    %3612 = cirh.Add %3609, %3611 : tensor<768xf32> loc(#loc2)
    %3613 = cirh.Mul %arg467, %cst_69 : tensor<f32> loc(#loc319)
    %3614 = cirh.Mul %arg468, %cst_68 : tensor<f32> loc(#loc320)
    %3615 = cirh.Sub %cst_36, %arg467 : tensor<f32> loc(#loc331)
    %3616 = cirh.Sub %cst_36, %arg468 : tensor<f32> loc(#loc332)
    %3617 = cirh.Sqrt %3616 : tensor<f32> loc(#loc333)
    %3618 = cirh.Div %3617, %3615 : tensor<f32> loc(#loc334)
    %3619 = cirh.Sqrt %3612 : tensor<768xf32> loc(#loc335)
    %3620 = cirh.Add %3619, %cst_4 : tensor<768xf32> loc(#loc1)
    %3621 = cirh.Div %3608, %3620 : tensor<768xf32> loc(#loc336)
    %3622 = cirh.BroadcastInDim %3618 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3623 = cirh.Mul %3621, %3622 : tensor<768xf32> loc(#loc337)
    %3624 = cirh.Mul %3623, %3369 : tensor<768xf32> loc(#loc338)
    %3625 = cirh.Sub %arg93, %3624 : tensor<768xf32> loc(#loc339)
    %3626 = cirh.Mul %1421, %3349 : tensor<768xf32> loc(#loc318)
    %3627 = cirh.Mul %arg469, %cst_8 : tensor<768xf32> loc(#loc3)
    %3628 = cirh.Mul %3626, %cst_7 : tensor<768xf32> loc(#loc3)
    %3629 = cirh.Add %3627, %3628 : tensor<768xf32> loc(#loc3)
    %3630 = cirh.Mul %arg470, %cst_6 : tensor<768xf32> loc(#loc2)
    %3631 = cirh.Mul %3626, %3626 : tensor<768xf32> loc(#loc2)
    %3632 = cirh.Mul %3631, %cst_5 : tensor<768xf32> loc(#loc2)
    %3633 = cirh.Add %3630, %3632 : tensor<768xf32> loc(#loc2)
    %3634 = cirh.Mul %arg471, %cst_69 : tensor<f32> loc(#loc319)
    %3635 = cirh.Mul %arg472, %cst_68 : tensor<f32> loc(#loc320)
    %3636 = cirh.Sub %cst_36, %arg471 : tensor<f32> loc(#loc331)
    %3637 = cirh.Sub %cst_36, %arg472 : tensor<f32> loc(#loc332)
    %3638 = cirh.Sqrt %3637 : tensor<f32> loc(#loc333)
    %3639 = cirh.Div %3638, %3636 : tensor<f32> loc(#loc334)
    %3640 = cirh.Sqrt %3633 : tensor<768xf32> loc(#loc335)
    %3641 = cirh.Add %3640, %cst_4 : tensor<768xf32> loc(#loc1)
    %3642 = cirh.Div %3629, %3641 : tensor<768xf32> loc(#loc336)
    %3643 = cirh.BroadcastInDim %3639 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3644 = cirh.Mul %3642, %3643 : tensor<768xf32> loc(#loc337)
    %3645 = cirh.Mul %3644, %3369 : tensor<768xf32> loc(#loc338)
    %3646 = cirh.Sub %arg98, %3645 : tensor<768xf32> loc(#loc339)
    %3647 = cirh.Mul %gamma_grad_125, %3349 : tensor<768xf32> loc(#loc318)
    %3648 = cirh.Mul %arg473, %cst_8 : tensor<768xf32> loc(#loc3)
    %3649 = cirh.Mul %3647, %cst_7 : tensor<768xf32> loc(#loc3)
    %3650 = cirh.Add %3648, %3649 : tensor<768xf32> loc(#loc3)
    %3651 = cirh.Mul %arg474, %cst_6 : tensor<768xf32> loc(#loc2)
    %3652 = cirh.Mul %3647, %3647 : tensor<768xf32> loc(#loc2)
    %3653 = cirh.Mul %3652, %cst_5 : tensor<768xf32> loc(#loc2)
    %3654 = cirh.Add %3651, %3653 : tensor<768xf32> loc(#loc2)
    %3655 = cirh.Mul %arg475, %cst_69 : tensor<f32> loc(#loc319)
    %3656 = cirh.Mul %arg476, %cst_68 : tensor<f32> loc(#loc320)
    %3657 = cirh.Sub %cst_36, %arg475 : tensor<f32> loc(#loc331)
    %3658 = cirh.Sub %cst_36, %arg476 : tensor<f32> loc(#loc332)
    %3659 = cirh.Sqrt %3658 : tensor<f32> loc(#loc333)
    %3660 = cirh.Div %3659, %3657 : tensor<f32> loc(#loc334)
    %3661 = cirh.Sqrt %3654 : tensor<768xf32> loc(#loc335)
    %3662 = cirh.Add %3661, %cst_4 : tensor<768xf32> loc(#loc1)
    %3663 = cirh.Div %3650, %3662 : tensor<768xf32> loc(#loc336)
    %3664 = cirh.BroadcastInDim %3660 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3665 = cirh.Mul %3663, %3664 : tensor<768xf32> loc(#loc337)
    %3666 = cirh.Mul %3665, %3369 : tensor<768xf32> loc(#loc338)
    %3667 = cirh.Sub %arg73, %3666 : tensor<768xf32> loc(#loc339)
    %3668 = cirh.Mul %beta_grad_124, %3349 : tensor<768xf32> loc(#loc318)
    %3669 = cirh.Mul %arg477, %cst_8 : tensor<768xf32> loc(#loc3)
    %3670 = cirh.Mul %3668, %cst_7 : tensor<768xf32> loc(#loc3)
    %3671 = cirh.Add %3669, %3670 : tensor<768xf32> loc(#loc3)
    %3672 = cirh.Mul %arg478, %cst_6 : tensor<768xf32> loc(#loc2)
    %3673 = cirh.Mul %3668, %3668 : tensor<768xf32> loc(#loc2)
    %3674 = cirh.Mul %3673, %cst_5 : tensor<768xf32> loc(#loc2)
    %3675 = cirh.Add %3672, %3674 : tensor<768xf32> loc(#loc2)
    %3676 = cirh.Mul %arg479, %cst_69 : tensor<f32> loc(#loc319)
    %3677 = cirh.Mul %arg480, %cst_68 : tensor<f32> loc(#loc320)
    %3678 = cirh.Sub %cst_36, %arg479 : tensor<f32> loc(#loc331)
    %3679 = cirh.Sub %cst_36, %arg480 : tensor<f32> loc(#loc332)
    %3680 = cirh.Sqrt %3679 : tensor<f32> loc(#loc333)
    %3681 = cirh.Div %3680, %3678 : tensor<f32> loc(#loc334)
    %3682 = cirh.Sqrt %3675 : tensor<768xf32> loc(#loc335)
    %3683 = cirh.Add %3682, %cst_4 : tensor<768xf32> loc(#loc1)
    %3684 = cirh.Div %3671, %3683 : tensor<768xf32> loc(#loc336)
    %3685 = cirh.BroadcastInDim %3681 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3686 = cirh.Mul %3684, %3685 : tensor<768xf32> loc(#loc337)
    %3687 = cirh.Mul %3686, %3369 : tensor<768xf32> loc(#loc338)
    %3688 = cirh.Sub %arg72, %3687 : tensor<768xf32> loc(#loc339)
    %3689 = cirh.Mul %gamma_grad_122, %3349 : tensor<768xf32> loc(#loc318)
    %3690 = cirh.Mul %arg481, %cst_8 : tensor<768xf32> loc(#loc3)
    %3691 = cirh.Mul %3689, %cst_7 : tensor<768xf32> loc(#loc3)
    %3692 = cirh.Add %3690, %3691 : tensor<768xf32> loc(#loc3)
    %3693 = cirh.Mul %arg482, %cst_6 : tensor<768xf32> loc(#loc2)
    %3694 = cirh.Mul %3689, %3689 : tensor<768xf32> loc(#loc2)
    %3695 = cirh.Mul %3694, %cst_5 : tensor<768xf32> loc(#loc2)
    %3696 = cirh.Add %3693, %3695 : tensor<768xf32> loc(#loc2)
    %3697 = cirh.Mul %arg483, %cst_69 : tensor<f32> loc(#loc319)
    %3698 = cirh.Mul %arg484, %cst_68 : tensor<f32> loc(#loc320)
    %3699 = cirh.Sub %cst_36, %arg483 : tensor<f32> loc(#loc331)
    %3700 = cirh.Sub %cst_36, %arg484 : tensor<f32> loc(#loc332)
    %3701 = cirh.Sqrt %3700 : tensor<f32> loc(#loc333)
    %3702 = cirh.Div %3701, %3699 : tensor<f32> loc(#loc334)
    %3703 = cirh.Sqrt %3696 : tensor<768xf32> loc(#loc335)
    %3704 = cirh.Add %3703, %cst_4 : tensor<768xf32> loc(#loc1)
    %3705 = cirh.Div %3692, %3704 : tensor<768xf32> loc(#loc336)
    %3706 = cirh.BroadcastInDim %3702 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3707 = cirh.Mul %3705, %3706 : tensor<768xf32> loc(#loc337)
    %3708 = cirh.Mul %3707, %3369 : tensor<768xf32> loc(#loc338)
    %3709 = cirh.Sub %arg69, %3708 : tensor<768xf32> loc(#loc339)
    %3710 = cirh.Mul %beta_grad_121, %3349 : tensor<768xf32> loc(#loc318)
    %3711 = cirh.Mul %arg485, %cst_8 : tensor<768xf32> loc(#loc3)
    %3712 = cirh.Mul %3710, %cst_7 : tensor<768xf32> loc(#loc3)
    %3713 = cirh.Add %3711, %3712 : tensor<768xf32> loc(#loc3)
    %3714 = cirh.Mul %arg486, %cst_6 : tensor<768xf32> loc(#loc2)
    %3715 = cirh.Mul %3710, %3710 : tensor<768xf32> loc(#loc2)
    %3716 = cirh.Mul %3715, %cst_5 : tensor<768xf32> loc(#loc2)
    %3717 = cirh.Add %3714, %3716 : tensor<768xf32> loc(#loc2)
    %3718 = cirh.Mul %arg487, %cst_69 : tensor<f32> loc(#loc319)
    %3719 = cirh.Mul %arg488, %cst_68 : tensor<f32> loc(#loc320)
    %3720 = cirh.Sub %cst_36, %arg487 : tensor<f32> loc(#loc331)
    %3721 = cirh.Sub %cst_36, %arg488 : tensor<f32> loc(#loc332)
    %3722 = cirh.Sqrt %3721 : tensor<f32> loc(#loc333)
    %3723 = cirh.Div %3722, %3720 : tensor<f32> loc(#loc334)
    %3724 = cirh.Sqrt %3717 : tensor<768xf32> loc(#loc335)
    %3725 = cirh.Add %3724, %cst_4 : tensor<768xf32> loc(#loc1)
    %3726 = cirh.Div %3713, %3725 : tensor<768xf32> loc(#loc336)
    %3727 = cirh.BroadcastInDim %3723 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3728 = cirh.Mul %3726, %3727 : tensor<768xf32> loc(#loc337)
    %3729 = cirh.Mul %3728, %3369 : tensor<768xf32> loc(#loc338)
    %3730 = cirh.Sub %arg68, %3729 : tensor<768xf32> loc(#loc339)
    %3731 = cirh.Mul %1371, %3519 : tensor<3072xf32> loc(#loc318)
    %3732 = cirh.Mul %arg489, %cst_3 : tensor<3072xf32> loc(#loc3)
    %3733 = cirh.Mul %3731, %cst_2 : tensor<3072xf32> loc(#loc3)
    %3734 = cirh.Add %3732, %3733 : tensor<3072xf32> loc(#loc3)
    %3735 = cirh.Mul %arg490, %cst_1 : tensor<3072xf32> loc(#loc2)
    %3736 = cirh.Mul %3731, %3731 : tensor<3072xf32> loc(#loc2)
    %3737 = cirh.Mul %3736, %cst_0 : tensor<3072xf32> loc(#loc2)
    %3738 = cirh.Add %3735, %3737 : tensor<3072xf32> loc(#loc2)
    %3739 = cirh.Mul %arg491, %cst_69 : tensor<f32> loc(#loc319)
    %3740 = cirh.Mul %arg492, %cst_68 : tensor<f32> loc(#loc320)
    %3741 = cirh.Sub %cst_36, %arg491 : tensor<f32> loc(#loc331)
    %3742 = cirh.Sub %cst_36, %arg492 : tensor<f32> loc(#loc332)
    %3743 = cirh.Sqrt %3742 : tensor<f32> loc(#loc333)
    %3744 = cirh.Div %3743, %3741 : tensor<f32> loc(#loc334)
    %3745 = cirh.Sqrt %3738 : tensor<3072xf32> loc(#loc335)
    %3746 = cirh.Add %3745, %cst : tensor<3072xf32> loc(#loc1)
    %3747 = cirh.Div %3734, %3746 : tensor<3072xf32> loc(#loc336)
    %3748 = cirh.BroadcastInDim %3744 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc337)
    %3749 = cirh.Mul %3747, %3748 : tensor<3072xf32> loc(#loc337)
    %3750 = cirh.Mul %3749, %3539 : tensor<3072xf32> loc(#loc338)
    %3751 = cirh.Sub %arg99, %3750 : tensor<3072xf32> loc(#loc339)
    %3752 = cirh.Mul %1362, %3349 : tensor<768xf32> loc(#loc318)
    %3753 = cirh.Mul %arg493, %cst_8 : tensor<768xf32> loc(#loc3)
    %3754 = cirh.Mul %3752, %cst_7 : tensor<768xf32> loc(#loc3)
    %3755 = cirh.Add %3753, %3754 : tensor<768xf32> loc(#loc3)
    %3756 = cirh.Mul %arg494, %cst_6 : tensor<768xf32> loc(#loc2)
    %3757 = cirh.Mul %3752, %3752 : tensor<768xf32> loc(#loc2)
    %3758 = cirh.Mul %3757, %cst_5 : tensor<768xf32> loc(#loc2)
    %3759 = cirh.Add %3756, %3758 : tensor<768xf32> loc(#loc2)
    %3760 = cirh.Mul %arg495, %cst_69 : tensor<f32> loc(#loc319)
    %3761 = cirh.Mul %arg496, %cst_68 : tensor<f32> loc(#loc320)
    %3762 = cirh.Sub %cst_36, %arg495 : tensor<f32> loc(#loc331)
    %3763 = cirh.Sub %cst_36, %arg496 : tensor<f32> loc(#loc332)
    %3764 = cirh.Sqrt %3763 : tensor<f32> loc(#loc333)
    %3765 = cirh.Div %3764, %3762 : tensor<f32> loc(#loc334)
    %3766 = cirh.Sqrt %3759 : tensor<768xf32> loc(#loc335)
    %3767 = cirh.Add %3766, %cst_4 : tensor<768xf32> loc(#loc1)
    %3768 = cirh.Div %3755, %3767 : tensor<768xf32> loc(#loc336)
    %3769 = cirh.BroadcastInDim %3765 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3770 = cirh.Mul %3768, %3769 : tensor<768xf32> loc(#loc337)
    %3771 = cirh.Mul %3770, %3369 : tensor<768xf32> loc(#loc338)
    %3772 = cirh.Sub %arg100, %3771 : tensor<768xf32> loc(#loc339)
    %3773 = cirh.Mul %1354, %3349 : tensor<768xf32> loc(#loc318)
    %3774 = cirh.Mul %arg497, %cst_8 : tensor<768xf32> loc(#loc3)
    %3775 = cirh.Mul %3773, %cst_7 : tensor<768xf32> loc(#loc3)
    %3776 = cirh.Add %3774, %3775 : tensor<768xf32> loc(#loc3)
    %3777 = cirh.Mul %arg498, %cst_6 : tensor<768xf32> loc(#loc2)
    %3778 = cirh.Mul %3773, %3773 : tensor<768xf32> loc(#loc2)
    %3779 = cirh.Mul %3778, %cst_5 : tensor<768xf32> loc(#loc2)
    %3780 = cirh.Add %3777, %3779 : tensor<768xf32> loc(#loc2)
    %3781 = cirh.Mul %arg499, %cst_69 : tensor<f32> loc(#loc319)
    %3782 = cirh.Mul %arg500, %cst_68 : tensor<f32> loc(#loc320)
    %3783 = cirh.Sub %cst_36, %arg499 : tensor<f32> loc(#loc331)
    %3784 = cirh.Sub %cst_36, %arg500 : tensor<f32> loc(#loc332)
    %3785 = cirh.Sqrt %3784 : tensor<f32> loc(#loc333)
    %3786 = cirh.Div %3785, %3783 : tensor<f32> loc(#loc334)
    %3787 = cirh.Sqrt %3780 : tensor<768xf32> loc(#loc335)
    %3788 = cirh.Add %3787, %cst_4 : tensor<768xf32> loc(#loc1)
    %3789 = cirh.Div %3776, %3788 : tensor<768xf32> loc(#loc336)
    %3790 = cirh.BroadcastInDim %3786 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3791 = cirh.Mul %3789, %3790 : tensor<768xf32> loc(#loc337)
    %3792 = cirh.Mul %3791, %3369 : tensor<768xf32> loc(#loc338)
    %3793 = cirh.Sub %arg105, %3792 : tensor<768xf32> loc(#loc339)
    %3794 = cirh.Mul %1349, %3349 : tensor<768xf32> loc(#loc318)
    %3795 = cirh.Mul %arg501, %cst_8 : tensor<768xf32> loc(#loc3)
    %3796 = cirh.Mul %3794, %cst_7 : tensor<768xf32> loc(#loc3)
    %3797 = cirh.Add %3795, %3796 : tensor<768xf32> loc(#loc3)
    %3798 = cirh.Mul %arg502, %cst_6 : tensor<768xf32> loc(#loc2)
    %3799 = cirh.Mul %3794, %3794 : tensor<768xf32> loc(#loc2)
    %3800 = cirh.Mul %3799, %cst_5 : tensor<768xf32> loc(#loc2)
    %3801 = cirh.Add %3798, %3800 : tensor<768xf32> loc(#loc2)
    %3802 = cirh.Mul %arg503, %cst_69 : tensor<f32> loc(#loc319)
    %3803 = cirh.Mul %arg504, %cst_68 : tensor<f32> loc(#loc320)
    %3804 = cirh.Sub %cst_36, %arg503 : tensor<f32> loc(#loc331)
    %3805 = cirh.Sub %cst_36, %arg504 : tensor<f32> loc(#loc332)
    %3806 = cirh.Sqrt %3805 : tensor<f32> loc(#loc333)
    %3807 = cirh.Div %3806, %3804 : tensor<f32> loc(#loc334)
    %3808 = cirh.Sqrt %3801 : tensor<768xf32> loc(#loc335)
    %3809 = cirh.Add %3808, %cst_4 : tensor<768xf32> loc(#loc1)
    %3810 = cirh.Div %3797, %3809 : tensor<768xf32> loc(#loc336)
    %3811 = cirh.BroadcastInDim %3807 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3812 = cirh.Mul %3810, %3811 : tensor<768xf32> loc(#loc337)
    %3813 = cirh.Mul %3812, %3369 : tensor<768xf32> loc(#loc338)
    %3814 = cirh.Sub %arg103, %3813 : tensor<768xf32> loc(#loc339)
    %3815 = cirh.Mul %1344, %3349 : tensor<768xf32> loc(#loc318)
    %3816 = cirh.Mul %arg505, %cst_8 : tensor<768xf32> loc(#loc3)
    %3817 = cirh.Mul %3815, %cst_7 : tensor<768xf32> loc(#loc3)
    %3818 = cirh.Add %3816, %3817 : tensor<768xf32> loc(#loc3)
    %3819 = cirh.Mul %arg506, %cst_6 : tensor<768xf32> loc(#loc2)
    %3820 = cirh.Mul %3815, %3815 : tensor<768xf32> loc(#loc2)
    %3821 = cirh.Mul %3820, %cst_5 : tensor<768xf32> loc(#loc2)
    %3822 = cirh.Add %3819, %3821 : tensor<768xf32> loc(#loc2)
    %3823 = cirh.Mul %arg507, %cst_69 : tensor<f32> loc(#loc319)
    %3824 = cirh.Mul %arg508, %cst_68 : tensor<f32> loc(#loc320)
    %3825 = cirh.Sub %cst_36, %arg507 : tensor<f32> loc(#loc331)
    %3826 = cirh.Sub %cst_36, %arg508 : tensor<f32> loc(#loc332)
    %3827 = cirh.Sqrt %3826 : tensor<f32> loc(#loc333)
    %3828 = cirh.Div %3827, %3825 : tensor<f32> loc(#loc334)
    %3829 = cirh.Sqrt %3822 : tensor<768xf32> loc(#loc335)
    %3830 = cirh.Add %3829, %cst_4 : tensor<768xf32> loc(#loc1)
    %3831 = cirh.Div %3818, %3830 : tensor<768xf32> loc(#loc336)
    %3832 = cirh.BroadcastInDim %3828 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3833 = cirh.Mul %3831, %3832 : tensor<768xf32> loc(#loc337)
    %3834 = cirh.Mul %3833, %3369 : tensor<768xf32> loc(#loc338)
    %3835 = cirh.Sub %arg101, %3834 : tensor<768xf32> loc(#loc339)
    %3836 = cirh.Mul %1339, %3349 : tensor<768xf32> loc(#loc318)
    %3837 = cirh.Mul %arg509, %cst_8 : tensor<768xf32> loc(#loc3)
    %3838 = cirh.Mul %3836, %cst_7 : tensor<768xf32> loc(#loc3)
    %3839 = cirh.Add %3837, %3838 : tensor<768xf32> loc(#loc3)
    %3840 = cirh.Mul %arg510, %cst_6 : tensor<768xf32> loc(#loc2)
    %3841 = cirh.Mul %3836, %3836 : tensor<768xf32> loc(#loc2)
    %3842 = cirh.Mul %3841, %cst_5 : tensor<768xf32> loc(#loc2)
    %3843 = cirh.Add %3840, %3842 : tensor<768xf32> loc(#loc2)
    %3844 = cirh.Mul %arg511, %cst_69 : tensor<f32> loc(#loc319)
    %3845 = cirh.Mul %arg512, %cst_68 : tensor<f32> loc(#loc320)
    %3846 = cirh.Sub %cst_36, %arg511 : tensor<f32> loc(#loc331)
    %3847 = cirh.Sub %cst_36, %arg512 : tensor<f32> loc(#loc332)
    %3848 = cirh.Sqrt %3847 : tensor<f32> loc(#loc333)
    %3849 = cirh.Div %3848, %3846 : tensor<f32> loc(#loc334)
    %3850 = cirh.Sqrt %3843 : tensor<768xf32> loc(#loc335)
    %3851 = cirh.Add %3850, %cst_4 : tensor<768xf32> loc(#loc1)
    %3852 = cirh.Div %3839, %3851 : tensor<768xf32> loc(#loc336)
    %3853 = cirh.BroadcastInDim %3849 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3854 = cirh.Mul %3852, %3853 : tensor<768xf32> loc(#loc337)
    %3855 = cirh.Mul %3854, %3369 : tensor<768xf32> loc(#loc338)
    %3856 = cirh.Sub %arg106, %3855 : tensor<768xf32> loc(#loc339)
    %3857 = cirh.Mul %gamma_grad_119, %3349 : tensor<768xf32> loc(#loc318)
    %3858 = cirh.Mul %arg513, %cst_8 : tensor<768xf32> loc(#loc3)
    %3859 = cirh.Mul %3857, %cst_7 : tensor<768xf32> loc(#loc3)
    %3860 = cirh.Add %3858, %3859 : tensor<768xf32> loc(#loc3)
    %3861 = cirh.Mul %arg514, %cst_6 : tensor<768xf32> loc(#loc2)
    %3862 = cirh.Mul %3857, %3857 : tensor<768xf32> loc(#loc2)
    %3863 = cirh.Mul %3862, %cst_5 : tensor<768xf32> loc(#loc2)
    %3864 = cirh.Add %3861, %3863 : tensor<768xf32> loc(#loc2)
    %3865 = cirh.Mul %arg515, %cst_69 : tensor<f32> loc(#loc319)
    %3866 = cirh.Mul %arg516, %cst_68 : tensor<f32> loc(#loc320)
    %3867 = cirh.Sub %cst_36, %arg515 : tensor<f32> loc(#loc331)
    %3868 = cirh.Sub %cst_36, %arg516 : tensor<f32> loc(#loc332)
    %3869 = cirh.Sqrt %3868 : tensor<f32> loc(#loc333)
    %3870 = cirh.Div %3869, %3867 : tensor<f32> loc(#loc334)
    %3871 = cirh.Sqrt %3864 : tensor<768xf32> loc(#loc335)
    %3872 = cirh.Add %3871, %cst_4 : tensor<768xf32> loc(#loc1)
    %3873 = cirh.Div %3860, %3872 : tensor<768xf32> loc(#loc336)
    %3874 = cirh.BroadcastInDim %3870 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3875 = cirh.Mul %3873, %3874 : tensor<768xf32> loc(#loc337)
    %3876 = cirh.Mul %3875, %3369 : tensor<768xf32> loc(#loc338)
    %3877 = cirh.Sub %arg65, %3876 : tensor<768xf32> loc(#loc339)
    %3878 = cirh.Mul %beta_grad_118, %3349 : tensor<768xf32> loc(#loc318)
    %3879 = cirh.Mul %arg517, %cst_8 : tensor<768xf32> loc(#loc3)
    %3880 = cirh.Mul %3878, %cst_7 : tensor<768xf32> loc(#loc3)
    %3881 = cirh.Add %3879, %3880 : tensor<768xf32> loc(#loc3)
    %3882 = cirh.Mul %arg518, %cst_6 : tensor<768xf32> loc(#loc2)
    %3883 = cirh.Mul %3878, %3878 : tensor<768xf32> loc(#loc2)
    %3884 = cirh.Mul %3883, %cst_5 : tensor<768xf32> loc(#loc2)
    %3885 = cirh.Add %3882, %3884 : tensor<768xf32> loc(#loc2)
    %3886 = cirh.Mul %arg519, %cst_69 : tensor<f32> loc(#loc319)
    %3887 = cirh.Mul %arg520, %cst_68 : tensor<f32> loc(#loc320)
    %3888 = cirh.Sub %cst_36, %arg519 : tensor<f32> loc(#loc331)
    %3889 = cirh.Sub %cst_36, %arg520 : tensor<f32> loc(#loc332)
    %3890 = cirh.Sqrt %3889 : tensor<f32> loc(#loc333)
    %3891 = cirh.Div %3890, %3888 : tensor<f32> loc(#loc334)
    %3892 = cirh.Sqrt %3885 : tensor<768xf32> loc(#loc335)
    %3893 = cirh.Add %3892, %cst_4 : tensor<768xf32> loc(#loc1)
    %3894 = cirh.Div %3881, %3893 : tensor<768xf32> loc(#loc336)
    %3895 = cirh.BroadcastInDim %3891 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3896 = cirh.Mul %3894, %3895 : tensor<768xf32> loc(#loc337)
    %3897 = cirh.Mul %3896, %3369 : tensor<768xf32> loc(#loc338)
    %3898 = cirh.Sub %arg64, %3897 : tensor<768xf32> loc(#loc339)
    %3899 = cirh.Mul %gamma_grad_116, %3349 : tensor<768xf32> loc(#loc318)
    %3900 = cirh.Mul %arg521, %cst_8 : tensor<768xf32> loc(#loc3)
    %3901 = cirh.Mul %3899, %cst_7 : tensor<768xf32> loc(#loc3)
    %3902 = cirh.Add %3900, %3901 : tensor<768xf32> loc(#loc3)
    %3903 = cirh.Mul %arg522, %cst_6 : tensor<768xf32> loc(#loc2)
    %3904 = cirh.Mul %3899, %3899 : tensor<768xf32> loc(#loc2)
    %3905 = cirh.Mul %3904, %cst_5 : tensor<768xf32> loc(#loc2)
    %3906 = cirh.Add %3903, %3905 : tensor<768xf32> loc(#loc2)
    %3907 = cirh.Mul %arg523, %cst_69 : tensor<f32> loc(#loc319)
    %3908 = cirh.Mul %arg524, %cst_68 : tensor<f32> loc(#loc320)
    %3909 = cirh.Sub %cst_36, %arg523 : tensor<f32> loc(#loc331)
    %3910 = cirh.Sub %cst_36, %arg524 : tensor<f32> loc(#loc332)
    %3911 = cirh.Sqrt %3910 : tensor<f32> loc(#loc333)
    %3912 = cirh.Div %3911, %3909 : tensor<f32> loc(#loc334)
    %3913 = cirh.Sqrt %3906 : tensor<768xf32> loc(#loc335)
    %3914 = cirh.Add %3913, %cst_4 : tensor<768xf32> loc(#loc1)
    %3915 = cirh.Div %3902, %3914 : tensor<768xf32> loc(#loc336)
    %3916 = cirh.BroadcastInDim %3912 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3917 = cirh.Mul %3915, %3916 : tensor<768xf32> loc(#loc337)
    %3918 = cirh.Mul %3917, %3369 : tensor<768xf32> loc(#loc338)
    %3919 = cirh.Sub %arg61, %3918 : tensor<768xf32> loc(#loc339)
    %3920 = cirh.Mul %beta_grad_115, %3349 : tensor<768xf32> loc(#loc318)
    %3921 = cirh.Mul %arg525, %cst_8 : tensor<768xf32> loc(#loc3)
    %3922 = cirh.Mul %3920, %cst_7 : tensor<768xf32> loc(#loc3)
    %3923 = cirh.Add %3921, %3922 : tensor<768xf32> loc(#loc3)
    %3924 = cirh.Mul %arg526, %cst_6 : tensor<768xf32> loc(#loc2)
    %3925 = cirh.Mul %3920, %3920 : tensor<768xf32> loc(#loc2)
    %3926 = cirh.Mul %3925, %cst_5 : tensor<768xf32> loc(#loc2)
    %3927 = cirh.Add %3924, %3926 : tensor<768xf32> loc(#loc2)
    %3928 = cirh.Mul %arg527, %cst_69 : tensor<f32> loc(#loc319)
    %3929 = cirh.Mul %arg528, %cst_68 : tensor<f32> loc(#loc320)
    %3930 = cirh.Sub %cst_36, %arg527 : tensor<f32> loc(#loc331)
    %3931 = cirh.Sub %cst_36, %arg528 : tensor<f32> loc(#loc332)
    %3932 = cirh.Sqrt %3931 : tensor<f32> loc(#loc333)
    %3933 = cirh.Div %3932, %3930 : tensor<f32> loc(#loc334)
    %3934 = cirh.Sqrt %3927 : tensor<768xf32> loc(#loc335)
    %3935 = cirh.Add %3934, %cst_4 : tensor<768xf32> loc(#loc1)
    %3936 = cirh.Div %3923, %3935 : tensor<768xf32> loc(#loc336)
    %3937 = cirh.BroadcastInDim %3933 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3938 = cirh.Mul %3936, %3937 : tensor<768xf32> loc(#loc337)
    %3939 = cirh.Mul %3938, %3369 : tensor<768xf32> loc(#loc338)
    %3940 = cirh.Sub %arg60, %3939 : tensor<768xf32> loc(#loc339)
    %3941 = cirh.Mul %1289, %3519 : tensor<3072xf32> loc(#loc318)
    %3942 = cirh.Mul %arg529, %cst_3 : tensor<3072xf32> loc(#loc3)
    %3943 = cirh.Mul %3941, %cst_2 : tensor<3072xf32> loc(#loc3)
    %3944 = cirh.Add %3942, %3943 : tensor<3072xf32> loc(#loc3)
    %3945 = cirh.Mul %arg530, %cst_1 : tensor<3072xf32> loc(#loc2)
    %3946 = cirh.Mul %3941, %3941 : tensor<3072xf32> loc(#loc2)
    %3947 = cirh.Mul %3946, %cst_0 : tensor<3072xf32> loc(#loc2)
    %3948 = cirh.Add %3945, %3947 : tensor<3072xf32> loc(#loc2)
    %3949 = cirh.Mul %arg531, %cst_69 : tensor<f32> loc(#loc319)
    %3950 = cirh.Mul %arg532, %cst_68 : tensor<f32> loc(#loc320)
    %3951 = cirh.Sub %cst_36, %arg531 : tensor<f32> loc(#loc331)
    %3952 = cirh.Sub %cst_36, %arg532 : tensor<f32> loc(#loc332)
    %3953 = cirh.Sqrt %3952 : tensor<f32> loc(#loc333)
    %3954 = cirh.Div %3953, %3951 : tensor<f32> loc(#loc334)
    %3955 = cirh.Sqrt %3948 : tensor<3072xf32> loc(#loc335)
    %3956 = cirh.Add %3955, %cst : tensor<3072xf32> loc(#loc1)
    %3957 = cirh.Div %3944, %3956 : tensor<3072xf32> loc(#loc336)
    %3958 = cirh.BroadcastInDim %3954 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc337)
    %3959 = cirh.Mul %3957, %3958 : tensor<3072xf32> loc(#loc337)
    %3960 = cirh.Mul %3959, %3539 : tensor<3072xf32> loc(#loc338)
    %3961 = cirh.Sub %arg107, %3960 : tensor<3072xf32> loc(#loc339)
    %3962 = cirh.Mul %1280, %3349 : tensor<768xf32> loc(#loc318)
    %3963 = cirh.Mul %arg533, %cst_8 : tensor<768xf32> loc(#loc3)
    %3964 = cirh.Mul %3962, %cst_7 : tensor<768xf32> loc(#loc3)
    %3965 = cirh.Add %3963, %3964 : tensor<768xf32> loc(#loc3)
    %3966 = cirh.Mul %arg534, %cst_6 : tensor<768xf32> loc(#loc2)
    %3967 = cirh.Mul %3962, %3962 : tensor<768xf32> loc(#loc2)
    %3968 = cirh.Mul %3967, %cst_5 : tensor<768xf32> loc(#loc2)
    %3969 = cirh.Add %3966, %3968 : tensor<768xf32> loc(#loc2)
    %3970 = cirh.Mul %arg535, %cst_69 : tensor<f32> loc(#loc319)
    %3971 = cirh.Mul %arg536, %cst_68 : tensor<f32> loc(#loc320)
    %3972 = cirh.Sub %cst_36, %arg535 : tensor<f32> loc(#loc331)
    %3973 = cirh.Sub %cst_36, %arg536 : tensor<f32> loc(#loc332)
    %3974 = cirh.Sqrt %3973 : tensor<f32> loc(#loc333)
    %3975 = cirh.Div %3974, %3972 : tensor<f32> loc(#loc334)
    %3976 = cirh.Sqrt %3969 : tensor<768xf32> loc(#loc335)
    %3977 = cirh.Add %3976, %cst_4 : tensor<768xf32> loc(#loc1)
    %3978 = cirh.Div %3965, %3977 : tensor<768xf32> loc(#loc336)
    %3979 = cirh.BroadcastInDim %3975 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %3980 = cirh.Mul %3978, %3979 : tensor<768xf32> loc(#loc337)
    %3981 = cirh.Mul %3980, %3369 : tensor<768xf32> loc(#loc338)
    %3982 = cirh.Sub %arg108, %3981 : tensor<768xf32> loc(#loc339)
    %3983 = cirh.Mul %1272, %3349 : tensor<768xf32> loc(#loc318)
    %3984 = cirh.Mul %arg537, %cst_8 : tensor<768xf32> loc(#loc3)
    %3985 = cirh.Mul %3983, %cst_7 : tensor<768xf32> loc(#loc3)
    %3986 = cirh.Add %3984, %3985 : tensor<768xf32> loc(#loc3)
    %3987 = cirh.Mul %arg538, %cst_6 : tensor<768xf32> loc(#loc2)
    %3988 = cirh.Mul %3983, %3983 : tensor<768xf32> loc(#loc2)
    %3989 = cirh.Mul %3988, %cst_5 : tensor<768xf32> loc(#loc2)
    %3990 = cirh.Add %3987, %3989 : tensor<768xf32> loc(#loc2)
    %3991 = cirh.Mul %arg539, %cst_69 : tensor<f32> loc(#loc319)
    %3992 = cirh.Mul %arg540, %cst_68 : tensor<f32> loc(#loc320)
    %3993 = cirh.Sub %cst_36, %arg539 : tensor<f32> loc(#loc331)
    %3994 = cirh.Sub %cst_36, %arg540 : tensor<f32> loc(#loc332)
    %3995 = cirh.Sqrt %3994 : tensor<f32> loc(#loc333)
    %3996 = cirh.Div %3995, %3993 : tensor<f32> loc(#loc334)
    %3997 = cirh.Sqrt %3990 : tensor<768xf32> loc(#loc335)
    %3998 = cirh.Add %3997, %cst_4 : tensor<768xf32> loc(#loc1)
    %3999 = cirh.Div %3986, %3998 : tensor<768xf32> loc(#loc336)
    %4000 = cirh.BroadcastInDim %3996 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4001 = cirh.Mul %3999, %4000 : tensor<768xf32> loc(#loc337)
    %4002 = cirh.Mul %4001, %3369 : tensor<768xf32> loc(#loc338)
    %4003 = cirh.Sub %arg113, %4002 : tensor<768xf32> loc(#loc339)
    %4004 = cirh.Mul %1267, %3349 : tensor<768xf32> loc(#loc318)
    %4005 = cirh.Mul %arg541, %cst_8 : tensor<768xf32> loc(#loc3)
    %4006 = cirh.Mul %4004, %cst_7 : tensor<768xf32> loc(#loc3)
    %4007 = cirh.Add %4005, %4006 : tensor<768xf32> loc(#loc3)
    %4008 = cirh.Mul %arg542, %cst_6 : tensor<768xf32> loc(#loc2)
    %4009 = cirh.Mul %4004, %4004 : tensor<768xf32> loc(#loc2)
    %4010 = cirh.Mul %4009, %cst_5 : tensor<768xf32> loc(#loc2)
    %4011 = cirh.Add %4008, %4010 : tensor<768xf32> loc(#loc2)
    %4012 = cirh.Mul %arg543, %cst_69 : tensor<f32> loc(#loc319)
    %4013 = cirh.Mul %arg544, %cst_68 : tensor<f32> loc(#loc320)
    %4014 = cirh.Sub %cst_36, %arg543 : tensor<f32> loc(#loc331)
    %4015 = cirh.Sub %cst_36, %arg544 : tensor<f32> loc(#loc332)
    %4016 = cirh.Sqrt %4015 : tensor<f32> loc(#loc333)
    %4017 = cirh.Div %4016, %4014 : tensor<f32> loc(#loc334)
    %4018 = cirh.Sqrt %4011 : tensor<768xf32> loc(#loc335)
    %4019 = cirh.Add %4018, %cst_4 : tensor<768xf32> loc(#loc1)
    %4020 = cirh.Div %4007, %4019 : tensor<768xf32> loc(#loc336)
    %4021 = cirh.BroadcastInDim %4017 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4022 = cirh.Mul %4020, %4021 : tensor<768xf32> loc(#loc337)
    %4023 = cirh.Mul %4022, %3369 : tensor<768xf32> loc(#loc338)
    %4024 = cirh.Sub %arg111, %4023 : tensor<768xf32> loc(#loc339)
    %4025 = cirh.Mul %1262, %3349 : tensor<768xf32> loc(#loc318)
    %4026 = cirh.Mul %arg545, %cst_8 : tensor<768xf32> loc(#loc3)
    %4027 = cirh.Mul %4025, %cst_7 : tensor<768xf32> loc(#loc3)
    %4028 = cirh.Add %4026, %4027 : tensor<768xf32> loc(#loc3)
    %4029 = cirh.Mul %arg546, %cst_6 : tensor<768xf32> loc(#loc2)
    %4030 = cirh.Mul %4025, %4025 : tensor<768xf32> loc(#loc2)
    %4031 = cirh.Mul %4030, %cst_5 : tensor<768xf32> loc(#loc2)
    %4032 = cirh.Add %4029, %4031 : tensor<768xf32> loc(#loc2)
    %4033 = cirh.Mul %arg547, %cst_69 : tensor<f32> loc(#loc319)
    %4034 = cirh.Mul %arg548, %cst_68 : tensor<f32> loc(#loc320)
    %4035 = cirh.Sub %cst_36, %arg547 : tensor<f32> loc(#loc331)
    %4036 = cirh.Sub %cst_36, %arg548 : tensor<f32> loc(#loc332)
    %4037 = cirh.Sqrt %4036 : tensor<f32> loc(#loc333)
    %4038 = cirh.Div %4037, %4035 : tensor<f32> loc(#loc334)
    %4039 = cirh.Sqrt %4032 : tensor<768xf32> loc(#loc335)
    %4040 = cirh.Add %4039, %cst_4 : tensor<768xf32> loc(#loc1)
    %4041 = cirh.Div %4028, %4040 : tensor<768xf32> loc(#loc336)
    %4042 = cirh.BroadcastInDim %4038 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4043 = cirh.Mul %4041, %4042 : tensor<768xf32> loc(#loc337)
    %4044 = cirh.Mul %4043, %3369 : tensor<768xf32> loc(#loc338)
    %4045 = cirh.Sub %arg109, %4044 : tensor<768xf32> loc(#loc339)
    %4046 = cirh.Mul %1257, %3349 : tensor<768xf32> loc(#loc318)
    %4047 = cirh.Mul %arg549, %cst_8 : tensor<768xf32> loc(#loc3)
    %4048 = cirh.Mul %4046, %cst_7 : tensor<768xf32> loc(#loc3)
    %4049 = cirh.Add %4047, %4048 : tensor<768xf32> loc(#loc3)
    %4050 = cirh.Mul %arg550, %cst_6 : tensor<768xf32> loc(#loc2)
    %4051 = cirh.Mul %4046, %4046 : tensor<768xf32> loc(#loc2)
    %4052 = cirh.Mul %4051, %cst_5 : tensor<768xf32> loc(#loc2)
    %4053 = cirh.Add %4050, %4052 : tensor<768xf32> loc(#loc2)
    %4054 = cirh.Mul %arg551, %cst_69 : tensor<f32> loc(#loc319)
    %4055 = cirh.Mul %arg552, %cst_68 : tensor<f32> loc(#loc320)
    %4056 = cirh.Sub %cst_36, %arg551 : tensor<f32> loc(#loc331)
    %4057 = cirh.Sub %cst_36, %arg552 : tensor<f32> loc(#loc332)
    %4058 = cirh.Sqrt %4057 : tensor<f32> loc(#loc333)
    %4059 = cirh.Div %4058, %4056 : tensor<f32> loc(#loc334)
    %4060 = cirh.Sqrt %4053 : tensor<768xf32> loc(#loc335)
    %4061 = cirh.Add %4060, %cst_4 : tensor<768xf32> loc(#loc1)
    %4062 = cirh.Div %4049, %4061 : tensor<768xf32> loc(#loc336)
    %4063 = cirh.BroadcastInDim %4059 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4064 = cirh.Mul %4062, %4063 : tensor<768xf32> loc(#loc337)
    %4065 = cirh.Mul %4064, %3369 : tensor<768xf32> loc(#loc338)
    %4066 = cirh.Sub %arg114, %4065 : tensor<768xf32> loc(#loc339)
    %4067 = cirh.Mul %gamma_grad_113, %3349 : tensor<768xf32> loc(#loc318)
    %4068 = cirh.Mul %arg553, %cst_8 : tensor<768xf32> loc(#loc3)
    %4069 = cirh.Mul %4067, %cst_7 : tensor<768xf32> loc(#loc3)
    %4070 = cirh.Add %4068, %4069 : tensor<768xf32> loc(#loc3)
    %4071 = cirh.Mul %arg554, %cst_6 : tensor<768xf32> loc(#loc2)
    %4072 = cirh.Mul %4067, %4067 : tensor<768xf32> loc(#loc2)
    %4073 = cirh.Mul %4072, %cst_5 : tensor<768xf32> loc(#loc2)
    %4074 = cirh.Add %4071, %4073 : tensor<768xf32> loc(#loc2)
    %4075 = cirh.Mul %arg555, %cst_69 : tensor<f32> loc(#loc319)
    %4076 = cirh.Mul %arg556, %cst_68 : tensor<f32> loc(#loc320)
    %4077 = cirh.Sub %cst_36, %arg555 : tensor<f32> loc(#loc331)
    %4078 = cirh.Sub %cst_36, %arg556 : tensor<f32> loc(#loc332)
    %4079 = cirh.Sqrt %4078 : tensor<f32> loc(#loc333)
    %4080 = cirh.Div %4079, %4077 : tensor<f32> loc(#loc334)
    %4081 = cirh.Sqrt %4074 : tensor<768xf32> loc(#loc335)
    %4082 = cirh.Add %4081, %cst_4 : tensor<768xf32> loc(#loc1)
    %4083 = cirh.Div %4070, %4082 : tensor<768xf32> loc(#loc336)
    %4084 = cirh.BroadcastInDim %4080 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4085 = cirh.Mul %4083, %4084 : tensor<768xf32> loc(#loc337)
    %4086 = cirh.Mul %4085, %3369 : tensor<768xf32> loc(#loc338)
    %4087 = cirh.Sub %arg57, %4086 : tensor<768xf32> loc(#loc339)
    %4088 = cirh.Mul %beta_grad_112, %3349 : tensor<768xf32> loc(#loc318)
    %4089 = cirh.Mul %arg557, %cst_8 : tensor<768xf32> loc(#loc3)
    %4090 = cirh.Mul %4088, %cst_7 : tensor<768xf32> loc(#loc3)
    %4091 = cirh.Add %4089, %4090 : tensor<768xf32> loc(#loc3)
    %4092 = cirh.Mul %arg558, %cst_6 : tensor<768xf32> loc(#loc2)
    %4093 = cirh.Mul %4088, %4088 : tensor<768xf32> loc(#loc2)
    %4094 = cirh.Mul %4093, %cst_5 : tensor<768xf32> loc(#loc2)
    %4095 = cirh.Add %4092, %4094 : tensor<768xf32> loc(#loc2)
    %4096 = cirh.Mul %arg559, %cst_69 : tensor<f32> loc(#loc319)
    %4097 = cirh.Mul %arg560, %cst_68 : tensor<f32> loc(#loc320)
    %4098 = cirh.Sub %cst_36, %arg559 : tensor<f32> loc(#loc331)
    %4099 = cirh.Sub %cst_36, %arg560 : tensor<f32> loc(#loc332)
    %4100 = cirh.Sqrt %4099 : tensor<f32> loc(#loc333)
    %4101 = cirh.Div %4100, %4098 : tensor<f32> loc(#loc334)
    %4102 = cirh.Sqrt %4095 : tensor<768xf32> loc(#loc335)
    %4103 = cirh.Add %4102, %cst_4 : tensor<768xf32> loc(#loc1)
    %4104 = cirh.Div %4091, %4103 : tensor<768xf32> loc(#loc336)
    %4105 = cirh.BroadcastInDim %4101 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4106 = cirh.Mul %4104, %4105 : tensor<768xf32> loc(#loc337)
    %4107 = cirh.Mul %4106, %3369 : tensor<768xf32> loc(#loc338)
    %4108 = cirh.Sub %arg56, %4107 : tensor<768xf32> loc(#loc339)
    %4109 = cirh.Mul %gamma_grad_110, %3349 : tensor<768xf32> loc(#loc318)
    %4110 = cirh.Mul %arg561, %cst_8 : tensor<768xf32> loc(#loc3)
    %4111 = cirh.Mul %4109, %cst_7 : tensor<768xf32> loc(#loc3)
    %4112 = cirh.Add %4110, %4111 : tensor<768xf32> loc(#loc3)
    %4113 = cirh.Mul %arg562, %cst_6 : tensor<768xf32> loc(#loc2)
    %4114 = cirh.Mul %4109, %4109 : tensor<768xf32> loc(#loc2)
    %4115 = cirh.Mul %4114, %cst_5 : tensor<768xf32> loc(#loc2)
    %4116 = cirh.Add %4113, %4115 : tensor<768xf32> loc(#loc2)
    %4117 = cirh.Mul %arg563, %cst_69 : tensor<f32> loc(#loc319)
    %4118 = cirh.Mul %arg564, %cst_68 : tensor<f32> loc(#loc320)
    %4119 = cirh.Sub %cst_36, %arg563 : tensor<f32> loc(#loc331)
    %4120 = cirh.Sub %cst_36, %arg564 : tensor<f32> loc(#loc332)
    %4121 = cirh.Sqrt %4120 : tensor<f32> loc(#loc333)
    %4122 = cirh.Div %4121, %4119 : tensor<f32> loc(#loc334)
    %4123 = cirh.Sqrt %4116 : tensor<768xf32> loc(#loc335)
    %4124 = cirh.Add %4123, %cst_4 : tensor<768xf32> loc(#loc1)
    %4125 = cirh.Div %4112, %4124 : tensor<768xf32> loc(#loc336)
    %4126 = cirh.BroadcastInDim %4122 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4127 = cirh.Mul %4125, %4126 : tensor<768xf32> loc(#loc337)
    %4128 = cirh.Mul %4127, %3369 : tensor<768xf32> loc(#loc338)
    %4129 = cirh.Sub %arg53, %4128 : tensor<768xf32> loc(#loc339)
    %4130 = cirh.Mul %beta_grad_109, %3349 : tensor<768xf32> loc(#loc318)
    %4131 = cirh.Mul %arg565, %cst_8 : tensor<768xf32> loc(#loc3)
    %4132 = cirh.Mul %4130, %cst_7 : tensor<768xf32> loc(#loc3)
    %4133 = cirh.Add %4131, %4132 : tensor<768xf32> loc(#loc3)
    %4134 = cirh.Mul %arg566, %cst_6 : tensor<768xf32> loc(#loc2)
    %4135 = cirh.Mul %4130, %4130 : tensor<768xf32> loc(#loc2)
    %4136 = cirh.Mul %4135, %cst_5 : tensor<768xf32> loc(#loc2)
    %4137 = cirh.Add %4134, %4136 : tensor<768xf32> loc(#loc2)
    %4138 = cirh.Mul %arg567, %cst_69 : tensor<f32> loc(#loc319)
    %4139 = cirh.Mul %arg568, %cst_68 : tensor<f32> loc(#loc320)
    %4140 = cirh.Sub %cst_36, %arg567 : tensor<f32> loc(#loc331)
    %4141 = cirh.Sub %cst_36, %arg568 : tensor<f32> loc(#loc332)
    %4142 = cirh.Sqrt %4141 : tensor<f32> loc(#loc333)
    %4143 = cirh.Div %4142, %4140 : tensor<f32> loc(#loc334)
    %4144 = cirh.Sqrt %4137 : tensor<768xf32> loc(#loc335)
    %4145 = cirh.Add %4144, %cst_4 : tensor<768xf32> loc(#loc1)
    %4146 = cirh.Div %4133, %4145 : tensor<768xf32> loc(#loc336)
    %4147 = cirh.BroadcastInDim %4143 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4148 = cirh.Mul %4146, %4147 : tensor<768xf32> loc(#loc337)
    %4149 = cirh.Mul %4148, %3369 : tensor<768xf32> loc(#loc338)
    %4150 = cirh.Sub %arg52, %4149 : tensor<768xf32> loc(#loc339)
    %4151 = cirh.Mul %1207, %3519 : tensor<3072xf32> loc(#loc318)
    %4152 = cirh.Mul %arg569, %cst_3 : tensor<3072xf32> loc(#loc3)
    %4153 = cirh.Mul %4151, %cst_2 : tensor<3072xf32> loc(#loc3)
    %4154 = cirh.Add %4152, %4153 : tensor<3072xf32> loc(#loc3)
    %4155 = cirh.Mul %arg570, %cst_1 : tensor<3072xf32> loc(#loc2)
    %4156 = cirh.Mul %4151, %4151 : tensor<3072xf32> loc(#loc2)
    %4157 = cirh.Mul %4156, %cst_0 : tensor<3072xf32> loc(#loc2)
    %4158 = cirh.Add %4155, %4157 : tensor<3072xf32> loc(#loc2)
    %4159 = cirh.Mul %arg571, %cst_69 : tensor<f32> loc(#loc319)
    %4160 = cirh.Mul %arg572, %cst_68 : tensor<f32> loc(#loc320)
    %4161 = cirh.Sub %cst_36, %arg571 : tensor<f32> loc(#loc331)
    %4162 = cirh.Sub %cst_36, %arg572 : tensor<f32> loc(#loc332)
    %4163 = cirh.Sqrt %4162 : tensor<f32> loc(#loc333)
    %4164 = cirh.Div %4163, %4161 : tensor<f32> loc(#loc334)
    %4165 = cirh.Sqrt %4158 : tensor<3072xf32> loc(#loc335)
    %4166 = cirh.Add %4165, %cst : tensor<3072xf32> loc(#loc1)
    %4167 = cirh.Div %4154, %4166 : tensor<3072xf32> loc(#loc336)
    %4168 = cirh.BroadcastInDim %4164 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc337)
    %4169 = cirh.Mul %4167, %4168 : tensor<3072xf32> loc(#loc337)
    %4170 = cirh.Mul %4169, %3539 : tensor<3072xf32> loc(#loc338)
    %4171 = cirh.Sub %arg115, %4170 : tensor<3072xf32> loc(#loc339)
    %4172 = cirh.Mul %1198, %3349 : tensor<768xf32> loc(#loc318)
    %4173 = cirh.Mul %arg573, %cst_8 : tensor<768xf32> loc(#loc3)
    %4174 = cirh.Mul %4172, %cst_7 : tensor<768xf32> loc(#loc3)
    %4175 = cirh.Add %4173, %4174 : tensor<768xf32> loc(#loc3)
    %4176 = cirh.Mul %arg574, %cst_6 : tensor<768xf32> loc(#loc2)
    %4177 = cirh.Mul %4172, %4172 : tensor<768xf32> loc(#loc2)
    %4178 = cirh.Mul %4177, %cst_5 : tensor<768xf32> loc(#loc2)
    %4179 = cirh.Add %4176, %4178 : tensor<768xf32> loc(#loc2)
    %4180 = cirh.Mul %arg575, %cst_69 : tensor<f32> loc(#loc319)
    %4181 = cirh.Mul %arg576, %cst_68 : tensor<f32> loc(#loc320)
    %4182 = cirh.Sub %cst_36, %arg575 : tensor<f32> loc(#loc331)
    %4183 = cirh.Sub %cst_36, %arg576 : tensor<f32> loc(#loc332)
    %4184 = cirh.Sqrt %4183 : tensor<f32> loc(#loc333)
    %4185 = cirh.Div %4184, %4182 : tensor<f32> loc(#loc334)
    %4186 = cirh.Sqrt %4179 : tensor<768xf32> loc(#loc335)
    %4187 = cirh.Add %4186, %cst_4 : tensor<768xf32> loc(#loc1)
    %4188 = cirh.Div %4175, %4187 : tensor<768xf32> loc(#loc336)
    %4189 = cirh.BroadcastInDim %4185 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4190 = cirh.Mul %4188, %4189 : tensor<768xf32> loc(#loc337)
    %4191 = cirh.Mul %4190, %3369 : tensor<768xf32> loc(#loc338)
    %4192 = cirh.Sub %arg116, %4191 : tensor<768xf32> loc(#loc339)
    %4193 = cirh.Mul %1190, %3349 : tensor<768xf32> loc(#loc318)
    %4194 = cirh.Mul %arg577, %cst_8 : tensor<768xf32> loc(#loc3)
    %4195 = cirh.Mul %4193, %cst_7 : tensor<768xf32> loc(#loc3)
    %4196 = cirh.Add %4194, %4195 : tensor<768xf32> loc(#loc3)
    %4197 = cirh.Mul %arg578, %cst_6 : tensor<768xf32> loc(#loc2)
    %4198 = cirh.Mul %4193, %4193 : tensor<768xf32> loc(#loc2)
    %4199 = cirh.Mul %4198, %cst_5 : tensor<768xf32> loc(#loc2)
    %4200 = cirh.Add %4197, %4199 : tensor<768xf32> loc(#loc2)
    %4201 = cirh.Mul %arg579, %cst_69 : tensor<f32> loc(#loc319)
    %4202 = cirh.Mul %arg580, %cst_68 : tensor<f32> loc(#loc320)
    %4203 = cirh.Sub %cst_36, %arg579 : tensor<f32> loc(#loc331)
    %4204 = cirh.Sub %cst_36, %arg580 : tensor<f32> loc(#loc332)
    %4205 = cirh.Sqrt %4204 : tensor<f32> loc(#loc333)
    %4206 = cirh.Div %4205, %4203 : tensor<f32> loc(#loc334)
    %4207 = cirh.Sqrt %4200 : tensor<768xf32> loc(#loc335)
    %4208 = cirh.Add %4207, %cst_4 : tensor<768xf32> loc(#loc1)
    %4209 = cirh.Div %4196, %4208 : tensor<768xf32> loc(#loc336)
    %4210 = cirh.BroadcastInDim %4206 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4211 = cirh.Mul %4209, %4210 : tensor<768xf32> loc(#loc337)
    %4212 = cirh.Mul %4211, %3369 : tensor<768xf32> loc(#loc338)
    %4213 = cirh.Sub %arg121, %4212 : tensor<768xf32> loc(#loc339)
    %4214 = cirh.Mul %1185, %3349 : tensor<768xf32> loc(#loc318)
    %4215 = cirh.Mul %arg581, %cst_8 : tensor<768xf32> loc(#loc3)
    %4216 = cirh.Mul %4214, %cst_7 : tensor<768xf32> loc(#loc3)
    %4217 = cirh.Add %4215, %4216 : tensor<768xf32> loc(#loc3)
    %4218 = cirh.Mul %arg582, %cst_6 : tensor<768xf32> loc(#loc2)
    %4219 = cirh.Mul %4214, %4214 : tensor<768xf32> loc(#loc2)
    %4220 = cirh.Mul %4219, %cst_5 : tensor<768xf32> loc(#loc2)
    %4221 = cirh.Add %4218, %4220 : tensor<768xf32> loc(#loc2)
    %4222 = cirh.Mul %arg583, %cst_69 : tensor<f32> loc(#loc319)
    %4223 = cirh.Mul %arg584, %cst_68 : tensor<f32> loc(#loc320)
    %4224 = cirh.Sub %cst_36, %arg583 : tensor<f32> loc(#loc331)
    %4225 = cirh.Sub %cst_36, %arg584 : tensor<f32> loc(#loc332)
    %4226 = cirh.Sqrt %4225 : tensor<f32> loc(#loc333)
    %4227 = cirh.Div %4226, %4224 : tensor<f32> loc(#loc334)
    %4228 = cirh.Sqrt %4221 : tensor<768xf32> loc(#loc335)
    %4229 = cirh.Add %4228, %cst_4 : tensor<768xf32> loc(#loc1)
    %4230 = cirh.Div %4217, %4229 : tensor<768xf32> loc(#loc336)
    %4231 = cirh.BroadcastInDim %4227 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4232 = cirh.Mul %4230, %4231 : tensor<768xf32> loc(#loc337)
    %4233 = cirh.Mul %4232, %3369 : tensor<768xf32> loc(#loc338)
    %4234 = cirh.Sub %arg119, %4233 : tensor<768xf32> loc(#loc339)
    %4235 = cirh.Mul %1180, %3349 : tensor<768xf32> loc(#loc318)
    %4236 = cirh.Mul %arg585, %cst_8 : tensor<768xf32> loc(#loc3)
    %4237 = cirh.Mul %4235, %cst_7 : tensor<768xf32> loc(#loc3)
    %4238 = cirh.Add %4236, %4237 : tensor<768xf32> loc(#loc3)
    %4239 = cirh.Mul %arg586, %cst_6 : tensor<768xf32> loc(#loc2)
    %4240 = cirh.Mul %4235, %4235 : tensor<768xf32> loc(#loc2)
    %4241 = cirh.Mul %4240, %cst_5 : tensor<768xf32> loc(#loc2)
    %4242 = cirh.Add %4239, %4241 : tensor<768xf32> loc(#loc2)
    %4243 = cirh.Mul %arg587, %cst_69 : tensor<f32> loc(#loc319)
    %4244 = cirh.Mul %arg588, %cst_68 : tensor<f32> loc(#loc320)
    %4245 = cirh.Sub %cst_36, %arg587 : tensor<f32> loc(#loc331)
    %4246 = cirh.Sub %cst_36, %arg588 : tensor<f32> loc(#loc332)
    %4247 = cirh.Sqrt %4246 : tensor<f32> loc(#loc333)
    %4248 = cirh.Div %4247, %4245 : tensor<f32> loc(#loc334)
    %4249 = cirh.Sqrt %4242 : tensor<768xf32> loc(#loc335)
    %4250 = cirh.Add %4249, %cst_4 : tensor<768xf32> loc(#loc1)
    %4251 = cirh.Div %4238, %4250 : tensor<768xf32> loc(#loc336)
    %4252 = cirh.BroadcastInDim %4248 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4253 = cirh.Mul %4251, %4252 : tensor<768xf32> loc(#loc337)
    %4254 = cirh.Mul %4253, %3369 : tensor<768xf32> loc(#loc338)
    %4255 = cirh.Sub %arg117, %4254 : tensor<768xf32> loc(#loc339)
    %4256 = cirh.Mul %1175, %3349 : tensor<768xf32> loc(#loc318)
    %4257 = cirh.Mul %arg589, %cst_8 : tensor<768xf32> loc(#loc3)
    %4258 = cirh.Mul %4256, %cst_7 : tensor<768xf32> loc(#loc3)
    %4259 = cirh.Add %4257, %4258 : tensor<768xf32> loc(#loc3)
    %4260 = cirh.Mul %arg590, %cst_6 : tensor<768xf32> loc(#loc2)
    %4261 = cirh.Mul %4256, %4256 : tensor<768xf32> loc(#loc2)
    %4262 = cirh.Mul %4261, %cst_5 : tensor<768xf32> loc(#loc2)
    %4263 = cirh.Add %4260, %4262 : tensor<768xf32> loc(#loc2)
    %4264 = cirh.Mul %arg591, %cst_69 : tensor<f32> loc(#loc319)
    %4265 = cirh.Mul %arg592, %cst_68 : tensor<f32> loc(#loc320)
    %4266 = cirh.Sub %cst_36, %arg591 : tensor<f32> loc(#loc331)
    %4267 = cirh.Sub %cst_36, %arg592 : tensor<f32> loc(#loc332)
    %4268 = cirh.Sqrt %4267 : tensor<f32> loc(#loc333)
    %4269 = cirh.Div %4268, %4266 : tensor<f32> loc(#loc334)
    %4270 = cirh.Sqrt %4263 : tensor<768xf32> loc(#loc335)
    %4271 = cirh.Add %4270, %cst_4 : tensor<768xf32> loc(#loc1)
    %4272 = cirh.Div %4259, %4271 : tensor<768xf32> loc(#loc336)
    %4273 = cirh.BroadcastInDim %4269 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4274 = cirh.Mul %4272, %4273 : tensor<768xf32> loc(#loc337)
    %4275 = cirh.Mul %4274, %3369 : tensor<768xf32> loc(#loc338)
    %4276 = cirh.Sub %arg122, %4275 : tensor<768xf32> loc(#loc339)
    %4277 = cirh.Mul %gamma_grad_107, %3349 : tensor<768xf32> loc(#loc318)
    %4278 = cirh.Mul %arg593, %cst_8 : tensor<768xf32> loc(#loc3)
    %4279 = cirh.Mul %4277, %cst_7 : tensor<768xf32> loc(#loc3)
    %4280 = cirh.Add %4278, %4279 : tensor<768xf32> loc(#loc3)
    %4281 = cirh.Mul %arg594, %cst_6 : tensor<768xf32> loc(#loc2)
    %4282 = cirh.Mul %4277, %4277 : tensor<768xf32> loc(#loc2)
    %4283 = cirh.Mul %4282, %cst_5 : tensor<768xf32> loc(#loc2)
    %4284 = cirh.Add %4281, %4283 : tensor<768xf32> loc(#loc2)
    %4285 = cirh.Mul %arg595, %cst_69 : tensor<f32> loc(#loc319)
    %4286 = cirh.Mul %arg596, %cst_68 : tensor<f32> loc(#loc320)
    %4287 = cirh.Sub %cst_36, %arg595 : tensor<f32> loc(#loc331)
    %4288 = cirh.Sub %cst_36, %arg596 : tensor<f32> loc(#loc332)
    %4289 = cirh.Sqrt %4288 : tensor<f32> loc(#loc333)
    %4290 = cirh.Div %4289, %4287 : tensor<f32> loc(#loc334)
    %4291 = cirh.Sqrt %4284 : tensor<768xf32> loc(#loc335)
    %4292 = cirh.Add %4291, %cst_4 : tensor<768xf32> loc(#loc1)
    %4293 = cirh.Div %4280, %4292 : tensor<768xf32> loc(#loc336)
    %4294 = cirh.BroadcastInDim %4290 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4295 = cirh.Mul %4293, %4294 : tensor<768xf32> loc(#loc337)
    %4296 = cirh.Mul %4295, %3369 : tensor<768xf32> loc(#loc338)
    %4297 = cirh.Sub %arg49, %4296 : tensor<768xf32> loc(#loc339)
    %4298 = cirh.Mul %beta_grad_106, %3349 : tensor<768xf32> loc(#loc318)
    %4299 = cirh.Mul %arg597, %cst_8 : tensor<768xf32> loc(#loc3)
    %4300 = cirh.Mul %4298, %cst_7 : tensor<768xf32> loc(#loc3)
    %4301 = cirh.Add %4299, %4300 : tensor<768xf32> loc(#loc3)
    %4302 = cirh.Mul %arg598, %cst_6 : tensor<768xf32> loc(#loc2)
    %4303 = cirh.Mul %4298, %4298 : tensor<768xf32> loc(#loc2)
    %4304 = cirh.Mul %4303, %cst_5 : tensor<768xf32> loc(#loc2)
    %4305 = cirh.Add %4302, %4304 : tensor<768xf32> loc(#loc2)
    %4306 = cirh.Mul %arg599, %cst_69 : tensor<f32> loc(#loc319)
    %4307 = cirh.Mul %arg600, %cst_68 : tensor<f32> loc(#loc320)
    %4308 = cirh.Sub %cst_36, %arg599 : tensor<f32> loc(#loc331)
    %4309 = cirh.Sub %cst_36, %arg600 : tensor<f32> loc(#loc332)
    %4310 = cirh.Sqrt %4309 : tensor<f32> loc(#loc333)
    %4311 = cirh.Div %4310, %4308 : tensor<f32> loc(#loc334)
    %4312 = cirh.Sqrt %4305 : tensor<768xf32> loc(#loc335)
    %4313 = cirh.Add %4312, %cst_4 : tensor<768xf32> loc(#loc1)
    %4314 = cirh.Div %4301, %4313 : tensor<768xf32> loc(#loc336)
    %4315 = cirh.BroadcastInDim %4311 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4316 = cirh.Mul %4314, %4315 : tensor<768xf32> loc(#loc337)
    %4317 = cirh.Mul %4316, %3369 : tensor<768xf32> loc(#loc338)
    %4318 = cirh.Sub %arg48, %4317 : tensor<768xf32> loc(#loc339)
    %4319 = cirh.Mul %gamma_grad_104, %3349 : tensor<768xf32> loc(#loc318)
    %4320 = cirh.Mul %arg601, %cst_8 : tensor<768xf32> loc(#loc3)
    %4321 = cirh.Mul %4319, %cst_7 : tensor<768xf32> loc(#loc3)
    %4322 = cirh.Add %4320, %4321 : tensor<768xf32> loc(#loc3)
    %4323 = cirh.Mul %arg602, %cst_6 : tensor<768xf32> loc(#loc2)
    %4324 = cirh.Mul %4319, %4319 : tensor<768xf32> loc(#loc2)
    %4325 = cirh.Mul %4324, %cst_5 : tensor<768xf32> loc(#loc2)
    %4326 = cirh.Add %4323, %4325 : tensor<768xf32> loc(#loc2)
    %4327 = cirh.Mul %arg603, %cst_69 : tensor<f32> loc(#loc319)
    %4328 = cirh.Mul %arg604, %cst_68 : tensor<f32> loc(#loc320)
    %4329 = cirh.Sub %cst_36, %arg603 : tensor<f32> loc(#loc331)
    %4330 = cirh.Sub %cst_36, %arg604 : tensor<f32> loc(#loc332)
    %4331 = cirh.Sqrt %4330 : tensor<f32> loc(#loc333)
    %4332 = cirh.Div %4331, %4329 : tensor<f32> loc(#loc334)
    %4333 = cirh.Sqrt %4326 : tensor<768xf32> loc(#loc335)
    %4334 = cirh.Add %4333, %cst_4 : tensor<768xf32> loc(#loc1)
    %4335 = cirh.Div %4322, %4334 : tensor<768xf32> loc(#loc336)
    %4336 = cirh.BroadcastInDim %4332 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4337 = cirh.Mul %4335, %4336 : tensor<768xf32> loc(#loc337)
    %4338 = cirh.Mul %4337, %3369 : tensor<768xf32> loc(#loc338)
    %4339 = cirh.Sub %arg45, %4338 : tensor<768xf32> loc(#loc339)
    %4340 = cirh.Mul %beta_grad_103, %3349 : tensor<768xf32> loc(#loc318)
    %4341 = cirh.Mul %arg605, %cst_8 : tensor<768xf32> loc(#loc3)
    %4342 = cirh.Mul %4340, %cst_7 : tensor<768xf32> loc(#loc3)
    %4343 = cirh.Add %4341, %4342 : tensor<768xf32> loc(#loc3)
    %4344 = cirh.Mul %arg606, %cst_6 : tensor<768xf32> loc(#loc2)
    %4345 = cirh.Mul %4340, %4340 : tensor<768xf32> loc(#loc2)
    %4346 = cirh.Mul %4345, %cst_5 : tensor<768xf32> loc(#loc2)
    %4347 = cirh.Add %4344, %4346 : tensor<768xf32> loc(#loc2)
    %4348 = cirh.Mul %arg607, %cst_69 : tensor<f32> loc(#loc319)
    %4349 = cirh.Mul %arg608, %cst_68 : tensor<f32> loc(#loc320)
    %4350 = cirh.Sub %cst_36, %arg607 : tensor<f32> loc(#loc331)
    %4351 = cirh.Sub %cst_36, %arg608 : tensor<f32> loc(#loc332)
    %4352 = cirh.Sqrt %4351 : tensor<f32> loc(#loc333)
    %4353 = cirh.Div %4352, %4350 : tensor<f32> loc(#loc334)
    %4354 = cirh.Sqrt %4347 : tensor<768xf32> loc(#loc335)
    %4355 = cirh.Add %4354, %cst_4 : tensor<768xf32> loc(#loc1)
    %4356 = cirh.Div %4343, %4355 : tensor<768xf32> loc(#loc336)
    %4357 = cirh.BroadcastInDim %4353 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4358 = cirh.Mul %4356, %4357 : tensor<768xf32> loc(#loc337)
    %4359 = cirh.Mul %4358, %3369 : tensor<768xf32> loc(#loc338)
    %4360 = cirh.Sub %arg44, %4359 : tensor<768xf32> loc(#loc339)
    %4361 = cirh.Mul %1125, %3519 : tensor<3072xf32> loc(#loc318)
    %4362 = cirh.Mul %arg609, %cst_3 : tensor<3072xf32> loc(#loc3)
    %4363 = cirh.Mul %4361, %cst_2 : tensor<3072xf32> loc(#loc3)
    %4364 = cirh.Add %4362, %4363 : tensor<3072xf32> loc(#loc3)
    %4365 = cirh.Mul %arg610, %cst_1 : tensor<3072xf32> loc(#loc2)
    %4366 = cirh.Mul %4361, %4361 : tensor<3072xf32> loc(#loc2)
    %4367 = cirh.Mul %4366, %cst_0 : tensor<3072xf32> loc(#loc2)
    %4368 = cirh.Add %4365, %4367 : tensor<3072xf32> loc(#loc2)
    %4369 = cirh.Mul %arg611, %cst_69 : tensor<f32> loc(#loc319)
    %4370 = cirh.Mul %arg612, %cst_68 : tensor<f32> loc(#loc320)
    %4371 = cirh.Sub %cst_36, %arg611 : tensor<f32> loc(#loc331)
    %4372 = cirh.Sub %cst_36, %arg612 : tensor<f32> loc(#loc332)
    %4373 = cirh.Sqrt %4372 : tensor<f32> loc(#loc333)
    %4374 = cirh.Div %4373, %4371 : tensor<f32> loc(#loc334)
    %4375 = cirh.Sqrt %4368 : tensor<3072xf32> loc(#loc335)
    %4376 = cirh.Add %4375, %cst : tensor<3072xf32> loc(#loc1)
    %4377 = cirh.Div %4364, %4376 : tensor<3072xf32> loc(#loc336)
    %4378 = cirh.BroadcastInDim %4374 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc337)
    %4379 = cirh.Mul %4377, %4378 : tensor<3072xf32> loc(#loc337)
    %4380 = cirh.Mul %4379, %3539 : tensor<3072xf32> loc(#loc338)
    %4381 = cirh.Sub %arg123, %4380 : tensor<3072xf32> loc(#loc339)
    %4382 = cirh.Mul %1116, %3349 : tensor<768xf32> loc(#loc318)
    %4383 = cirh.Mul %arg613, %cst_8 : tensor<768xf32> loc(#loc3)
    %4384 = cirh.Mul %4382, %cst_7 : tensor<768xf32> loc(#loc3)
    %4385 = cirh.Add %4383, %4384 : tensor<768xf32> loc(#loc3)
    %4386 = cirh.Mul %arg614, %cst_6 : tensor<768xf32> loc(#loc2)
    %4387 = cirh.Mul %4382, %4382 : tensor<768xf32> loc(#loc2)
    %4388 = cirh.Mul %4387, %cst_5 : tensor<768xf32> loc(#loc2)
    %4389 = cirh.Add %4386, %4388 : tensor<768xf32> loc(#loc2)
    %4390 = cirh.Mul %arg615, %cst_69 : tensor<f32> loc(#loc319)
    %4391 = cirh.Mul %arg616, %cst_68 : tensor<f32> loc(#loc320)
    %4392 = cirh.Sub %cst_36, %arg615 : tensor<f32> loc(#loc331)
    %4393 = cirh.Sub %cst_36, %arg616 : tensor<f32> loc(#loc332)
    %4394 = cirh.Sqrt %4393 : tensor<f32> loc(#loc333)
    %4395 = cirh.Div %4394, %4392 : tensor<f32> loc(#loc334)
    %4396 = cirh.Sqrt %4389 : tensor<768xf32> loc(#loc335)
    %4397 = cirh.Add %4396, %cst_4 : tensor<768xf32> loc(#loc1)
    %4398 = cirh.Div %4385, %4397 : tensor<768xf32> loc(#loc336)
    %4399 = cirh.BroadcastInDim %4395 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4400 = cirh.Mul %4398, %4399 : tensor<768xf32> loc(#loc337)
    %4401 = cirh.Mul %4400, %3369 : tensor<768xf32> loc(#loc338)
    %4402 = cirh.Sub %arg124, %4401 : tensor<768xf32> loc(#loc339)
    %4403 = cirh.Mul %1108, %3349 : tensor<768xf32> loc(#loc318)
    %4404 = cirh.Mul %arg617, %cst_8 : tensor<768xf32> loc(#loc3)
    %4405 = cirh.Mul %4403, %cst_7 : tensor<768xf32> loc(#loc3)
    %4406 = cirh.Add %4404, %4405 : tensor<768xf32> loc(#loc3)
    %4407 = cirh.Mul %arg618, %cst_6 : tensor<768xf32> loc(#loc2)
    %4408 = cirh.Mul %4403, %4403 : tensor<768xf32> loc(#loc2)
    %4409 = cirh.Mul %4408, %cst_5 : tensor<768xf32> loc(#loc2)
    %4410 = cirh.Add %4407, %4409 : tensor<768xf32> loc(#loc2)
    %4411 = cirh.Mul %arg619, %cst_69 : tensor<f32> loc(#loc319)
    %4412 = cirh.Mul %arg620, %cst_68 : tensor<f32> loc(#loc320)
    %4413 = cirh.Sub %cst_36, %arg619 : tensor<f32> loc(#loc331)
    %4414 = cirh.Sub %cst_36, %arg620 : tensor<f32> loc(#loc332)
    %4415 = cirh.Sqrt %4414 : tensor<f32> loc(#loc333)
    %4416 = cirh.Div %4415, %4413 : tensor<f32> loc(#loc334)
    %4417 = cirh.Sqrt %4410 : tensor<768xf32> loc(#loc335)
    %4418 = cirh.Add %4417, %cst_4 : tensor<768xf32> loc(#loc1)
    %4419 = cirh.Div %4406, %4418 : tensor<768xf32> loc(#loc336)
    %4420 = cirh.BroadcastInDim %4416 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4421 = cirh.Mul %4419, %4420 : tensor<768xf32> loc(#loc337)
    %4422 = cirh.Mul %4421, %3369 : tensor<768xf32> loc(#loc338)
    %4423 = cirh.Sub %arg129, %4422 : tensor<768xf32> loc(#loc339)
    %4424 = cirh.Mul %1103, %3349 : tensor<768xf32> loc(#loc318)
    %4425 = cirh.Mul %arg621, %cst_8 : tensor<768xf32> loc(#loc3)
    %4426 = cirh.Mul %4424, %cst_7 : tensor<768xf32> loc(#loc3)
    %4427 = cirh.Add %4425, %4426 : tensor<768xf32> loc(#loc3)
    %4428 = cirh.Mul %arg622, %cst_6 : tensor<768xf32> loc(#loc2)
    %4429 = cirh.Mul %4424, %4424 : tensor<768xf32> loc(#loc2)
    %4430 = cirh.Mul %4429, %cst_5 : tensor<768xf32> loc(#loc2)
    %4431 = cirh.Add %4428, %4430 : tensor<768xf32> loc(#loc2)
    %4432 = cirh.Mul %arg623, %cst_69 : tensor<f32> loc(#loc319)
    %4433 = cirh.Mul %arg624, %cst_68 : tensor<f32> loc(#loc320)
    %4434 = cirh.Sub %cst_36, %arg623 : tensor<f32> loc(#loc331)
    %4435 = cirh.Sub %cst_36, %arg624 : tensor<f32> loc(#loc332)
    %4436 = cirh.Sqrt %4435 : tensor<f32> loc(#loc333)
    %4437 = cirh.Div %4436, %4434 : tensor<f32> loc(#loc334)
    %4438 = cirh.Sqrt %4431 : tensor<768xf32> loc(#loc335)
    %4439 = cirh.Add %4438, %cst_4 : tensor<768xf32> loc(#loc1)
    %4440 = cirh.Div %4427, %4439 : tensor<768xf32> loc(#loc336)
    %4441 = cirh.BroadcastInDim %4437 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4442 = cirh.Mul %4440, %4441 : tensor<768xf32> loc(#loc337)
    %4443 = cirh.Mul %4442, %3369 : tensor<768xf32> loc(#loc338)
    %4444 = cirh.Sub %arg127, %4443 : tensor<768xf32> loc(#loc339)
    %4445 = cirh.Mul %1098, %3349 : tensor<768xf32> loc(#loc318)
    %4446 = cirh.Mul %arg625, %cst_8 : tensor<768xf32> loc(#loc3)
    %4447 = cirh.Mul %4445, %cst_7 : tensor<768xf32> loc(#loc3)
    %4448 = cirh.Add %4446, %4447 : tensor<768xf32> loc(#loc3)
    %4449 = cirh.Mul %arg626, %cst_6 : tensor<768xf32> loc(#loc2)
    %4450 = cirh.Mul %4445, %4445 : tensor<768xf32> loc(#loc2)
    %4451 = cirh.Mul %4450, %cst_5 : tensor<768xf32> loc(#loc2)
    %4452 = cirh.Add %4449, %4451 : tensor<768xf32> loc(#loc2)
    %4453 = cirh.Mul %arg627, %cst_69 : tensor<f32> loc(#loc319)
    %4454 = cirh.Mul %arg628, %cst_68 : tensor<f32> loc(#loc320)
    %4455 = cirh.Sub %cst_36, %arg627 : tensor<f32> loc(#loc331)
    %4456 = cirh.Sub %cst_36, %arg628 : tensor<f32> loc(#loc332)
    %4457 = cirh.Sqrt %4456 : tensor<f32> loc(#loc333)
    %4458 = cirh.Div %4457, %4455 : tensor<f32> loc(#loc334)
    %4459 = cirh.Sqrt %4452 : tensor<768xf32> loc(#loc335)
    %4460 = cirh.Add %4459, %cst_4 : tensor<768xf32> loc(#loc1)
    %4461 = cirh.Div %4448, %4460 : tensor<768xf32> loc(#loc336)
    %4462 = cirh.BroadcastInDim %4458 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4463 = cirh.Mul %4461, %4462 : tensor<768xf32> loc(#loc337)
    %4464 = cirh.Mul %4463, %3369 : tensor<768xf32> loc(#loc338)
    %4465 = cirh.Sub %arg125, %4464 : tensor<768xf32> loc(#loc339)
    %4466 = cirh.Mul %1093, %3349 : tensor<768xf32> loc(#loc318)
    %4467 = cirh.Mul %arg629, %cst_8 : tensor<768xf32> loc(#loc3)
    %4468 = cirh.Mul %4466, %cst_7 : tensor<768xf32> loc(#loc3)
    %4469 = cirh.Add %4467, %4468 : tensor<768xf32> loc(#loc3)
    %4470 = cirh.Mul %arg630, %cst_6 : tensor<768xf32> loc(#loc2)
    %4471 = cirh.Mul %4466, %4466 : tensor<768xf32> loc(#loc2)
    %4472 = cirh.Mul %4471, %cst_5 : tensor<768xf32> loc(#loc2)
    %4473 = cirh.Add %4470, %4472 : tensor<768xf32> loc(#loc2)
    %4474 = cirh.Mul %arg631, %cst_69 : tensor<f32> loc(#loc319)
    %4475 = cirh.Mul %arg632, %cst_68 : tensor<f32> loc(#loc320)
    %4476 = cirh.Sub %cst_36, %arg631 : tensor<f32> loc(#loc331)
    %4477 = cirh.Sub %cst_36, %arg632 : tensor<f32> loc(#loc332)
    %4478 = cirh.Sqrt %4477 : tensor<f32> loc(#loc333)
    %4479 = cirh.Div %4478, %4476 : tensor<f32> loc(#loc334)
    %4480 = cirh.Sqrt %4473 : tensor<768xf32> loc(#loc335)
    %4481 = cirh.Add %4480, %cst_4 : tensor<768xf32> loc(#loc1)
    %4482 = cirh.Div %4469, %4481 : tensor<768xf32> loc(#loc336)
    %4483 = cirh.BroadcastInDim %4479 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4484 = cirh.Mul %4482, %4483 : tensor<768xf32> loc(#loc337)
    %4485 = cirh.Mul %4484, %3369 : tensor<768xf32> loc(#loc338)
    %4486 = cirh.Sub %arg130, %4485 : tensor<768xf32> loc(#loc339)
    %4487 = cirh.Mul %gamma_grad_101, %3349 : tensor<768xf32> loc(#loc318)
    %4488 = cirh.Mul %arg633, %cst_8 : tensor<768xf32> loc(#loc3)
    %4489 = cirh.Mul %4487, %cst_7 : tensor<768xf32> loc(#loc3)
    %4490 = cirh.Add %4488, %4489 : tensor<768xf32> loc(#loc3)
    %4491 = cirh.Mul %arg634, %cst_6 : tensor<768xf32> loc(#loc2)
    %4492 = cirh.Mul %4487, %4487 : tensor<768xf32> loc(#loc2)
    %4493 = cirh.Mul %4492, %cst_5 : tensor<768xf32> loc(#loc2)
    %4494 = cirh.Add %4491, %4493 : tensor<768xf32> loc(#loc2)
    %4495 = cirh.Mul %arg635, %cst_69 : tensor<f32> loc(#loc319)
    %4496 = cirh.Mul %arg636, %cst_68 : tensor<f32> loc(#loc320)
    %4497 = cirh.Sub %cst_36, %arg635 : tensor<f32> loc(#loc331)
    %4498 = cirh.Sub %cst_36, %arg636 : tensor<f32> loc(#loc332)
    %4499 = cirh.Sqrt %4498 : tensor<f32> loc(#loc333)
    %4500 = cirh.Div %4499, %4497 : tensor<f32> loc(#loc334)
    %4501 = cirh.Sqrt %4494 : tensor<768xf32> loc(#loc335)
    %4502 = cirh.Add %4501, %cst_4 : tensor<768xf32> loc(#loc1)
    %4503 = cirh.Div %4490, %4502 : tensor<768xf32> loc(#loc336)
    %4504 = cirh.BroadcastInDim %4500 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4505 = cirh.Mul %4503, %4504 : tensor<768xf32> loc(#loc337)
    %4506 = cirh.Mul %4505, %3369 : tensor<768xf32> loc(#loc338)
    %4507 = cirh.Sub %arg41, %4506 : tensor<768xf32> loc(#loc339)
    %4508 = cirh.Mul %beta_grad_100, %3349 : tensor<768xf32> loc(#loc318)
    %4509 = cirh.Mul %arg637, %cst_8 : tensor<768xf32> loc(#loc3)
    %4510 = cirh.Mul %4508, %cst_7 : tensor<768xf32> loc(#loc3)
    %4511 = cirh.Add %4509, %4510 : tensor<768xf32> loc(#loc3)
    %4512 = cirh.Mul %arg638, %cst_6 : tensor<768xf32> loc(#loc2)
    %4513 = cirh.Mul %4508, %4508 : tensor<768xf32> loc(#loc2)
    %4514 = cirh.Mul %4513, %cst_5 : tensor<768xf32> loc(#loc2)
    %4515 = cirh.Add %4512, %4514 : tensor<768xf32> loc(#loc2)
    %4516 = cirh.Mul %arg639, %cst_69 : tensor<f32> loc(#loc319)
    %4517 = cirh.Mul %arg640, %cst_68 : tensor<f32> loc(#loc320)
    %4518 = cirh.Sub %cst_36, %arg639 : tensor<f32> loc(#loc331)
    %4519 = cirh.Sub %cst_36, %arg640 : tensor<f32> loc(#loc332)
    %4520 = cirh.Sqrt %4519 : tensor<f32> loc(#loc333)
    %4521 = cirh.Div %4520, %4518 : tensor<f32> loc(#loc334)
    %4522 = cirh.Sqrt %4515 : tensor<768xf32> loc(#loc335)
    %4523 = cirh.Add %4522, %cst_4 : tensor<768xf32> loc(#loc1)
    %4524 = cirh.Div %4511, %4523 : tensor<768xf32> loc(#loc336)
    %4525 = cirh.BroadcastInDim %4521 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4526 = cirh.Mul %4524, %4525 : tensor<768xf32> loc(#loc337)
    %4527 = cirh.Mul %4526, %3369 : tensor<768xf32> loc(#loc338)
    %4528 = cirh.Sub %arg40, %4527 : tensor<768xf32> loc(#loc339)
    %4529 = cirh.Mul %gamma_grad_98, %3349 : tensor<768xf32> loc(#loc318)
    %4530 = cirh.Mul %arg641, %cst_8 : tensor<768xf32> loc(#loc3)
    %4531 = cirh.Mul %4529, %cst_7 : tensor<768xf32> loc(#loc3)
    %4532 = cirh.Add %4530, %4531 : tensor<768xf32> loc(#loc3)
    %4533 = cirh.Mul %arg642, %cst_6 : tensor<768xf32> loc(#loc2)
    %4534 = cirh.Mul %4529, %4529 : tensor<768xf32> loc(#loc2)
    %4535 = cirh.Mul %4534, %cst_5 : tensor<768xf32> loc(#loc2)
    %4536 = cirh.Add %4533, %4535 : tensor<768xf32> loc(#loc2)
    %4537 = cirh.Mul %arg643, %cst_69 : tensor<f32> loc(#loc319)
    %4538 = cirh.Mul %arg644, %cst_68 : tensor<f32> loc(#loc320)
    %4539 = cirh.Sub %cst_36, %arg643 : tensor<f32> loc(#loc331)
    %4540 = cirh.Sub %cst_36, %arg644 : tensor<f32> loc(#loc332)
    %4541 = cirh.Sqrt %4540 : tensor<f32> loc(#loc333)
    %4542 = cirh.Div %4541, %4539 : tensor<f32> loc(#loc334)
    %4543 = cirh.Sqrt %4536 : tensor<768xf32> loc(#loc335)
    %4544 = cirh.Add %4543, %cst_4 : tensor<768xf32> loc(#loc1)
    %4545 = cirh.Div %4532, %4544 : tensor<768xf32> loc(#loc336)
    %4546 = cirh.BroadcastInDim %4542 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4547 = cirh.Mul %4545, %4546 : tensor<768xf32> loc(#loc337)
    %4548 = cirh.Mul %4547, %3369 : tensor<768xf32> loc(#loc338)
    %4549 = cirh.Sub %arg37, %4548 : tensor<768xf32> loc(#loc339)
    %4550 = cirh.Mul %beta_grad_97, %3349 : tensor<768xf32> loc(#loc318)
    %4551 = cirh.Mul %arg645, %cst_8 : tensor<768xf32> loc(#loc3)
    %4552 = cirh.Mul %4550, %cst_7 : tensor<768xf32> loc(#loc3)
    %4553 = cirh.Add %4551, %4552 : tensor<768xf32> loc(#loc3)
    %4554 = cirh.Mul %arg646, %cst_6 : tensor<768xf32> loc(#loc2)
    %4555 = cirh.Mul %4550, %4550 : tensor<768xf32> loc(#loc2)
    %4556 = cirh.Mul %4555, %cst_5 : tensor<768xf32> loc(#loc2)
    %4557 = cirh.Add %4554, %4556 : tensor<768xf32> loc(#loc2)
    %4558 = cirh.Mul %arg647, %cst_69 : tensor<f32> loc(#loc319)
    %4559 = cirh.Mul %arg648, %cst_68 : tensor<f32> loc(#loc320)
    %4560 = cirh.Sub %cst_36, %arg647 : tensor<f32> loc(#loc331)
    %4561 = cirh.Sub %cst_36, %arg648 : tensor<f32> loc(#loc332)
    %4562 = cirh.Sqrt %4561 : tensor<f32> loc(#loc333)
    %4563 = cirh.Div %4562, %4560 : tensor<f32> loc(#loc334)
    %4564 = cirh.Sqrt %4557 : tensor<768xf32> loc(#loc335)
    %4565 = cirh.Add %4564, %cst_4 : tensor<768xf32> loc(#loc1)
    %4566 = cirh.Div %4553, %4565 : tensor<768xf32> loc(#loc336)
    %4567 = cirh.BroadcastInDim %4563 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4568 = cirh.Mul %4566, %4567 : tensor<768xf32> loc(#loc337)
    %4569 = cirh.Mul %4568, %3369 : tensor<768xf32> loc(#loc338)
    %4570 = cirh.Sub %arg36, %4569 : tensor<768xf32> loc(#loc339)
    %4571 = cirh.Mul %1043, %3519 : tensor<3072xf32> loc(#loc318)
    %4572 = cirh.Mul %arg649, %cst_3 : tensor<3072xf32> loc(#loc3)
    %4573 = cirh.Mul %4571, %cst_2 : tensor<3072xf32> loc(#loc3)
    %4574 = cirh.Add %4572, %4573 : tensor<3072xf32> loc(#loc3)
    %4575 = cirh.Mul %arg650, %cst_1 : tensor<3072xf32> loc(#loc2)
    %4576 = cirh.Mul %4571, %4571 : tensor<3072xf32> loc(#loc2)
    %4577 = cirh.Mul %4576, %cst_0 : tensor<3072xf32> loc(#loc2)
    %4578 = cirh.Add %4575, %4577 : tensor<3072xf32> loc(#loc2)
    %4579 = cirh.Mul %arg651, %cst_69 : tensor<f32> loc(#loc319)
    %4580 = cirh.Mul %arg652, %cst_68 : tensor<f32> loc(#loc320)
    %4581 = cirh.Sub %cst_36, %arg651 : tensor<f32> loc(#loc331)
    %4582 = cirh.Sub %cst_36, %arg652 : tensor<f32> loc(#loc332)
    %4583 = cirh.Sqrt %4582 : tensor<f32> loc(#loc333)
    %4584 = cirh.Div %4583, %4581 : tensor<f32> loc(#loc334)
    %4585 = cirh.Sqrt %4578 : tensor<3072xf32> loc(#loc335)
    %4586 = cirh.Add %4585, %cst : tensor<3072xf32> loc(#loc1)
    %4587 = cirh.Div %4574, %4586 : tensor<3072xf32> loc(#loc336)
    %4588 = cirh.BroadcastInDim %4584 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc337)
    %4589 = cirh.Mul %4587, %4588 : tensor<3072xf32> loc(#loc337)
    %4590 = cirh.Mul %4589, %3539 : tensor<3072xf32> loc(#loc338)
    %4591 = cirh.Sub %arg131, %4590 : tensor<3072xf32> loc(#loc339)
    %4592 = cirh.Mul %1034, %3349 : tensor<768xf32> loc(#loc318)
    %4593 = cirh.Mul %arg653, %cst_8 : tensor<768xf32> loc(#loc3)
    %4594 = cirh.Mul %4592, %cst_7 : tensor<768xf32> loc(#loc3)
    %4595 = cirh.Add %4593, %4594 : tensor<768xf32> loc(#loc3)
    %4596 = cirh.Mul %arg654, %cst_6 : tensor<768xf32> loc(#loc2)
    %4597 = cirh.Mul %4592, %4592 : tensor<768xf32> loc(#loc2)
    %4598 = cirh.Mul %4597, %cst_5 : tensor<768xf32> loc(#loc2)
    %4599 = cirh.Add %4596, %4598 : tensor<768xf32> loc(#loc2)
    %4600 = cirh.Mul %arg655, %cst_69 : tensor<f32> loc(#loc319)
    %4601 = cirh.Mul %arg656, %cst_68 : tensor<f32> loc(#loc320)
    %4602 = cirh.Sub %cst_36, %arg655 : tensor<f32> loc(#loc331)
    %4603 = cirh.Sub %cst_36, %arg656 : tensor<f32> loc(#loc332)
    %4604 = cirh.Sqrt %4603 : tensor<f32> loc(#loc333)
    %4605 = cirh.Div %4604, %4602 : tensor<f32> loc(#loc334)
    %4606 = cirh.Sqrt %4599 : tensor<768xf32> loc(#loc335)
    %4607 = cirh.Add %4606, %cst_4 : tensor<768xf32> loc(#loc1)
    %4608 = cirh.Div %4595, %4607 : tensor<768xf32> loc(#loc336)
    %4609 = cirh.BroadcastInDim %4605 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4610 = cirh.Mul %4608, %4609 : tensor<768xf32> loc(#loc337)
    %4611 = cirh.Mul %4610, %3369 : tensor<768xf32> loc(#loc338)
    %4612 = cirh.Sub %arg132, %4611 : tensor<768xf32> loc(#loc339)
    %4613 = cirh.Mul %1026, %3349 : tensor<768xf32> loc(#loc318)
    %4614 = cirh.Mul %arg657, %cst_8 : tensor<768xf32> loc(#loc3)
    %4615 = cirh.Mul %4613, %cst_7 : tensor<768xf32> loc(#loc3)
    %4616 = cirh.Add %4614, %4615 : tensor<768xf32> loc(#loc3)
    %4617 = cirh.Mul %arg658, %cst_6 : tensor<768xf32> loc(#loc2)
    %4618 = cirh.Mul %4613, %4613 : tensor<768xf32> loc(#loc2)
    %4619 = cirh.Mul %4618, %cst_5 : tensor<768xf32> loc(#loc2)
    %4620 = cirh.Add %4617, %4619 : tensor<768xf32> loc(#loc2)
    %4621 = cirh.Mul %arg659, %cst_69 : tensor<f32> loc(#loc319)
    %4622 = cirh.Mul %arg660, %cst_68 : tensor<f32> loc(#loc320)
    %4623 = cirh.Sub %cst_36, %arg659 : tensor<f32> loc(#loc331)
    %4624 = cirh.Sub %cst_36, %arg660 : tensor<f32> loc(#loc332)
    %4625 = cirh.Sqrt %4624 : tensor<f32> loc(#loc333)
    %4626 = cirh.Div %4625, %4623 : tensor<f32> loc(#loc334)
    %4627 = cirh.Sqrt %4620 : tensor<768xf32> loc(#loc335)
    %4628 = cirh.Add %4627, %cst_4 : tensor<768xf32> loc(#loc1)
    %4629 = cirh.Div %4616, %4628 : tensor<768xf32> loc(#loc336)
    %4630 = cirh.BroadcastInDim %4626 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4631 = cirh.Mul %4629, %4630 : tensor<768xf32> loc(#loc337)
    %4632 = cirh.Mul %4631, %3369 : tensor<768xf32> loc(#loc338)
    %4633 = cirh.Sub %arg137, %4632 : tensor<768xf32> loc(#loc339)
    %4634 = cirh.Mul %1021, %3349 : tensor<768xf32> loc(#loc318)
    %4635 = cirh.Mul %arg661, %cst_8 : tensor<768xf32> loc(#loc3)
    %4636 = cirh.Mul %4634, %cst_7 : tensor<768xf32> loc(#loc3)
    %4637 = cirh.Add %4635, %4636 : tensor<768xf32> loc(#loc3)
    %4638 = cirh.Mul %arg662, %cst_6 : tensor<768xf32> loc(#loc2)
    %4639 = cirh.Mul %4634, %4634 : tensor<768xf32> loc(#loc2)
    %4640 = cirh.Mul %4639, %cst_5 : tensor<768xf32> loc(#loc2)
    %4641 = cirh.Add %4638, %4640 : tensor<768xf32> loc(#loc2)
    %4642 = cirh.Mul %arg663, %cst_69 : tensor<f32> loc(#loc319)
    %4643 = cirh.Mul %arg664, %cst_68 : tensor<f32> loc(#loc320)
    %4644 = cirh.Sub %cst_36, %arg663 : tensor<f32> loc(#loc331)
    %4645 = cirh.Sub %cst_36, %arg664 : tensor<f32> loc(#loc332)
    %4646 = cirh.Sqrt %4645 : tensor<f32> loc(#loc333)
    %4647 = cirh.Div %4646, %4644 : tensor<f32> loc(#loc334)
    %4648 = cirh.Sqrt %4641 : tensor<768xf32> loc(#loc335)
    %4649 = cirh.Add %4648, %cst_4 : tensor<768xf32> loc(#loc1)
    %4650 = cirh.Div %4637, %4649 : tensor<768xf32> loc(#loc336)
    %4651 = cirh.BroadcastInDim %4647 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4652 = cirh.Mul %4650, %4651 : tensor<768xf32> loc(#loc337)
    %4653 = cirh.Mul %4652, %3369 : tensor<768xf32> loc(#loc338)
    %4654 = cirh.Sub %arg135, %4653 : tensor<768xf32> loc(#loc339)
    %4655 = cirh.Mul %1016, %3349 : tensor<768xf32> loc(#loc318)
    %4656 = cirh.Mul %arg665, %cst_8 : tensor<768xf32> loc(#loc3)
    %4657 = cirh.Mul %4655, %cst_7 : tensor<768xf32> loc(#loc3)
    %4658 = cirh.Add %4656, %4657 : tensor<768xf32> loc(#loc3)
    %4659 = cirh.Mul %arg666, %cst_6 : tensor<768xf32> loc(#loc2)
    %4660 = cirh.Mul %4655, %4655 : tensor<768xf32> loc(#loc2)
    %4661 = cirh.Mul %4660, %cst_5 : tensor<768xf32> loc(#loc2)
    %4662 = cirh.Add %4659, %4661 : tensor<768xf32> loc(#loc2)
    %4663 = cirh.Mul %arg667, %cst_69 : tensor<f32> loc(#loc319)
    %4664 = cirh.Mul %arg668, %cst_68 : tensor<f32> loc(#loc320)
    %4665 = cirh.Sub %cst_36, %arg667 : tensor<f32> loc(#loc331)
    %4666 = cirh.Sub %cst_36, %arg668 : tensor<f32> loc(#loc332)
    %4667 = cirh.Sqrt %4666 : tensor<f32> loc(#loc333)
    %4668 = cirh.Div %4667, %4665 : tensor<f32> loc(#loc334)
    %4669 = cirh.Sqrt %4662 : tensor<768xf32> loc(#loc335)
    %4670 = cirh.Add %4669, %cst_4 : tensor<768xf32> loc(#loc1)
    %4671 = cirh.Div %4658, %4670 : tensor<768xf32> loc(#loc336)
    %4672 = cirh.BroadcastInDim %4668 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4673 = cirh.Mul %4671, %4672 : tensor<768xf32> loc(#loc337)
    %4674 = cirh.Mul %4673, %3369 : tensor<768xf32> loc(#loc338)
    %4675 = cirh.Sub %arg133, %4674 : tensor<768xf32> loc(#loc339)
    %4676 = cirh.Mul %1011, %3349 : tensor<768xf32> loc(#loc318)
    %4677 = cirh.Mul %arg669, %cst_8 : tensor<768xf32> loc(#loc3)
    %4678 = cirh.Mul %4676, %cst_7 : tensor<768xf32> loc(#loc3)
    %4679 = cirh.Add %4677, %4678 : tensor<768xf32> loc(#loc3)
    %4680 = cirh.Mul %arg670, %cst_6 : tensor<768xf32> loc(#loc2)
    %4681 = cirh.Mul %4676, %4676 : tensor<768xf32> loc(#loc2)
    %4682 = cirh.Mul %4681, %cst_5 : tensor<768xf32> loc(#loc2)
    %4683 = cirh.Add %4680, %4682 : tensor<768xf32> loc(#loc2)
    %4684 = cirh.Mul %arg671, %cst_69 : tensor<f32> loc(#loc319)
    %4685 = cirh.Mul %arg672, %cst_68 : tensor<f32> loc(#loc320)
    %4686 = cirh.Sub %cst_36, %arg671 : tensor<f32> loc(#loc331)
    %4687 = cirh.Sub %cst_36, %arg672 : tensor<f32> loc(#loc332)
    %4688 = cirh.Sqrt %4687 : tensor<f32> loc(#loc333)
    %4689 = cirh.Div %4688, %4686 : tensor<f32> loc(#loc334)
    %4690 = cirh.Sqrt %4683 : tensor<768xf32> loc(#loc335)
    %4691 = cirh.Add %4690, %cst_4 : tensor<768xf32> loc(#loc1)
    %4692 = cirh.Div %4679, %4691 : tensor<768xf32> loc(#loc336)
    %4693 = cirh.BroadcastInDim %4689 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4694 = cirh.Mul %4692, %4693 : tensor<768xf32> loc(#loc337)
    %4695 = cirh.Mul %4694, %3369 : tensor<768xf32> loc(#loc338)
    %4696 = cirh.Sub %arg138, %4695 : tensor<768xf32> loc(#loc339)
    %4697 = cirh.Mul %gamma_grad_95, %3349 : tensor<768xf32> loc(#loc318)
    %4698 = cirh.Mul %arg673, %cst_8 : tensor<768xf32> loc(#loc3)
    %4699 = cirh.Mul %4697, %cst_7 : tensor<768xf32> loc(#loc3)
    %4700 = cirh.Add %4698, %4699 : tensor<768xf32> loc(#loc3)
    %4701 = cirh.Mul %arg674, %cst_6 : tensor<768xf32> loc(#loc2)
    %4702 = cirh.Mul %4697, %4697 : tensor<768xf32> loc(#loc2)
    %4703 = cirh.Mul %4702, %cst_5 : tensor<768xf32> loc(#loc2)
    %4704 = cirh.Add %4701, %4703 : tensor<768xf32> loc(#loc2)
    %4705 = cirh.Mul %arg675, %cst_69 : tensor<f32> loc(#loc319)
    %4706 = cirh.Mul %arg676, %cst_68 : tensor<f32> loc(#loc320)
    %4707 = cirh.Sub %cst_36, %arg675 : tensor<f32> loc(#loc331)
    %4708 = cirh.Sub %cst_36, %arg676 : tensor<f32> loc(#loc332)
    %4709 = cirh.Sqrt %4708 : tensor<f32> loc(#loc333)
    %4710 = cirh.Div %4709, %4707 : tensor<f32> loc(#loc334)
    %4711 = cirh.Sqrt %4704 : tensor<768xf32> loc(#loc335)
    %4712 = cirh.Add %4711, %cst_4 : tensor<768xf32> loc(#loc1)
    %4713 = cirh.Div %4700, %4712 : tensor<768xf32> loc(#loc336)
    %4714 = cirh.BroadcastInDim %4710 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4715 = cirh.Mul %4713, %4714 : tensor<768xf32> loc(#loc337)
    %4716 = cirh.Mul %4715, %3369 : tensor<768xf32> loc(#loc338)
    %4717 = cirh.Sub %arg33, %4716 : tensor<768xf32> loc(#loc339)
    %4718 = cirh.Mul %beta_grad_94, %3349 : tensor<768xf32> loc(#loc318)
    %4719 = cirh.Mul %arg677, %cst_8 : tensor<768xf32> loc(#loc3)
    %4720 = cirh.Mul %4718, %cst_7 : tensor<768xf32> loc(#loc3)
    %4721 = cirh.Add %4719, %4720 : tensor<768xf32> loc(#loc3)
    %4722 = cirh.Mul %arg678, %cst_6 : tensor<768xf32> loc(#loc2)
    %4723 = cirh.Mul %4718, %4718 : tensor<768xf32> loc(#loc2)
    %4724 = cirh.Mul %4723, %cst_5 : tensor<768xf32> loc(#loc2)
    %4725 = cirh.Add %4722, %4724 : tensor<768xf32> loc(#loc2)
    %4726 = cirh.Mul %arg679, %cst_69 : tensor<f32> loc(#loc319)
    %4727 = cirh.Mul %arg680, %cst_68 : tensor<f32> loc(#loc320)
    %4728 = cirh.Sub %cst_36, %arg679 : tensor<f32> loc(#loc331)
    %4729 = cirh.Sub %cst_36, %arg680 : tensor<f32> loc(#loc332)
    %4730 = cirh.Sqrt %4729 : tensor<f32> loc(#loc333)
    %4731 = cirh.Div %4730, %4728 : tensor<f32> loc(#loc334)
    %4732 = cirh.Sqrt %4725 : tensor<768xf32> loc(#loc335)
    %4733 = cirh.Add %4732, %cst_4 : tensor<768xf32> loc(#loc1)
    %4734 = cirh.Div %4721, %4733 : tensor<768xf32> loc(#loc336)
    %4735 = cirh.BroadcastInDim %4731 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4736 = cirh.Mul %4734, %4735 : tensor<768xf32> loc(#loc337)
    %4737 = cirh.Mul %4736, %3369 : tensor<768xf32> loc(#loc338)
    %4738 = cirh.Sub %arg32, %4737 : tensor<768xf32> loc(#loc339)
    %4739 = cirh.Mul %gamma_grad_92, %3349 : tensor<768xf32> loc(#loc318)
    %4740 = cirh.Mul %arg681, %cst_8 : tensor<768xf32> loc(#loc3)
    %4741 = cirh.Mul %4739, %cst_7 : tensor<768xf32> loc(#loc3)
    %4742 = cirh.Add %4740, %4741 : tensor<768xf32> loc(#loc3)
    %4743 = cirh.Mul %arg682, %cst_6 : tensor<768xf32> loc(#loc2)
    %4744 = cirh.Mul %4739, %4739 : tensor<768xf32> loc(#loc2)
    %4745 = cirh.Mul %4744, %cst_5 : tensor<768xf32> loc(#loc2)
    %4746 = cirh.Add %4743, %4745 : tensor<768xf32> loc(#loc2)
    %4747 = cirh.Mul %arg683, %cst_69 : tensor<f32> loc(#loc319)
    %4748 = cirh.Mul %arg684, %cst_68 : tensor<f32> loc(#loc320)
    %4749 = cirh.Sub %cst_36, %arg683 : tensor<f32> loc(#loc331)
    %4750 = cirh.Sub %cst_36, %arg684 : tensor<f32> loc(#loc332)
    %4751 = cirh.Sqrt %4750 : tensor<f32> loc(#loc333)
    %4752 = cirh.Div %4751, %4749 : tensor<f32> loc(#loc334)
    %4753 = cirh.Sqrt %4746 : tensor<768xf32> loc(#loc335)
    %4754 = cirh.Add %4753, %cst_4 : tensor<768xf32> loc(#loc1)
    %4755 = cirh.Div %4742, %4754 : tensor<768xf32> loc(#loc336)
    %4756 = cirh.BroadcastInDim %4752 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4757 = cirh.Mul %4755, %4756 : tensor<768xf32> loc(#loc337)
    %4758 = cirh.Mul %4757, %3369 : tensor<768xf32> loc(#loc338)
    %4759 = cirh.Sub %arg29, %4758 : tensor<768xf32> loc(#loc339)
    %4760 = cirh.Mul %beta_grad_91, %3349 : tensor<768xf32> loc(#loc318)
    %4761 = cirh.Mul %arg685, %cst_8 : tensor<768xf32> loc(#loc3)
    %4762 = cirh.Mul %4760, %cst_7 : tensor<768xf32> loc(#loc3)
    %4763 = cirh.Add %4761, %4762 : tensor<768xf32> loc(#loc3)
    %4764 = cirh.Mul %arg686, %cst_6 : tensor<768xf32> loc(#loc2)
    %4765 = cirh.Mul %4760, %4760 : tensor<768xf32> loc(#loc2)
    %4766 = cirh.Mul %4765, %cst_5 : tensor<768xf32> loc(#loc2)
    %4767 = cirh.Add %4764, %4766 : tensor<768xf32> loc(#loc2)
    %4768 = cirh.Mul %arg687, %cst_69 : tensor<f32> loc(#loc319)
    %4769 = cirh.Mul %arg688, %cst_68 : tensor<f32> loc(#loc320)
    %4770 = cirh.Sub %cst_36, %arg687 : tensor<f32> loc(#loc331)
    %4771 = cirh.Sub %cst_36, %arg688 : tensor<f32> loc(#loc332)
    %4772 = cirh.Sqrt %4771 : tensor<f32> loc(#loc333)
    %4773 = cirh.Div %4772, %4770 : tensor<f32> loc(#loc334)
    %4774 = cirh.Sqrt %4767 : tensor<768xf32> loc(#loc335)
    %4775 = cirh.Add %4774, %cst_4 : tensor<768xf32> loc(#loc1)
    %4776 = cirh.Div %4763, %4775 : tensor<768xf32> loc(#loc336)
    %4777 = cirh.BroadcastInDim %4773 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4778 = cirh.Mul %4776, %4777 : tensor<768xf32> loc(#loc337)
    %4779 = cirh.Mul %4778, %3369 : tensor<768xf32> loc(#loc338)
    %4780 = cirh.Sub %arg28, %4779 : tensor<768xf32> loc(#loc339)
    %4781 = cirh.Mul %961, %3519 : tensor<3072xf32> loc(#loc318)
    %4782 = cirh.Mul %arg689, %cst_3 : tensor<3072xf32> loc(#loc3)
    %4783 = cirh.Mul %4781, %cst_2 : tensor<3072xf32> loc(#loc3)
    %4784 = cirh.Add %4782, %4783 : tensor<3072xf32> loc(#loc3)
    %4785 = cirh.Mul %arg690, %cst_1 : tensor<3072xf32> loc(#loc2)
    %4786 = cirh.Mul %4781, %4781 : tensor<3072xf32> loc(#loc2)
    %4787 = cirh.Mul %4786, %cst_0 : tensor<3072xf32> loc(#loc2)
    %4788 = cirh.Add %4785, %4787 : tensor<3072xf32> loc(#loc2)
    %4789 = cirh.Mul %arg691, %cst_69 : tensor<f32> loc(#loc319)
    %4790 = cirh.Mul %arg692, %cst_68 : tensor<f32> loc(#loc320)
    %4791 = cirh.Sub %cst_36, %arg691 : tensor<f32> loc(#loc331)
    %4792 = cirh.Sub %cst_36, %arg692 : tensor<f32> loc(#loc332)
    %4793 = cirh.Sqrt %4792 : tensor<f32> loc(#loc333)
    %4794 = cirh.Div %4793, %4791 : tensor<f32> loc(#loc334)
    %4795 = cirh.Sqrt %4788 : tensor<3072xf32> loc(#loc335)
    %4796 = cirh.Add %4795, %cst : tensor<3072xf32> loc(#loc1)
    %4797 = cirh.Div %4784, %4796 : tensor<3072xf32> loc(#loc336)
    %4798 = cirh.BroadcastInDim %4794 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc337)
    %4799 = cirh.Mul %4797, %4798 : tensor<3072xf32> loc(#loc337)
    %4800 = cirh.Mul %4799, %3539 : tensor<3072xf32> loc(#loc338)
    %4801 = cirh.Sub %arg139, %4800 : tensor<3072xf32> loc(#loc339)
    %4802 = cirh.Mul %952, %3349 : tensor<768xf32> loc(#loc318)
    %4803 = cirh.Mul %arg693, %cst_8 : tensor<768xf32> loc(#loc3)
    %4804 = cirh.Mul %4802, %cst_7 : tensor<768xf32> loc(#loc3)
    %4805 = cirh.Add %4803, %4804 : tensor<768xf32> loc(#loc3)
    %4806 = cirh.Mul %arg694, %cst_6 : tensor<768xf32> loc(#loc2)
    %4807 = cirh.Mul %4802, %4802 : tensor<768xf32> loc(#loc2)
    %4808 = cirh.Mul %4807, %cst_5 : tensor<768xf32> loc(#loc2)
    %4809 = cirh.Add %4806, %4808 : tensor<768xf32> loc(#loc2)
    %4810 = cirh.Mul %arg695, %cst_69 : tensor<f32> loc(#loc319)
    %4811 = cirh.Mul %arg696, %cst_68 : tensor<f32> loc(#loc320)
    %4812 = cirh.Sub %cst_36, %arg695 : tensor<f32> loc(#loc331)
    %4813 = cirh.Sub %cst_36, %arg696 : tensor<f32> loc(#loc332)
    %4814 = cirh.Sqrt %4813 : tensor<f32> loc(#loc333)
    %4815 = cirh.Div %4814, %4812 : tensor<f32> loc(#loc334)
    %4816 = cirh.Sqrt %4809 : tensor<768xf32> loc(#loc335)
    %4817 = cirh.Add %4816, %cst_4 : tensor<768xf32> loc(#loc1)
    %4818 = cirh.Div %4805, %4817 : tensor<768xf32> loc(#loc336)
    %4819 = cirh.BroadcastInDim %4815 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4820 = cirh.Mul %4818, %4819 : tensor<768xf32> loc(#loc337)
    %4821 = cirh.Mul %4820, %3369 : tensor<768xf32> loc(#loc338)
    %4822 = cirh.Sub %arg140, %4821 : tensor<768xf32> loc(#loc339)
    %4823 = cirh.Mul %944, %3349 : tensor<768xf32> loc(#loc318)
    %4824 = cirh.Mul %arg697, %cst_8 : tensor<768xf32> loc(#loc3)
    %4825 = cirh.Mul %4823, %cst_7 : tensor<768xf32> loc(#loc3)
    %4826 = cirh.Add %4824, %4825 : tensor<768xf32> loc(#loc3)
    %4827 = cirh.Mul %arg698, %cst_6 : tensor<768xf32> loc(#loc2)
    %4828 = cirh.Mul %4823, %4823 : tensor<768xf32> loc(#loc2)
    %4829 = cirh.Mul %4828, %cst_5 : tensor<768xf32> loc(#loc2)
    %4830 = cirh.Add %4827, %4829 : tensor<768xf32> loc(#loc2)
    %4831 = cirh.Mul %arg699, %cst_69 : tensor<f32> loc(#loc319)
    %4832 = cirh.Mul %arg700, %cst_68 : tensor<f32> loc(#loc320)
    %4833 = cirh.Sub %cst_36, %arg699 : tensor<f32> loc(#loc331)
    %4834 = cirh.Sub %cst_36, %arg700 : tensor<f32> loc(#loc332)
    %4835 = cirh.Sqrt %4834 : tensor<f32> loc(#loc333)
    %4836 = cirh.Div %4835, %4833 : tensor<f32> loc(#loc334)
    %4837 = cirh.Sqrt %4830 : tensor<768xf32> loc(#loc335)
    %4838 = cirh.Add %4837, %cst_4 : tensor<768xf32> loc(#loc1)
    %4839 = cirh.Div %4826, %4838 : tensor<768xf32> loc(#loc336)
    %4840 = cirh.BroadcastInDim %4836 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4841 = cirh.Mul %4839, %4840 : tensor<768xf32> loc(#loc337)
    %4842 = cirh.Mul %4841, %3369 : tensor<768xf32> loc(#loc338)
    %4843 = cirh.Sub %arg145, %4842 : tensor<768xf32> loc(#loc339)
    %4844 = cirh.Mul %939, %3349 : tensor<768xf32> loc(#loc318)
    %4845 = cirh.Mul %arg701, %cst_8 : tensor<768xf32> loc(#loc3)
    %4846 = cirh.Mul %4844, %cst_7 : tensor<768xf32> loc(#loc3)
    %4847 = cirh.Add %4845, %4846 : tensor<768xf32> loc(#loc3)
    %4848 = cirh.Mul %arg702, %cst_6 : tensor<768xf32> loc(#loc2)
    %4849 = cirh.Mul %4844, %4844 : tensor<768xf32> loc(#loc2)
    %4850 = cirh.Mul %4849, %cst_5 : tensor<768xf32> loc(#loc2)
    %4851 = cirh.Add %4848, %4850 : tensor<768xf32> loc(#loc2)
    %4852 = cirh.Mul %arg703, %cst_69 : tensor<f32> loc(#loc319)
    %4853 = cirh.Mul %arg704, %cst_68 : tensor<f32> loc(#loc320)
    %4854 = cirh.Sub %cst_36, %arg703 : tensor<f32> loc(#loc331)
    %4855 = cirh.Sub %cst_36, %arg704 : tensor<f32> loc(#loc332)
    %4856 = cirh.Sqrt %4855 : tensor<f32> loc(#loc333)
    %4857 = cirh.Div %4856, %4854 : tensor<f32> loc(#loc334)
    %4858 = cirh.Sqrt %4851 : tensor<768xf32> loc(#loc335)
    %4859 = cirh.Add %4858, %cst_4 : tensor<768xf32> loc(#loc1)
    %4860 = cirh.Div %4847, %4859 : tensor<768xf32> loc(#loc336)
    %4861 = cirh.BroadcastInDim %4857 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4862 = cirh.Mul %4860, %4861 : tensor<768xf32> loc(#loc337)
    %4863 = cirh.Mul %4862, %3369 : tensor<768xf32> loc(#loc338)
    %4864 = cirh.Sub %arg143, %4863 : tensor<768xf32> loc(#loc339)
    %4865 = cirh.Mul %934, %3349 : tensor<768xf32> loc(#loc318)
    %4866 = cirh.Mul %arg705, %cst_8 : tensor<768xf32> loc(#loc3)
    %4867 = cirh.Mul %4865, %cst_7 : tensor<768xf32> loc(#loc3)
    %4868 = cirh.Add %4866, %4867 : tensor<768xf32> loc(#loc3)
    %4869 = cirh.Mul %arg706, %cst_6 : tensor<768xf32> loc(#loc2)
    %4870 = cirh.Mul %4865, %4865 : tensor<768xf32> loc(#loc2)
    %4871 = cirh.Mul %4870, %cst_5 : tensor<768xf32> loc(#loc2)
    %4872 = cirh.Add %4869, %4871 : tensor<768xf32> loc(#loc2)
    %4873 = cirh.Mul %arg707, %cst_69 : tensor<f32> loc(#loc319)
    %4874 = cirh.Mul %arg708, %cst_68 : tensor<f32> loc(#loc320)
    %4875 = cirh.Sub %cst_36, %arg707 : tensor<f32> loc(#loc331)
    %4876 = cirh.Sub %cst_36, %arg708 : tensor<f32> loc(#loc332)
    %4877 = cirh.Sqrt %4876 : tensor<f32> loc(#loc333)
    %4878 = cirh.Div %4877, %4875 : tensor<f32> loc(#loc334)
    %4879 = cirh.Sqrt %4872 : tensor<768xf32> loc(#loc335)
    %4880 = cirh.Add %4879, %cst_4 : tensor<768xf32> loc(#loc1)
    %4881 = cirh.Div %4868, %4880 : tensor<768xf32> loc(#loc336)
    %4882 = cirh.BroadcastInDim %4878 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4883 = cirh.Mul %4881, %4882 : tensor<768xf32> loc(#loc337)
    %4884 = cirh.Mul %4883, %3369 : tensor<768xf32> loc(#loc338)
    %4885 = cirh.Sub %arg141, %4884 : tensor<768xf32> loc(#loc339)
    %4886 = cirh.Mul %929, %3349 : tensor<768xf32> loc(#loc318)
    %4887 = cirh.Mul %arg709, %cst_8 : tensor<768xf32> loc(#loc3)
    %4888 = cirh.Mul %4886, %cst_7 : tensor<768xf32> loc(#loc3)
    %4889 = cirh.Add %4887, %4888 : tensor<768xf32> loc(#loc3)
    %4890 = cirh.Mul %arg710, %cst_6 : tensor<768xf32> loc(#loc2)
    %4891 = cirh.Mul %4886, %4886 : tensor<768xf32> loc(#loc2)
    %4892 = cirh.Mul %4891, %cst_5 : tensor<768xf32> loc(#loc2)
    %4893 = cirh.Add %4890, %4892 : tensor<768xf32> loc(#loc2)
    %4894 = cirh.Mul %arg711, %cst_69 : tensor<f32> loc(#loc319)
    %4895 = cirh.Mul %arg712, %cst_68 : tensor<f32> loc(#loc320)
    %4896 = cirh.Sub %cst_36, %arg711 : tensor<f32> loc(#loc331)
    %4897 = cirh.Sub %cst_36, %arg712 : tensor<f32> loc(#loc332)
    %4898 = cirh.Sqrt %4897 : tensor<f32> loc(#loc333)
    %4899 = cirh.Div %4898, %4896 : tensor<f32> loc(#loc334)
    %4900 = cirh.Sqrt %4893 : tensor<768xf32> loc(#loc335)
    %4901 = cirh.Add %4900, %cst_4 : tensor<768xf32> loc(#loc1)
    %4902 = cirh.Div %4889, %4901 : tensor<768xf32> loc(#loc336)
    %4903 = cirh.BroadcastInDim %4899 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4904 = cirh.Mul %4902, %4903 : tensor<768xf32> loc(#loc337)
    %4905 = cirh.Mul %4904, %3369 : tensor<768xf32> loc(#loc338)
    %4906 = cirh.Sub %arg146, %4905 : tensor<768xf32> loc(#loc339)
    %4907 = cirh.Mul %gamma_grad_89, %3349 : tensor<768xf32> loc(#loc318)
    %4908 = cirh.Mul %arg713, %cst_8 : tensor<768xf32> loc(#loc3)
    %4909 = cirh.Mul %4907, %cst_7 : tensor<768xf32> loc(#loc3)
    %4910 = cirh.Add %4908, %4909 : tensor<768xf32> loc(#loc3)
    %4911 = cirh.Mul %arg714, %cst_6 : tensor<768xf32> loc(#loc2)
    %4912 = cirh.Mul %4907, %4907 : tensor<768xf32> loc(#loc2)
    %4913 = cirh.Mul %4912, %cst_5 : tensor<768xf32> loc(#loc2)
    %4914 = cirh.Add %4911, %4913 : tensor<768xf32> loc(#loc2)
    %4915 = cirh.Mul %arg715, %cst_69 : tensor<f32> loc(#loc319)
    %4916 = cirh.Mul %arg716, %cst_68 : tensor<f32> loc(#loc320)
    %4917 = cirh.Sub %cst_36, %arg715 : tensor<f32> loc(#loc331)
    %4918 = cirh.Sub %cst_36, %arg716 : tensor<f32> loc(#loc332)
    %4919 = cirh.Sqrt %4918 : tensor<f32> loc(#loc333)
    %4920 = cirh.Div %4919, %4917 : tensor<f32> loc(#loc334)
    %4921 = cirh.Sqrt %4914 : tensor<768xf32> loc(#loc335)
    %4922 = cirh.Add %4921, %cst_4 : tensor<768xf32> loc(#loc1)
    %4923 = cirh.Div %4910, %4922 : tensor<768xf32> loc(#loc336)
    %4924 = cirh.BroadcastInDim %4920 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4925 = cirh.Mul %4923, %4924 : tensor<768xf32> loc(#loc337)
    %4926 = cirh.Mul %4925, %3369 : tensor<768xf32> loc(#loc338)
    %4927 = cirh.Sub %arg25, %4926 : tensor<768xf32> loc(#loc339)
    %4928 = cirh.Mul %beta_grad_88, %3349 : tensor<768xf32> loc(#loc318)
    %4929 = cirh.Mul %arg717, %cst_8 : tensor<768xf32> loc(#loc3)
    %4930 = cirh.Mul %4928, %cst_7 : tensor<768xf32> loc(#loc3)
    %4931 = cirh.Add %4929, %4930 : tensor<768xf32> loc(#loc3)
    %4932 = cirh.Mul %arg718, %cst_6 : tensor<768xf32> loc(#loc2)
    %4933 = cirh.Mul %4928, %4928 : tensor<768xf32> loc(#loc2)
    %4934 = cirh.Mul %4933, %cst_5 : tensor<768xf32> loc(#loc2)
    %4935 = cirh.Add %4932, %4934 : tensor<768xf32> loc(#loc2)
    %4936 = cirh.Mul %arg719, %cst_69 : tensor<f32> loc(#loc319)
    %4937 = cirh.Mul %arg720, %cst_68 : tensor<f32> loc(#loc320)
    %4938 = cirh.Sub %cst_36, %arg719 : tensor<f32> loc(#loc331)
    %4939 = cirh.Sub %cst_36, %arg720 : tensor<f32> loc(#loc332)
    %4940 = cirh.Sqrt %4939 : tensor<f32> loc(#loc333)
    %4941 = cirh.Div %4940, %4938 : tensor<f32> loc(#loc334)
    %4942 = cirh.Sqrt %4935 : tensor<768xf32> loc(#loc335)
    %4943 = cirh.Add %4942, %cst_4 : tensor<768xf32> loc(#loc1)
    %4944 = cirh.Div %4931, %4943 : tensor<768xf32> loc(#loc336)
    %4945 = cirh.BroadcastInDim %4941 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4946 = cirh.Mul %4944, %4945 : tensor<768xf32> loc(#loc337)
    %4947 = cirh.Mul %4946, %3369 : tensor<768xf32> loc(#loc338)
    %4948 = cirh.Sub %arg24, %4947 : tensor<768xf32> loc(#loc339)
    %4949 = cirh.Mul %gamma_grad_86, %3349 : tensor<768xf32> loc(#loc318)
    %4950 = cirh.Mul %arg721, %cst_8 : tensor<768xf32> loc(#loc3)
    %4951 = cirh.Mul %4949, %cst_7 : tensor<768xf32> loc(#loc3)
    %4952 = cirh.Add %4950, %4951 : tensor<768xf32> loc(#loc3)
    %4953 = cirh.Mul %arg722, %cst_6 : tensor<768xf32> loc(#loc2)
    %4954 = cirh.Mul %4949, %4949 : tensor<768xf32> loc(#loc2)
    %4955 = cirh.Mul %4954, %cst_5 : tensor<768xf32> loc(#loc2)
    %4956 = cirh.Add %4953, %4955 : tensor<768xf32> loc(#loc2)
    %4957 = cirh.Mul %arg723, %cst_69 : tensor<f32> loc(#loc319)
    %4958 = cirh.Mul %arg724, %cst_68 : tensor<f32> loc(#loc320)
    %4959 = cirh.Sub %cst_36, %arg723 : tensor<f32> loc(#loc331)
    %4960 = cirh.Sub %cst_36, %arg724 : tensor<f32> loc(#loc332)
    %4961 = cirh.Sqrt %4960 : tensor<f32> loc(#loc333)
    %4962 = cirh.Div %4961, %4959 : tensor<f32> loc(#loc334)
    %4963 = cirh.Sqrt %4956 : tensor<768xf32> loc(#loc335)
    %4964 = cirh.Add %4963, %cst_4 : tensor<768xf32> loc(#loc1)
    %4965 = cirh.Div %4952, %4964 : tensor<768xf32> loc(#loc336)
    %4966 = cirh.BroadcastInDim %4962 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4967 = cirh.Mul %4965, %4966 : tensor<768xf32> loc(#loc337)
    %4968 = cirh.Mul %4967, %3369 : tensor<768xf32> loc(#loc338)
    %4969 = cirh.Sub %arg21, %4968 : tensor<768xf32> loc(#loc339)
    %4970 = cirh.Mul %beta_grad_85, %3349 : tensor<768xf32> loc(#loc318)
    %4971 = cirh.Mul %arg725, %cst_8 : tensor<768xf32> loc(#loc3)
    %4972 = cirh.Mul %4970, %cst_7 : tensor<768xf32> loc(#loc3)
    %4973 = cirh.Add %4971, %4972 : tensor<768xf32> loc(#loc3)
    %4974 = cirh.Mul %arg726, %cst_6 : tensor<768xf32> loc(#loc2)
    %4975 = cirh.Mul %4970, %4970 : tensor<768xf32> loc(#loc2)
    %4976 = cirh.Mul %4975, %cst_5 : tensor<768xf32> loc(#loc2)
    %4977 = cirh.Add %4974, %4976 : tensor<768xf32> loc(#loc2)
    %4978 = cirh.Mul %arg727, %cst_69 : tensor<f32> loc(#loc319)
    %4979 = cirh.Mul %arg728, %cst_68 : tensor<f32> loc(#loc320)
    %4980 = cirh.Sub %cst_36, %arg727 : tensor<f32> loc(#loc331)
    %4981 = cirh.Sub %cst_36, %arg728 : tensor<f32> loc(#loc332)
    %4982 = cirh.Sqrt %4981 : tensor<f32> loc(#loc333)
    %4983 = cirh.Div %4982, %4980 : tensor<f32> loc(#loc334)
    %4984 = cirh.Sqrt %4977 : tensor<768xf32> loc(#loc335)
    %4985 = cirh.Add %4984, %cst_4 : tensor<768xf32> loc(#loc1)
    %4986 = cirh.Div %4973, %4985 : tensor<768xf32> loc(#loc336)
    %4987 = cirh.BroadcastInDim %4983 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %4988 = cirh.Mul %4986, %4987 : tensor<768xf32> loc(#loc337)
    %4989 = cirh.Mul %4988, %3369 : tensor<768xf32> loc(#loc338)
    %4990 = cirh.Sub %arg20, %4989 : tensor<768xf32> loc(#loc339)
    %4991 = cirh.Mul %879, %3519 : tensor<3072xf32> loc(#loc318)
    %4992 = cirh.Mul %arg729, %cst_3 : tensor<3072xf32> loc(#loc3)
    %4993 = cirh.Mul %4991, %cst_2 : tensor<3072xf32> loc(#loc3)
    %4994 = cirh.Add %4992, %4993 : tensor<3072xf32> loc(#loc3)
    %4995 = cirh.Mul %arg730, %cst_1 : tensor<3072xf32> loc(#loc2)
    %4996 = cirh.Mul %4991, %4991 : tensor<3072xf32> loc(#loc2)
    %4997 = cirh.Mul %4996, %cst_0 : tensor<3072xf32> loc(#loc2)
    %4998 = cirh.Add %4995, %4997 : tensor<3072xf32> loc(#loc2)
    %4999 = cirh.Mul %arg731, %cst_69 : tensor<f32> loc(#loc319)
    %5000 = cirh.Mul %arg732, %cst_68 : tensor<f32> loc(#loc320)
    %5001 = cirh.Sub %cst_36, %arg731 : tensor<f32> loc(#loc331)
    %5002 = cirh.Sub %cst_36, %arg732 : tensor<f32> loc(#loc332)
    %5003 = cirh.Sqrt %5002 : tensor<f32> loc(#loc333)
    %5004 = cirh.Div %5003, %5001 : tensor<f32> loc(#loc334)
    %5005 = cirh.Sqrt %4998 : tensor<3072xf32> loc(#loc335)
    %5006 = cirh.Add %5005, %cst : tensor<3072xf32> loc(#loc1)
    %5007 = cirh.Div %4994, %5006 : tensor<3072xf32> loc(#loc336)
    %5008 = cirh.BroadcastInDim %5004 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc337)
    %5009 = cirh.Mul %5007, %5008 : tensor<3072xf32> loc(#loc337)
    %5010 = cirh.Mul %5009, %3539 : tensor<3072xf32> loc(#loc338)
    %5011 = cirh.Sub %arg147, %5010 : tensor<3072xf32> loc(#loc339)
    %5012 = cirh.Mul %870, %3349 : tensor<768xf32> loc(#loc318)
    %5013 = cirh.Mul %arg733, %cst_8 : tensor<768xf32> loc(#loc3)
    %5014 = cirh.Mul %5012, %cst_7 : tensor<768xf32> loc(#loc3)
    %5015 = cirh.Add %5013, %5014 : tensor<768xf32> loc(#loc3)
    %5016 = cirh.Mul %arg734, %cst_6 : tensor<768xf32> loc(#loc2)
    %5017 = cirh.Mul %5012, %5012 : tensor<768xf32> loc(#loc2)
    %5018 = cirh.Mul %5017, %cst_5 : tensor<768xf32> loc(#loc2)
    %5019 = cirh.Add %5016, %5018 : tensor<768xf32> loc(#loc2)
    %5020 = cirh.Mul %arg735, %cst_69 : tensor<f32> loc(#loc319)
    %5021 = cirh.Mul %arg736, %cst_68 : tensor<f32> loc(#loc320)
    %5022 = cirh.Sub %cst_36, %arg735 : tensor<f32> loc(#loc331)
    %5023 = cirh.Sub %cst_36, %arg736 : tensor<f32> loc(#loc332)
    %5024 = cirh.Sqrt %5023 : tensor<f32> loc(#loc333)
    %5025 = cirh.Div %5024, %5022 : tensor<f32> loc(#loc334)
    %5026 = cirh.Sqrt %5019 : tensor<768xf32> loc(#loc335)
    %5027 = cirh.Add %5026, %cst_4 : tensor<768xf32> loc(#loc1)
    %5028 = cirh.Div %5015, %5027 : tensor<768xf32> loc(#loc336)
    %5029 = cirh.BroadcastInDim %5025 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5030 = cirh.Mul %5028, %5029 : tensor<768xf32> loc(#loc337)
    %5031 = cirh.Mul %5030, %3369 : tensor<768xf32> loc(#loc338)
    %5032 = cirh.Sub %arg148, %5031 : tensor<768xf32> loc(#loc339)
    %5033 = cirh.Mul %862, %3349 : tensor<768xf32> loc(#loc318)
    %5034 = cirh.Mul %arg737, %cst_8 : tensor<768xf32> loc(#loc3)
    %5035 = cirh.Mul %5033, %cst_7 : tensor<768xf32> loc(#loc3)
    %5036 = cirh.Add %5034, %5035 : tensor<768xf32> loc(#loc3)
    %5037 = cirh.Mul %arg738, %cst_6 : tensor<768xf32> loc(#loc2)
    %5038 = cirh.Mul %5033, %5033 : tensor<768xf32> loc(#loc2)
    %5039 = cirh.Mul %5038, %cst_5 : tensor<768xf32> loc(#loc2)
    %5040 = cirh.Add %5037, %5039 : tensor<768xf32> loc(#loc2)
    %5041 = cirh.Mul %arg739, %cst_69 : tensor<f32> loc(#loc319)
    %5042 = cirh.Mul %arg740, %cst_68 : tensor<f32> loc(#loc320)
    %5043 = cirh.Sub %cst_36, %arg739 : tensor<f32> loc(#loc331)
    %5044 = cirh.Sub %cst_36, %arg740 : tensor<f32> loc(#loc332)
    %5045 = cirh.Sqrt %5044 : tensor<f32> loc(#loc333)
    %5046 = cirh.Div %5045, %5043 : tensor<f32> loc(#loc334)
    %5047 = cirh.Sqrt %5040 : tensor<768xf32> loc(#loc335)
    %5048 = cirh.Add %5047, %cst_4 : tensor<768xf32> loc(#loc1)
    %5049 = cirh.Div %5036, %5048 : tensor<768xf32> loc(#loc336)
    %5050 = cirh.BroadcastInDim %5046 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5051 = cirh.Mul %5049, %5050 : tensor<768xf32> loc(#loc337)
    %5052 = cirh.Mul %5051, %3369 : tensor<768xf32> loc(#loc338)
    %5053 = cirh.Sub %arg153, %5052 : tensor<768xf32> loc(#loc339)
    %5054 = cirh.Mul %857, %3349 : tensor<768xf32> loc(#loc318)
    %5055 = cirh.Mul %arg741, %cst_8 : tensor<768xf32> loc(#loc3)
    %5056 = cirh.Mul %5054, %cst_7 : tensor<768xf32> loc(#loc3)
    %5057 = cirh.Add %5055, %5056 : tensor<768xf32> loc(#loc3)
    %5058 = cirh.Mul %arg742, %cst_6 : tensor<768xf32> loc(#loc2)
    %5059 = cirh.Mul %5054, %5054 : tensor<768xf32> loc(#loc2)
    %5060 = cirh.Mul %5059, %cst_5 : tensor<768xf32> loc(#loc2)
    %5061 = cirh.Add %5058, %5060 : tensor<768xf32> loc(#loc2)
    %5062 = cirh.Mul %arg743, %cst_69 : tensor<f32> loc(#loc319)
    %5063 = cirh.Mul %arg744, %cst_68 : tensor<f32> loc(#loc320)
    %5064 = cirh.Sub %cst_36, %arg743 : tensor<f32> loc(#loc331)
    %5065 = cirh.Sub %cst_36, %arg744 : tensor<f32> loc(#loc332)
    %5066 = cirh.Sqrt %5065 : tensor<f32> loc(#loc333)
    %5067 = cirh.Div %5066, %5064 : tensor<f32> loc(#loc334)
    %5068 = cirh.Sqrt %5061 : tensor<768xf32> loc(#loc335)
    %5069 = cirh.Add %5068, %cst_4 : tensor<768xf32> loc(#loc1)
    %5070 = cirh.Div %5057, %5069 : tensor<768xf32> loc(#loc336)
    %5071 = cirh.BroadcastInDim %5067 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5072 = cirh.Mul %5070, %5071 : tensor<768xf32> loc(#loc337)
    %5073 = cirh.Mul %5072, %3369 : tensor<768xf32> loc(#loc338)
    %5074 = cirh.Sub %arg151, %5073 : tensor<768xf32> loc(#loc339)
    %5075 = cirh.Mul %852, %3349 : tensor<768xf32> loc(#loc318)
    %5076 = cirh.Mul %arg745, %cst_8 : tensor<768xf32> loc(#loc3)
    %5077 = cirh.Mul %5075, %cst_7 : tensor<768xf32> loc(#loc3)
    %5078 = cirh.Add %5076, %5077 : tensor<768xf32> loc(#loc3)
    %5079 = cirh.Mul %arg746, %cst_6 : tensor<768xf32> loc(#loc2)
    %5080 = cirh.Mul %5075, %5075 : tensor<768xf32> loc(#loc2)
    %5081 = cirh.Mul %5080, %cst_5 : tensor<768xf32> loc(#loc2)
    %5082 = cirh.Add %5079, %5081 : tensor<768xf32> loc(#loc2)
    %5083 = cirh.Mul %arg747, %cst_69 : tensor<f32> loc(#loc319)
    %5084 = cirh.Mul %arg748, %cst_68 : tensor<f32> loc(#loc320)
    %5085 = cirh.Sub %cst_36, %arg747 : tensor<f32> loc(#loc331)
    %5086 = cirh.Sub %cst_36, %arg748 : tensor<f32> loc(#loc332)
    %5087 = cirh.Sqrt %5086 : tensor<f32> loc(#loc333)
    %5088 = cirh.Div %5087, %5085 : tensor<f32> loc(#loc334)
    %5089 = cirh.Sqrt %5082 : tensor<768xf32> loc(#loc335)
    %5090 = cirh.Add %5089, %cst_4 : tensor<768xf32> loc(#loc1)
    %5091 = cirh.Div %5078, %5090 : tensor<768xf32> loc(#loc336)
    %5092 = cirh.BroadcastInDim %5088 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5093 = cirh.Mul %5091, %5092 : tensor<768xf32> loc(#loc337)
    %5094 = cirh.Mul %5093, %3369 : tensor<768xf32> loc(#loc338)
    %5095 = cirh.Sub %arg149, %5094 : tensor<768xf32> loc(#loc339)
    %5096 = cirh.Mul %847, %3349 : tensor<768xf32> loc(#loc318)
    %5097 = cirh.Mul %arg749, %cst_8 : tensor<768xf32> loc(#loc3)
    %5098 = cirh.Mul %5096, %cst_7 : tensor<768xf32> loc(#loc3)
    %5099 = cirh.Add %5097, %5098 : tensor<768xf32> loc(#loc3)
    %5100 = cirh.Mul %arg750, %cst_6 : tensor<768xf32> loc(#loc2)
    %5101 = cirh.Mul %5096, %5096 : tensor<768xf32> loc(#loc2)
    %5102 = cirh.Mul %5101, %cst_5 : tensor<768xf32> loc(#loc2)
    %5103 = cirh.Add %5100, %5102 : tensor<768xf32> loc(#loc2)
    %5104 = cirh.Mul %arg751, %cst_69 : tensor<f32> loc(#loc319)
    %5105 = cirh.Mul %arg752, %cst_68 : tensor<f32> loc(#loc320)
    %5106 = cirh.Sub %cst_36, %arg751 : tensor<f32> loc(#loc331)
    %5107 = cirh.Sub %cst_36, %arg752 : tensor<f32> loc(#loc332)
    %5108 = cirh.Sqrt %5107 : tensor<f32> loc(#loc333)
    %5109 = cirh.Div %5108, %5106 : tensor<f32> loc(#loc334)
    %5110 = cirh.Sqrt %5103 : tensor<768xf32> loc(#loc335)
    %5111 = cirh.Add %5110, %cst_4 : tensor<768xf32> loc(#loc1)
    %5112 = cirh.Div %5099, %5111 : tensor<768xf32> loc(#loc336)
    %5113 = cirh.BroadcastInDim %5109 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5114 = cirh.Mul %5112, %5113 : tensor<768xf32> loc(#loc337)
    %5115 = cirh.Mul %5114, %3369 : tensor<768xf32> loc(#loc338)
    %5116 = cirh.Sub %arg154, %5115 : tensor<768xf32> loc(#loc339)
    %5117 = cirh.Mul %gamma_grad_83, %3349 : tensor<768xf32> loc(#loc318)
    %5118 = cirh.Mul %arg753, %cst_8 : tensor<768xf32> loc(#loc3)
    %5119 = cirh.Mul %5117, %cst_7 : tensor<768xf32> loc(#loc3)
    %5120 = cirh.Add %5118, %5119 : tensor<768xf32> loc(#loc3)
    %5121 = cirh.Mul %arg754, %cst_6 : tensor<768xf32> loc(#loc2)
    %5122 = cirh.Mul %5117, %5117 : tensor<768xf32> loc(#loc2)
    %5123 = cirh.Mul %5122, %cst_5 : tensor<768xf32> loc(#loc2)
    %5124 = cirh.Add %5121, %5123 : tensor<768xf32> loc(#loc2)
    %5125 = cirh.Mul %arg755, %cst_69 : tensor<f32> loc(#loc319)
    %5126 = cirh.Mul %arg756, %cst_68 : tensor<f32> loc(#loc320)
    %5127 = cirh.Sub %cst_36, %arg755 : tensor<f32> loc(#loc331)
    %5128 = cirh.Sub %cst_36, %arg756 : tensor<f32> loc(#loc332)
    %5129 = cirh.Sqrt %5128 : tensor<f32> loc(#loc333)
    %5130 = cirh.Div %5129, %5127 : tensor<f32> loc(#loc334)
    %5131 = cirh.Sqrt %5124 : tensor<768xf32> loc(#loc335)
    %5132 = cirh.Add %5131, %cst_4 : tensor<768xf32> loc(#loc1)
    %5133 = cirh.Div %5120, %5132 : tensor<768xf32> loc(#loc336)
    %5134 = cirh.BroadcastInDim %5130 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5135 = cirh.Mul %5133, %5134 : tensor<768xf32> loc(#loc337)
    %5136 = cirh.Mul %5135, %3369 : tensor<768xf32> loc(#loc338)
    %5137 = cirh.Sub %arg17, %5136 : tensor<768xf32> loc(#loc339)
    %5138 = cirh.Mul %beta_grad_82, %3349 : tensor<768xf32> loc(#loc318)
    %5139 = cirh.Mul %arg757, %cst_8 : tensor<768xf32> loc(#loc3)
    %5140 = cirh.Mul %5138, %cst_7 : tensor<768xf32> loc(#loc3)
    %5141 = cirh.Add %5139, %5140 : tensor<768xf32> loc(#loc3)
    %5142 = cirh.Mul %arg758, %cst_6 : tensor<768xf32> loc(#loc2)
    %5143 = cirh.Mul %5138, %5138 : tensor<768xf32> loc(#loc2)
    %5144 = cirh.Mul %5143, %cst_5 : tensor<768xf32> loc(#loc2)
    %5145 = cirh.Add %5142, %5144 : tensor<768xf32> loc(#loc2)
    %5146 = cirh.Mul %arg759, %cst_69 : tensor<f32> loc(#loc319)
    %5147 = cirh.Mul %arg760, %cst_68 : tensor<f32> loc(#loc320)
    %5148 = cirh.Sub %cst_36, %arg759 : tensor<f32> loc(#loc331)
    %5149 = cirh.Sub %cst_36, %arg760 : tensor<f32> loc(#loc332)
    %5150 = cirh.Sqrt %5149 : tensor<f32> loc(#loc333)
    %5151 = cirh.Div %5150, %5148 : tensor<f32> loc(#loc334)
    %5152 = cirh.Sqrt %5145 : tensor<768xf32> loc(#loc335)
    %5153 = cirh.Add %5152, %cst_4 : tensor<768xf32> loc(#loc1)
    %5154 = cirh.Div %5141, %5153 : tensor<768xf32> loc(#loc336)
    %5155 = cirh.BroadcastInDim %5151 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5156 = cirh.Mul %5154, %5155 : tensor<768xf32> loc(#loc337)
    %5157 = cirh.Mul %5156, %3369 : tensor<768xf32> loc(#loc338)
    %5158 = cirh.Sub %arg16, %5157 : tensor<768xf32> loc(#loc339)
    %5159 = cirh.Mul %gamma_grad_80, %3349 : tensor<768xf32> loc(#loc318)
    %5160 = cirh.Mul %arg761, %cst_8 : tensor<768xf32> loc(#loc3)
    %5161 = cirh.Mul %5159, %cst_7 : tensor<768xf32> loc(#loc3)
    %5162 = cirh.Add %5160, %5161 : tensor<768xf32> loc(#loc3)
    %5163 = cirh.Mul %arg762, %cst_6 : tensor<768xf32> loc(#loc2)
    %5164 = cirh.Mul %5159, %5159 : tensor<768xf32> loc(#loc2)
    %5165 = cirh.Mul %5164, %cst_5 : tensor<768xf32> loc(#loc2)
    %5166 = cirh.Add %5163, %5165 : tensor<768xf32> loc(#loc2)
    %5167 = cirh.Mul %arg763, %cst_69 : tensor<f32> loc(#loc319)
    %5168 = cirh.Mul %arg764, %cst_68 : tensor<f32> loc(#loc320)
    %5169 = cirh.Sub %cst_36, %arg763 : tensor<f32> loc(#loc331)
    %5170 = cirh.Sub %cst_36, %arg764 : tensor<f32> loc(#loc332)
    %5171 = cirh.Sqrt %5170 : tensor<f32> loc(#loc333)
    %5172 = cirh.Div %5171, %5169 : tensor<f32> loc(#loc334)
    %5173 = cirh.Sqrt %5166 : tensor<768xf32> loc(#loc335)
    %5174 = cirh.Add %5173, %cst_4 : tensor<768xf32> loc(#loc1)
    %5175 = cirh.Div %5162, %5174 : tensor<768xf32> loc(#loc336)
    %5176 = cirh.BroadcastInDim %5172 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5177 = cirh.Mul %5175, %5176 : tensor<768xf32> loc(#loc337)
    %5178 = cirh.Mul %5177, %3369 : tensor<768xf32> loc(#loc338)
    %5179 = cirh.Sub %arg13, %5178 : tensor<768xf32> loc(#loc339)
    %5180 = cirh.Mul %beta_grad_79, %3349 : tensor<768xf32> loc(#loc318)
    %5181 = cirh.Mul %arg765, %cst_8 : tensor<768xf32> loc(#loc3)
    %5182 = cirh.Mul %5180, %cst_7 : tensor<768xf32> loc(#loc3)
    %5183 = cirh.Add %5181, %5182 : tensor<768xf32> loc(#loc3)
    %5184 = cirh.Mul %arg766, %cst_6 : tensor<768xf32> loc(#loc2)
    %5185 = cirh.Mul %5180, %5180 : tensor<768xf32> loc(#loc2)
    %5186 = cirh.Mul %5185, %cst_5 : tensor<768xf32> loc(#loc2)
    %5187 = cirh.Add %5184, %5186 : tensor<768xf32> loc(#loc2)
    %5188 = cirh.Mul %arg767, %cst_69 : tensor<f32> loc(#loc319)
    %5189 = cirh.Mul %arg768, %cst_68 : tensor<f32> loc(#loc320)
    %5190 = cirh.Sub %cst_36, %arg767 : tensor<f32> loc(#loc331)
    %5191 = cirh.Sub %cst_36, %arg768 : tensor<f32> loc(#loc332)
    %5192 = cirh.Sqrt %5191 : tensor<f32> loc(#loc333)
    %5193 = cirh.Div %5192, %5190 : tensor<f32> loc(#loc334)
    %5194 = cirh.Sqrt %5187 : tensor<768xf32> loc(#loc335)
    %5195 = cirh.Add %5194, %cst_4 : tensor<768xf32> loc(#loc1)
    %5196 = cirh.Div %5183, %5195 : tensor<768xf32> loc(#loc336)
    %5197 = cirh.BroadcastInDim %5193 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5198 = cirh.Mul %5196, %5197 : tensor<768xf32> loc(#loc337)
    %5199 = cirh.Mul %5198, %3369 : tensor<768xf32> loc(#loc338)
    %5200 = cirh.Sub %arg12, %5199 : tensor<768xf32> loc(#loc339)
    %5201 = cirh.Mul %797, %3519 : tensor<3072xf32> loc(#loc318)
    %5202 = cirh.Mul %arg769, %cst_3 : tensor<3072xf32> loc(#loc3)
    %5203 = cirh.Mul %5201, %cst_2 : tensor<3072xf32> loc(#loc3)
    %5204 = cirh.Add %5202, %5203 : tensor<3072xf32> loc(#loc3)
    %5205 = cirh.Mul %arg770, %cst_1 : tensor<3072xf32> loc(#loc2)
    %5206 = cirh.Mul %5201, %5201 : tensor<3072xf32> loc(#loc2)
    %5207 = cirh.Mul %5206, %cst_0 : tensor<3072xf32> loc(#loc2)
    %5208 = cirh.Add %5205, %5207 : tensor<3072xf32> loc(#loc2)
    %5209 = cirh.Mul %arg771, %cst_69 : tensor<f32> loc(#loc319)
    %5210 = cirh.Mul %arg772, %cst_68 : tensor<f32> loc(#loc320)
    %5211 = cirh.Sub %cst_36, %arg771 : tensor<f32> loc(#loc331)
    %5212 = cirh.Sub %cst_36, %arg772 : tensor<f32> loc(#loc332)
    %5213 = cirh.Sqrt %5212 : tensor<f32> loc(#loc333)
    %5214 = cirh.Div %5213, %5211 : tensor<f32> loc(#loc334)
    %5215 = cirh.Sqrt %5208 : tensor<3072xf32> loc(#loc335)
    %5216 = cirh.Add %5215, %cst : tensor<3072xf32> loc(#loc1)
    %5217 = cirh.Div %5204, %5216 : tensor<3072xf32> loc(#loc336)
    %5218 = cirh.BroadcastInDim %5214 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc337)
    %5219 = cirh.Mul %5217, %5218 : tensor<3072xf32> loc(#loc337)
    %5220 = cirh.Mul %5219, %3539 : tensor<3072xf32> loc(#loc338)
    %5221 = cirh.Sub %arg155, %5220 : tensor<3072xf32> loc(#loc339)
    %5222 = cirh.Mul %788, %3349 : tensor<768xf32> loc(#loc318)
    %5223 = cirh.Mul %arg773, %cst_8 : tensor<768xf32> loc(#loc3)
    %5224 = cirh.Mul %5222, %cst_7 : tensor<768xf32> loc(#loc3)
    %5225 = cirh.Add %5223, %5224 : tensor<768xf32> loc(#loc3)
    %5226 = cirh.Mul %arg774, %cst_6 : tensor<768xf32> loc(#loc2)
    %5227 = cirh.Mul %5222, %5222 : tensor<768xf32> loc(#loc2)
    %5228 = cirh.Mul %5227, %cst_5 : tensor<768xf32> loc(#loc2)
    %5229 = cirh.Add %5226, %5228 : tensor<768xf32> loc(#loc2)
    %5230 = cirh.Mul %arg775, %cst_69 : tensor<f32> loc(#loc319)
    %5231 = cirh.Mul %arg776, %cst_68 : tensor<f32> loc(#loc320)
    %5232 = cirh.Sub %cst_36, %arg775 : tensor<f32> loc(#loc331)
    %5233 = cirh.Sub %cst_36, %arg776 : tensor<f32> loc(#loc332)
    %5234 = cirh.Sqrt %5233 : tensor<f32> loc(#loc333)
    %5235 = cirh.Div %5234, %5232 : tensor<f32> loc(#loc334)
    %5236 = cirh.Sqrt %5229 : tensor<768xf32> loc(#loc335)
    %5237 = cirh.Add %5236, %cst_4 : tensor<768xf32> loc(#loc1)
    %5238 = cirh.Div %5225, %5237 : tensor<768xf32> loc(#loc336)
    %5239 = cirh.BroadcastInDim %5235 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5240 = cirh.Mul %5238, %5239 : tensor<768xf32> loc(#loc337)
    %5241 = cirh.Mul %5240, %3369 : tensor<768xf32> loc(#loc338)
    %5242 = cirh.Sub %arg156, %5241 : tensor<768xf32> loc(#loc339)
    %5243 = cirh.Mul %780, %3349 : tensor<768xf32> loc(#loc318)
    %5244 = cirh.Mul %arg777, %cst_8 : tensor<768xf32> loc(#loc3)
    %5245 = cirh.Mul %5243, %cst_7 : tensor<768xf32> loc(#loc3)
    %5246 = cirh.Add %5244, %5245 : tensor<768xf32> loc(#loc3)
    %5247 = cirh.Mul %arg778, %cst_6 : tensor<768xf32> loc(#loc2)
    %5248 = cirh.Mul %5243, %5243 : tensor<768xf32> loc(#loc2)
    %5249 = cirh.Mul %5248, %cst_5 : tensor<768xf32> loc(#loc2)
    %5250 = cirh.Add %5247, %5249 : tensor<768xf32> loc(#loc2)
    %5251 = cirh.Mul %arg779, %cst_69 : tensor<f32> loc(#loc319)
    %5252 = cirh.Mul %arg780, %cst_68 : tensor<f32> loc(#loc320)
    %5253 = cirh.Sub %cst_36, %arg779 : tensor<f32> loc(#loc331)
    %5254 = cirh.Sub %cst_36, %arg780 : tensor<f32> loc(#loc332)
    %5255 = cirh.Sqrt %5254 : tensor<f32> loc(#loc333)
    %5256 = cirh.Div %5255, %5253 : tensor<f32> loc(#loc334)
    %5257 = cirh.Sqrt %5250 : tensor<768xf32> loc(#loc335)
    %5258 = cirh.Add %5257, %cst_4 : tensor<768xf32> loc(#loc1)
    %5259 = cirh.Div %5246, %5258 : tensor<768xf32> loc(#loc336)
    %5260 = cirh.BroadcastInDim %5256 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5261 = cirh.Mul %5259, %5260 : tensor<768xf32> loc(#loc337)
    %5262 = cirh.Mul %5261, %3369 : tensor<768xf32> loc(#loc338)
    %5263 = cirh.Sub %arg161, %5262 : tensor<768xf32> loc(#loc339)
    %5264 = cirh.Mul %775, %3349 : tensor<768xf32> loc(#loc318)
    %5265 = cirh.Mul %arg781, %cst_8 : tensor<768xf32> loc(#loc3)
    %5266 = cirh.Mul %5264, %cst_7 : tensor<768xf32> loc(#loc3)
    %5267 = cirh.Add %5265, %5266 : tensor<768xf32> loc(#loc3)
    %5268 = cirh.Mul %arg782, %cst_6 : tensor<768xf32> loc(#loc2)
    %5269 = cirh.Mul %5264, %5264 : tensor<768xf32> loc(#loc2)
    %5270 = cirh.Mul %5269, %cst_5 : tensor<768xf32> loc(#loc2)
    %5271 = cirh.Add %5268, %5270 : tensor<768xf32> loc(#loc2)
    %5272 = cirh.Mul %arg783, %cst_69 : tensor<f32> loc(#loc319)
    %5273 = cirh.Mul %arg784, %cst_68 : tensor<f32> loc(#loc320)
    %5274 = cirh.Sub %cst_36, %arg783 : tensor<f32> loc(#loc331)
    %5275 = cirh.Sub %cst_36, %arg784 : tensor<f32> loc(#loc332)
    %5276 = cirh.Sqrt %5275 : tensor<f32> loc(#loc333)
    %5277 = cirh.Div %5276, %5274 : tensor<f32> loc(#loc334)
    %5278 = cirh.Sqrt %5271 : tensor<768xf32> loc(#loc335)
    %5279 = cirh.Add %5278, %cst_4 : tensor<768xf32> loc(#loc1)
    %5280 = cirh.Div %5267, %5279 : tensor<768xf32> loc(#loc336)
    %5281 = cirh.BroadcastInDim %5277 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5282 = cirh.Mul %5280, %5281 : tensor<768xf32> loc(#loc337)
    %5283 = cirh.Mul %5282, %3369 : tensor<768xf32> loc(#loc338)
    %5284 = cirh.Sub %arg159, %5283 : tensor<768xf32> loc(#loc339)
    %5285 = cirh.Mul %770, %3349 : tensor<768xf32> loc(#loc318)
    %5286 = cirh.Mul %arg785, %cst_8 : tensor<768xf32> loc(#loc3)
    %5287 = cirh.Mul %5285, %cst_7 : tensor<768xf32> loc(#loc3)
    %5288 = cirh.Add %5286, %5287 : tensor<768xf32> loc(#loc3)
    %5289 = cirh.Mul %arg786, %cst_6 : tensor<768xf32> loc(#loc2)
    %5290 = cirh.Mul %5285, %5285 : tensor<768xf32> loc(#loc2)
    %5291 = cirh.Mul %5290, %cst_5 : tensor<768xf32> loc(#loc2)
    %5292 = cirh.Add %5289, %5291 : tensor<768xf32> loc(#loc2)
    %5293 = cirh.Mul %arg787, %cst_69 : tensor<f32> loc(#loc319)
    %5294 = cirh.Mul %arg788, %cst_68 : tensor<f32> loc(#loc320)
    %5295 = cirh.Sub %cst_36, %arg787 : tensor<f32> loc(#loc331)
    %5296 = cirh.Sub %cst_36, %arg788 : tensor<f32> loc(#loc332)
    %5297 = cirh.Sqrt %5296 : tensor<f32> loc(#loc333)
    %5298 = cirh.Div %5297, %5295 : tensor<f32> loc(#loc334)
    %5299 = cirh.Sqrt %5292 : tensor<768xf32> loc(#loc335)
    %5300 = cirh.Add %5299, %cst_4 : tensor<768xf32> loc(#loc1)
    %5301 = cirh.Div %5288, %5300 : tensor<768xf32> loc(#loc336)
    %5302 = cirh.BroadcastInDim %5298 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5303 = cirh.Mul %5301, %5302 : tensor<768xf32> loc(#loc337)
    %5304 = cirh.Mul %5303, %3369 : tensor<768xf32> loc(#loc338)
    %5305 = cirh.Sub %arg157, %5304 : tensor<768xf32> loc(#loc339)
    %5306 = cirh.Mul %765, %3349 : tensor<768xf32> loc(#loc318)
    %5307 = cirh.Mul %arg789, %cst_8 : tensor<768xf32> loc(#loc3)
    %5308 = cirh.Mul %5306, %cst_7 : tensor<768xf32> loc(#loc3)
    %5309 = cirh.Add %5307, %5308 : tensor<768xf32> loc(#loc3)
    %5310 = cirh.Mul %arg790, %cst_6 : tensor<768xf32> loc(#loc2)
    %5311 = cirh.Mul %5306, %5306 : tensor<768xf32> loc(#loc2)
    %5312 = cirh.Mul %5311, %cst_5 : tensor<768xf32> loc(#loc2)
    %5313 = cirh.Add %5310, %5312 : tensor<768xf32> loc(#loc2)
    %5314 = cirh.Mul %arg791, %cst_69 : tensor<f32> loc(#loc319)
    %5315 = cirh.Mul %arg792, %cst_68 : tensor<f32> loc(#loc320)
    %5316 = cirh.Sub %cst_36, %arg791 : tensor<f32> loc(#loc331)
    %5317 = cirh.Sub %cst_36, %arg792 : tensor<f32> loc(#loc332)
    %5318 = cirh.Sqrt %5317 : tensor<f32> loc(#loc333)
    %5319 = cirh.Div %5318, %5316 : tensor<f32> loc(#loc334)
    %5320 = cirh.Sqrt %5313 : tensor<768xf32> loc(#loc335)
    %5321 = cirh.Add %5320, %cst_4 : tensor<768xf32> loc(#loc1)
    %5322 = cirh.Div %5309, %5321 : tensor<768xf32> loc(#loc336)
    %5323 = cirh.BroadcastInDim %5319 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5324 = cirh.Mul %5322, %5323 : tensor<768xf32> loc(#loc337)
    %5325 = cirh.Mul %5324, %3369 : tensor<768xf32> loc(#loc338)
    %5326 = cirh.Sub %arg162, %5325 : tensor<768xf32> loc(#loc339)
    %5327 = cirh.Mul %gamma_grad_77, %3349 : tensor<768xf32> loc(#loc318)
    %5328 = cirh.Mul %arg793, %cst_8 : tensor<768xf32> loc(#loc3)
    %5329 = cirh.Mul %5327, %cst_7 : tensor<768xf32> loc(#loc3)
    %5330 = cirh.Add %5328, %5329 : tensor<768xf32> loc(#loc3)
    %5331 = cirh.Mul %arg794, %cst_6 : tensor<768xf32> loc(#loc2)
    %5332 = cirh.Mul %5327, %5327 : tensor<768xf32> loc(#loc2)
    %5333 = cirh.Mul %5332, %cst_5 : tensor<768xf32> loc(#loc2)
    %5334 = cirh.Add %5331, %5333 : tensor<768xf32> loc(#loc2)
    %5335 = cirh.Mul %arg795, %cst_69 : tensor<f32> loc(#loc319)
    %5336 = cirh.Mul %arg796, %cst_68 : tensor<f32> loc(#loc320)
    %5337 = cirh.Sub %cst_36, %arg795 : tensor<f32> loc(#loc331)
    %5338 = cirh.Sub %cst_36, %arg796 : tensor<f32> loc(#loc332)
    %5339 = cirh.Sqrt %5338 : tensor<f32> loc(#loc333)
    %5340 = cirh.Div %5339, %5337 : tensor<f32> loc(#loc334)
    %5341 = cirh.Sqrt %5334 : tensor<768xf32> loc(#loc335)
    %5342 = cirh.Add %5341, %cst_4 : tensor<768xf32> loc(#loc1)
    %5343 = cirh.Div %5330, %5342 : tensor<768xf32> loc(#loc336)
    %5344 = cirh.BroadcastInDim %5340 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5345 = cirh.Mul %5343, %5344 : tensor<768xf32> loc(#loc337)
    %5346 = cirh.Mul %5345, %3369 : tensor<768xf32> loc(#loc338)
    %5347 = cirh.Sub %arg9, %5346 : tensor<768xf32> loc(#loc339)
    %5348 = cirh.Mul %beta_grad_76, %3349 : tensor<768xf32> loc(#loc318)
    %5349 = cirh.Mul %arg797, %cst_8 : tensor<768xf32> loc(#loc3)
    %5350 = cirh.Mul %5348, %cst_7 : tensor<768xf32> loc(#loc3)
    %5351 = cirh.Add %5349, %5350 : tensor<768xf32> loc(#loc3)
    %5352 = cirh.Mul %arg798, %cst_6 : tensor<768xf32> loc(#loc2)
    %5353 = cirh.Mul %5348, %5348 : tensor<768xf32> loc(#loc2)
    %5354 = cirh.Mul %5353, %cst_5 : tensor<768xf32> loc(#loc2)
    %5355 = cirh.Add %5352, %5354 : tensor<768xf32> loc(#loc2)
    %5356 = cirh.Mul %arg799, %cst_69 : tensor<f32> loc(#loc319)
    %5357 = cirh.Mul %arg800, %cst_68 : tensor<f32> loc(#loc320)
    %5358 = cirh.Sub %cst_36, %arg799 : tensor<f32> loc(#loc331)
    %5359 = cirh.Sub %cst_36, %arg800 : tensor<f32> loc(#loc332)
    %5360 = cirh.Sqrt %5359 : tensor<f32> loc(#loc333)
    %5361 = cirh.Div %5360, %5358 : tensor<f32> loc(#loc334)
    %5362 = cirh.Sqrt %5355 : tensor<768xf32> loc(#loc335)
    %5363 = cirh.Add %5362, %cst_4 : tensor<768xf32> loc(#loc1)
    %5364 = cirh.Div %5351, %5363 : tensor<768xf32> loc(#loc336)
    %5365 = cirh.BroadcastInDim %5361 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5366 = cirh.Mul %5364, %5365 : tensor<768xf32> loc(#loc337)
    %5367 = cirh.Mul %5366, %3369 : tensor<768xf32> loc(#loc338)
    %5368 = cirh.Sub %arg8, %5367 : tensor<768xf32> loc(#loc339)
    %5369 = cirh.Mul %gamma_grad_74, %3349 : tensor<768xf32> loc(#loc318)
    %5370 = cirh.Mul %arg801, %cst_8 : tensor<768xf32> loc(#loc3)
    %5371 = cirh.Mul %5369, %cst_7 : tensor<768xf32> loc(#loc3)
    %5372 = cirh.Add %5370, %5371 : tensor<768xf32> loc(#loc3)
    %5373 = cirh.Mul %arg802, %cst_6 : tensor<768xf32> loc(#loc2)
    %5374 = cirh.Mul %5369, %5369 : tensor<768xf32> loc(#loc2)
    %5375 = cirh.Mul %5374, %cst_5 : tensor<768xf32> loc(#loc2)
    %5376 = cirh.Add %5373, %5375 : tensor<768xf32> loc(#loc2)
    %5377 = cirh.Mul %arg803, %cst_69 : tensor<f32> loc(#loc319)
    %5378 = cirh.Mul %arg804, %cst_68 : tensor<f32> loc(#loc320)
    %5379 = cirh.Sub %cst_36, %arg803 : tensor<f32> loc(#loc331)
    %5380 = cirh.Sub %cst_36, %arg804 : tensor<f32> loc(#loc332)
    %5381 = cirh.Sqrt %5380 : tensor<f32> loc(#loc333)
    %5382 = cirh.Div %5381, %5379 : tensor<f32> loc(#loc334)
    %5383 = cirh.Sqrt %5376 : tensor<768xf32> loc(#loc335)
    %5384 = cirh.Add %5383, %cst_4 : tensor<768xf32> loc(#loc1)
    %5385 = cirh.Div %5372, %5384 : tensor<768xf32> loc(#loc336)
    %5386 = cirh.BroadcastInDim %5382 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5387 = cirh.Mul %5385, %5386 : tensor<768xf32> loc(#loc337)
    %5388 = cirh.Mul %5387, %3369 : tensor<768xf32> loc(#loc338)
    %5389 = cirh.Sub %arg5, %5388 : tensor<768xf32> loc(#loc339)
    %5390 = cirh.Mul %beta_grad_73, %3349 : tensor<768xf32> loc(#loc318)
    %5391 = cirh.Mul %arg805, %cst_8 : tensor<768xf32> loc(#loc3)
    %5392 = cirh.Mul %5390, %cst_7 : tensor<768xf32> loc(#loc3)
    %5393 = cirh.Add %5391, %5392 : tensor<768xf32> loc(#loc3)
    %5394 = cirh.Mul %arg806, %cst_6 : tensor<768xf32> loc(#loc2)
    %5395 = cirh.Mul %5390, %5390 : tensor<768xf32> loc(#loc2)
    %5396 = cirh.Mul %5395, %cst_5 : tensor<768xf32> loc(#loc2)
    %5397 = cirh.Add %5394, %5396 : tensor<768xf32> loc(#loc2)
    %5398 = cirh.Mul %arg807, %cst_69 : tensor<f32> loc(#loc319)
    %5399 = cirh.Mul %arg808, %cst_68 : tensor<f32> loc(#loc320)
    %5400 = cirh.Sub %cst_36, %arg807 : tensor<f32> loc(#loc331)
    %5401 = cirh.Sub %cst_36, %arg808 : tensor<f32> loc(#loc332)
    %5402 = cirh.Sqrt %5401 : tensor<f32> loc(#loc333)
    %5403 = cirh.Div %5402, %5400 : tensor<f32> loc(#loc334)
    %5404 = cirh.Sqrt %5397 : tensor<768xf32> loc(#loc335)
    %5405 = cirh.Add %5404, %cst_4 : tensor<768xf32> loc(#loc1)
    %5406 = cirh.Div %5393, %5405 : tensor<768xf32> loc(#loc336)
    %5407 = cirh.BroadcastInDim %5403 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5408 = cirh.Mul %5406, %5407 : tensor<768xf32> loc(#loc337)
    %5409 = cirh.Mul %5408, %3369 : tensor<768xf32> loc(#loc338)
    %5410 = cirh.Sub %arg4, %5409 : tensor<768xf32> loc(#loc339)
    %5411 = cirh.Mul %715, %3519 : tensor<3072xf32> loc(#loc318)
    %5412 = cirh.Mul %arg809, %cst_3 : tensor<3072xf32> loc(#loc3)
    %5413 = cirh.Mul %5411, %cst_2 : tensor<3072xf32> loc(#loc3)
    %5414 = cirh.Add %5412, %5413 : tensor<3072xf32> loc(#loc3)
    %5415 = cirh.Mul %arg810, %cst_1 : tensor<3072xf32> loc(#loc2)
    %5416 = cirh.Mul %5411, %5411 : tensor<3072xf32> loc(#loc2)
    %5417 = cirh.Mul %5416, %cst_0 : tensor<3072xf32> loc(#loc2)
    %5418 = cirh.Add %5415, %5417 : tensor<3072xf32> loc(#loc2)
    %5419 = cirh.Mul %arg811, %cst_69 : tensor<f32> loc(#loc319)
    %5420 = cirh.Mul %arg812, %cst_68 : tensor<f32> loc(#loc320)
    %5421 = cirh.Sub %cst_36, %arg811 : tensor<f32> loc(#loc331)
    %5422 = cirh.Sub %cst_36, %arg812 : tensor<f32> loc(#loc332)
    %5423 = cirh.Sqrt %5422 : tensor<f32> loc(#loc333)
    %5424 = cirh.Div %5423, %5421 : tensor<f32> loc(#loc334)
    %5425 = cirh.Sqrt %5418 : tensor<3072xf32> loc(#loc335)
    %5426 = cirh.Add %5425, %cst : tensor<3072xf32> loc(#loc1)
    %5427 = cirh.Div %5414, %5426 : tensor<3072xf32> loc(#loc336)
    %5428 = cirh.BroadcastInDim %5424 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3072xf32> loc(#loc337)
    %5429 = cirh.Mul %5427, %5428 : tensor<3072xf32> loc(#loc337)
    %5430 = cirh.Mul %5429, %3539 : tensor<3072xf32> loc(#loc338)
    %5431 = cirh.Sub %arg163, %5430 : tensor<3072xf32> loc(#loc339)
    %5432 = cirh.Mul %706, %3349 : tensor<768xf32> loc(#loc318)
    %5433 = cirh.Mul %arg813, %cst_8 : tensor<768xf32> loc(#loc3)
    %5434 = cirh.Mul %5432, %cst_7 : tensor<768xf32> loc(#loc3)
    %5435 = cirh.Add %5433, %5434 : tensor<768xf32> loc(#loc3)
    %5436 = cirh.Mul %arg814, %cst_6 : tensor<768xf32> loc(#loc2)
    %5437 = cirh.Mul %5432, %5432 : tensor<768xf32> loc(#loc2)
    %5438 = cirh.Mul %5437, %cst_5 : tensor<768xf32> loc(#loc2)
    %5439 = cirh.Add %5436, %5438 : tensor<768xf32> loc(#loc2)
    %5440 = cirh.Mul %arg815, %cst_69 : tensor<f32> loc(#loc319)
    %5441 = cirh.Mul %arg816, %cst_68 : tensor<f32> loc(#loc320)
    %5442 = cirh.Sub %cst_36, %arg815 : tensor<f32> loc(#loc331)
    %5443 = cirh.Sub %cst_36, %arg816 : tensor<f32> loc(#loc332)
    %5444 = cirh.Sqrt %5443 : tensor<f32> loc(#loc333)
    %5445 = cirh.Div %5444, %5442 : tensor<f32> loc(#loc334)
    %5446 = cirh.Sqrt %5439 : tensor<768xf32> loc(#loc335)
    %5447 = cirh.Add %5446, %cst_4 : tensor<768xf32> loc(#loc1)
    %5448 = cirh.Div %5435, %5447 : tensor<768xf32> loc(#loc336)
    %5449 = cirh.BroadcastInDim %5445 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5450 = cirh.Mul %5448, %5449 : tensor<768xf32> loc(#loc337)
    %5451 = cirh.Mul %5450, %3369 : tensor<768xf32> loc(#loc338)
    %5452 = cirh.Sub %arg164, %5451 : tensor<768xf32> loc(#loc339)
    %5453 = cirh.Mul %gamma_grad, %3349 : tensor<768xf32> loc(#loc318)
    %5454 = cirh.Mul %arg817, %cst_8 : tensor<768xf32> loc(#loc3)
    %5455 = cirh.Mul %5453, %cst_7 : tensor<768xf32> loc(#loc3)
    %5456 = cirh.Add %5454, %5455 : tensor<768xf32> loc(#loc3)
    %5457 = cirh.Mul %arg818, %cst_6 : tensor<768xf32> loc(#loc2)
    %5458 = cirh.Mul %5453, %5453 : tensor<768xf32> loc(#loc2)
    %5459 = cirh.Mul %5458, %cst_5 : tensor<768xf32> loc(#loc2)
    %5460 = cirh.Add %5457, %5459 : tensor<768xf32> loc(#loc2)
    %5461 = cirh.Mul %arg819, %cst_69 : tensor<f32> loc(#loc319)
    %5462 = cirh.Mul %arg820, %cst_68 : tensor<f32> loc(#loc320)
    %5463 = cirh.Sub %cst_36, %arg819 : tensor<f32> loc(#loc331)
    %5464 = cirh.Sub %cst_36, %arg820 : tensor<f32> loc(#loc332)
    %5465 = cirh.Sqrt %5464 : tensor<f32> loc(#loc333)
    %5466 = cirh.Div %5465, %5463 : tensor<f32> loc(#loc334)
    %5467 = cirh.Sqrt %5460 : tensor<768xf32> loc(#loc335)
    %5468 = cirh.Add %5467, %cst_4 : tensor<768xf32> loc(#loc1)
    %5469 = cirh.Div %5456, %5468 : tensor<768xf32> loc(#loc336)
    %5470 = cirh.BroadcastInDim %5466 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5471 = cirh.Mul %5469, %5470 : tensor<768xf32> loc(#loc337)
    %5472 = cirh.Mul %5471, %3369 : tensor<768xf32> loc(#loc338)
    %5473 = cirh.Sub %arg1, %5472 : tensor<768xf32> loc(#loc339)
    %5474 = cirh.Mul %beta_grad, %3349 : tensor<768xf32> loc(#loc318)
    %5475 = cirh.Mul %arg821, %cst_8 : tensor<768xf32> loc(#loc3)
    %5476 = cirh.Mul %5474, %cst_7 : tensor<768xf32> loc(#loc3)
    %5477 = cirh.Add %5475, %5476 : tensor<768xf32> loc(#loc3)
    %5478 = cirh.Mul %arg822, %cst_6 : tensor<768xf32> loc(#loc2)
    %5479 = cirh.Mul %5474, %5474 : tensor<768xf32> loc(#loc2)
    %5480 = cirh.Mul %5479, %cst_5 : tensor<768xf32> loc(#loc2)
    %5481 = cirh.Add %5478, %5480 : tensor<768xf32> loc(#loc2)
    %5482 = cirh.Mul %arg823, %cst_69 : tensor<f32> loc(#loc319)
    %5483 = cirh.Mul %arg824, %cst_68 : tensor<f32> loc(#loc320)
    %5484 = cirh.Sub %cst_36, %arg823 : tensor<f32> loc(#loc331)
    %5485 = cirh.Sub %cst_36, %arg824 : tensor<f32> loc(#loc332)
    %5486 = cirh.Sqrt %5485 : tensor<f32> loc(#loc333)
    %5487 = cirh.Div %5486, %5484 : tensor<f32> loc(#loc334)
    %5488 = cirh.Sqrt %5481 : tensor<768xf32> loc(#loc335)
    %5489 = cirh.Add %5488, %cst_4 : tensor<768xf32> loc(#loc1)
    %5490 = cirh.Div %5477, %5489 : tensor<768xf32> loc(#loc336)
    %5491 = cirh.BroadcastInDim %5487 {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<768xf32> loc(#loc337)
    %5492 = cirh.Mul %5490, %5491 : tensor<768xf32> loc(#loc337)
    %5493 = cirh.Mul %5492, %3369 : tensor<768xf32> loc(#loc338)
    %5494 = cirh.Sub %arg0, %5493 : tensor<768xf32> loc(#loc339)
    %5495 = cirh.Add %arg172, %cst_59 : tensor<i64> loc(#loc340)
    %5496 = cirh.Add %arg171, %cst_59 : tensor<i64> loc(#loc341)
    %5497 = cirh.Compare %5495, %cst_60 {comparison_direction = "LE"} : tensor<i64> -> tensor<i1> loc(#loc342)
    %5498 = cirh.Select %5497, %cst_58, %cst_59 : (tensor<i1>, tensor<i64>, tensor<i64>) -> tensor<i64> loc(#loc343)
    %5499 = cirh.Add %arg170, %5498 : tensor<i64> loc(#loc344)
    %5500 = cirh.Cast %5499 {Truncate = false} : tensor<i64> -> tensor<f32> loc(#loc345)
    %5501 = cirh.Clamp %cst_64, %cst_41, %5500 : (tensor<f32>, tensor<f32>, tensor<f32>) -> tensor<f32> loc(#loc345)
    %5502 = cirh.Mul %5501, %cst_63 : tensor<f32> loc(#loc346)
    %5503 = cirh.Cos %5502 : tensor<f32> loc(#loc347)
    %5504 = cirh.Add %5503, %cst_36 : tensor<f32> loc(#loc346)
    %5505 = cirh.Mul %5504, %cst_65 : tensor<f32> loc(#loc346)
    %5506 = cirh.Mul %5505, %cst_66 : tensor<f32> loc(#loc348)
    %5507 = cirh.Add %5506, %cst_67 : tensor<f32> loc(#loc348)
    %5508 = cirh.Cast %5496 {Truncate = false} : tensor<i64> -> tensor<f32> loc(#loc349)
    %5509 = cirh.Div %5508, %cst_35 : tensor<f32> loc(#loc349)
    %5510 = cirh.Sub %cst_36, %5509 : tensor<f32> loc(#loc350)
    %5511 = cirh.Mul %5510, %cst_61 : tensor<f32> loc(#loc351)
    %5512 = cirh.Add %5511, %cst_62 : tensor<f32> loc(#loc351)
    %5513 = cirh.Compare %5496, %cst_60 {comparison_direction = "GE"} : tensor<i64> -> tensor<i1> loc(#loc352)
    %5514 = cirh.Select %5513, %cst_62, %5512 : (tensor<i1>, tensor<f32>, tensor<f32>) -> tensor<f32> loc(#loc353)
    %5515 = cirh.Compare %5495, %cst_60 {comparison_direction = "LT"} : tensor<i64> -> tensor<i1> loc(#loc354)
    %5516 = cirh.Select %5515, %5514, %5507 : (tensor<i1>, tensor<f32>, tensor<f32>) -> tensor<f32> loc(#loc355)
    %5517 = cirh.Reduce %loss {dimensions = dense<0> : tensor<1xi64>, keep_dims = dense<> : tensor<0xi64>, reduce_kind = "ADD"} : (tensor<245760xf32>) -> tensor<f32> loc(#loc356)
    %5518 = cirh.Div %5517, %cst_52 : tensor<f32> loc(#loc357)
    %5519 = cirh.Cast %5518 {Truncate = false} : tensor<f32> -> tensor<bf16> loc(#loc358)
    return %1900, %1904, %1905, %1906, %1937, %1942, %1946, %1947, %1948, %1962, %1967, %1971, %1972, %1973, %1987, %1991, %1995, %1996, %1997, %2010, %2014, %2018, %2019, %2020, %2033, %2037, %2041, %2042, %2043, %2056, %2061, %2065, %2066, %2067, %2081, %2086, %2090, %2091, %2092, %2106, %2110, %2114, %2115, %2116, %2129, %2133, %2137, %2138, %2139, %2152, %2156, %2160, %2161, %2162, %2175, %2179, %2183, %2184, %2185, %2198, %2202, %2206, %2207, %2208, %2221, %2225, %2229, %2230, %2231, %2244, %2248, %2252, %2253, %2254, %2267, %2271, %2275, %2276, %2277, %2290, %2294, %2298, %2299, %2300, %2313, %2317, %2321, %2322, %2323, %2336, %2340, %2344, %2345, %2346, %2359, %2363, %2367, %2368, %2369, %2382, %2386, %2390, %2391, %2392, %2405, %2409, %2413, %2414, %2415, %2428, %2432, %2436, %2437, %2438, %2451, %2455, %2459, %2460, %2461, %2474, %2478, %2482, %2483, %2484, %2497, %2501, %2505, %2506, %2507, %2520, %2524, %2528, %2529, %2530, %2543, %2547, %2551, %2552, %2553, %2566, %2570, %2574, %2575, %2576, %2589, %2593, %2597, %2598, %2599, %2612, %2616, %2620, %2621, %2622, %2635, %2639, %2643, %2644, %2645, %2658, %2662, %2666, %2667, %2668, %2681, %2685, %2689, %2690, %2691, %2704, %2708, %2712, %2713, %2714, %2727, %2731, %2735, %2736, %2737, %2750, %2754, %2758, %2759, %2760, %2773, %2777, %2781, %2782, %2783, %2796, %2800, %2804, %2805, %2806, %2819, %2823, %2827, %2828, %2829, %2842, %2846, %2850, %2851, %2852, %2865, %2869, %2873, %2874, %2875, %2888, %2892, %2896, %2897, %2898, %2911, %2915, %2919, %2920, %2921, %2934, %2938, %2942, %2943, %2944, %2957, %2961, %2965, %2966, %2967, %2980, %2984, %2988, %2989, %2990, %3003, %3007, %3011, %3012, %3013, %3026, %3030, %3034, %3035, %3036, %3049, %3053, %3057, %3058, %3059, %3072, %3076, %3080, %3081, %3082, %3095, %3099, %3103, %3104, %3105, %3118, %3122, %3126, %3127, %3128, %3141, %3145, %3149, %3150, %3151, %3164, %3168, %3172, %3173, %3174, %3187, %3191, %3195, %3196, %3197, %3210, %3214, %3218, %3219, %3220, %3233, %3237, %3241, %3242, %3243, %3256, %3260, %3264, %3265, %3266, %3279, %3283, %3287, %3288, %3289, %3302, %3306, %3310, %3311, %3312, %3325, %3329, %3333, %3334, %3335, %3348, %3353, %3357, %3358, %3359, %3371, %3375, %3379, %3380, %3381, %3392, %3396, %3400, %3401, %3402, %3413, %3417, %3421, %3422, %3423, %3434, %3438, %3442, %3443, %3444, %3455, %3459, %3463, %3464, %3465, %3476, %3480, %3484, %3485, %3486, %3497, %3501, %3505, %3506, %3507, %3518, %3523, %3527, %3528, %3529, %3541, %3545, %3549, %3550, %3551, %3562, %3566, %3570, %3571, %3572, %3583, %3587, %3591, %3592, %3593, %3604, %3608, %3612, %3613, %3614, %3625, %3629, %3633, %3634, %3635, %3646, %3650, %3654, %3655, %3656, %3667, %3671, %3675, %3676, %3677, %3688, %3692, %3696, %3697, %3698, %3709, %3713, %3717, %3718, %3719, %3730, %3734, %3738, %3739, %3740, %3751, %3755, %3759, %3760, %3761, %3772, %3776, %3780, %3781, %3782, %3793, %3797, %3801, %3802, %3803, %3814, %3818, %3822, %3823, %3824, %3835, %3839, %3843, %3844, %3845, %3856, %3860, %3864, %3865, %3866, %3877, %3881, %3885, %3886, %3887, %3898, %3902, %3906, %3907, %3908, %3919, %3923, %3927, %3928, %3929, %3940, %3944, %3948, %3949, %3950, %3961, %3965, %3969, %3970, %3971, %3982, %3986, %3990, %3991, %3992, %4003, %4007, %4011, %4012, %4013, %4024, %4028, %4032, %4033, %4034, %4045, %4049, %4053, %4054, %4055, %4066, %4070, %4074, %4075, %4076, %4087, %4091, %4095, %4096, %4097, %4108, %4112, %4116, %4117, %4118, %4129, %4133, %4137, %4138, %4139, %4150, %4154, %4158, %4159, %4160, %4171, %4175, %4179, %4180, %4181, %4192, %4196, %4200, %4201, %4202, %4213, %4217, %4221, %4222, %4223, %4234, %4238, %4242, %4243, %4244, %4255, %4259, %4263, %4264, %4265, %4276, %4280, %4284, %4285, %4286, %4297, %4301, %4305, %4306, %4307, %4318, %4322, %4326, %4327, %4328, %4339, %4343, %4347, %4348, %4349, %4360, %4364, %4368, %4369, %4370, %4381, %4385, %4389, %4390, %4391, %4402, %4406, %4410, %4411, %4412, %4423, %4427, %4431, %4432, %4433, %4444, %4448, %4452, %4453, %4454, %4465, %4469, %4473, %4474, %4475, %4486, %4490, %4494, %4495, %4496, %4507, %4511, %4515, %4516, %4517, %4528, %4532, %4536, %4537, %4538, %4549, %4553, %4557, %4558, %4559, %4570, %4574, %4578, %4579, %4580, %4591, %4595, %4599, %4600, %4601, %4612, %4616, %4620, %4621, %4622, %4633, %4637, %4641, %4642, %4643, %4654, %4658, %4662, %4663, %4664, %4675, %4679, %4683, %4684, %4685, %4696, %4700, %4704, %4705, %4706, %4717, %4721, %4725, %4726, %4727, %4738, %4742, %4746, %4747, %4748, %4759, %4763, %4767, %4768, %4769, %4780, %4784, %4788, %4789, %4790, %4801, %4805, %4809, %4810, %4811, %4822, %4826, %4830, %4831, %4832, %4843, %4847, %4851, %4852, %4853, %4864, %4868, %4872, %4873, %4874, %4885, %4889, %4893, %4894, %4895, %4906, %4910, %4914, %4915, %4916, %4927, %4931, %4935, %4936, %4937, %4948, %4952, %4956, %4957, %4958, %4969, %4973, %4977, %4978, %4979, %4990, %4994, %4998, %4999, %5000, %5011, %5015, %5019, %5020, %5021, %5032, %5036, %5040, %5041, %5042, %5053, %5057, %5061, %5062, %5063, %5074, %5078, %5082, %5083, %5084, %5095, %5099, %5103, %5104, %5105, %5116, %5120, %5124, %5125, %5126, %5137, %5141, %5145, %5146, %5147, %5158, %5162, %5166, %5167, %5168, %5179, %5183, %5187, %5188, %5189, %5200, %5204, %5208, %5209, %5210, %5221, %5225, %5229, %5230, %5231, %5242, %5246, %5250, %5251, %5252, %5263, %5267, %5271, %5272, %5273, %5284, %5288, %5292, %5293, %5294, %5305, %5309, %5313, %5314, %5315, %5326, %5330, %5334, %5335, %5336, %5347, %5351, %5355, %5356, %5357, %5368, %5372, %5376, %5377, %5378, %5389, %5393, %5397, %5398, %5399, %5410, %5414, %5418, %5419, %5420, %5431, %5435, %5439, %5440, %5441, %5452, %5456, %5460, %5461, %5462, %5473, %5477, %5481, %5482, %5483, %5494, %5495, %5496, %5499, %5516, %5519 : tensor<50257x768xf32>, tensor<50257x768xf32>, tensor<f32>, tensor<f32>, tensor<50257x768xf32>, tensor<2048x768xf32>, tensor<2048x768xf32>, tensor<f32>, tensor<f32>, tensor<2048x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<768x768xf32>, tensor<f32>, tensor<f32>, tensor<768x768xf32>, tensor<3072x768xf32>, tensor<3072x768xf32>, tensor<f32>, tensor<f32>, tensor<3072x768xf32>, tensor<768x3072xf32>, tensor<768x3072xf32>, tensor<f32>, tensor<f32>, tensor<768x3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<3072xf32>, tensor<3072xf32>, tensor<f32>, tensor<f32>, tensor<3072xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<768xf32>, tensor<768xf32>, tensor<f32>, tensor<f32>, tensor<768xf32>, tensor<i64>, tensor<i64>, tensor<i64>, tensor<f32>, tensor<bf16> loc(#loc0)
  } loc(#loc0)
} loc(#loc0)
#loc1 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":156:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":128:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc2 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":156:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":118:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc3 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":156:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":117:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc4 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":156:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":148:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc5 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":238:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":506:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("pre_optimizer_step"("cerebras_pytorch/backend/ltc_backend.py":395:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":472:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc6 = loc("CrossEntropyLoss_1.fwd"(callsite("cross_entropy"("torch/nn/functional.py":3029:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/loss.py":1174:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":176:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc7 = loc("wte.bwd"(callsite("clip_grad_norm_"("torch/nn/utils/clip_grad.py":73:0) at callsite("training_step"("train.py":118:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))
#loc8 = loc("wte.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc9 = loc("wpe.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc10 = loc("GPTModel_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc11 = loc(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("forward"("model.py":62:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc12 = loc(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("forward"("model.py":165:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))
#loc13 = loc(callsite("forward"("model.py":157:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))
#loc14 = loc(callsite("forward"("model.py":158:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))
#loc15 = loc(callsite("forward"("model.py":60:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc16 = loc("decoder.9.ffn.proj.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc17 = loc("decoder.9.ffn.fc.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc18 = loc("decoder.9.attn.proj_output.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc19 = loc("decoder.9.attn.proj_v.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc20 = loc("decoder.8.ffn.proj.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc21 = loc("decoder.8.ffn.fc.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc22 = loc("decoder.8.attn.proj_output.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc23 = loc("decoder.8.attn.proj_v.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc24 = loc("decoder.7.ffn.proj.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc25 = loc("decoder.7.ffn.fc.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc26 = loc("decoder.7.attn.proj_output.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc27 = loc("decoder.7.attn.proj_v.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc28 = loc("decoder.6.ffn.proj.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc29 = loc("decoder.6.ffn.fc.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc30 = loc("decoder.6.attn.proj_output.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc31 = loc("decoder.6.attn.proj_v.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc32 = loc("decoder.5.ffn.proj.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc33 = loc("decoder.5.ffn.fc.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc34 = loc("decoder.5.attn.proj_output.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc35 = loc("decoder.5.attn.proj_v.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc36 = loc("decoder.4.ffn.proj.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc37 = loc("decoder.4.ffn.fc.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc38 = loc("decoder.4.attn.proj_output.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc39 = loc("decoder.4.attn.proj_v.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc40 = loc("decoder.3.ffn.proj.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc41 = loc("decoder.3.ffn.fc.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc42 = loc("decoder.3.attn.proj_output.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc43 = loc("decoder.3.attn.proj_v.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc44 = loc("decoder.2.ffn.proj.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc45 = loc("decoder.2.ffn.fc.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc46 = loc("decoder.2.attn.proj_output.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc47 = loc("decoder.2.attn.proj_v.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc48 = loc("decoder.1.ffn.proj.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc49 = loc("decoder.1.ffn.fc.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc50 = loc("decoder.1.attn.proj_output.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc51 = loc("decoder.1.attn.proj_v.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc52 = loc("decoder.0.ffn.proj.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc53 = loc("decoder.0.ffn.fc.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc54 = loc("decoder.0.attn.proj_output.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc55 = loc("decoder.0.attn.proj_v.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc56 = loc(callsite("forward"("model.py":151:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))
#loc57 = loc("wpe.fwd"(callsite("embedding"("torch/nn/functional.py":2210:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/sparse.py":162:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":154:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc58 = loc("wpe.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/sparse.py":162:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":154:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc59 = loc("wte.fwd"(callsite("embedding"("torch/nn/functional.py":2210:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/sparse.py":162:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":150:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc60 = loc("wte.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/sparse.py":162:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":150:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc61 = loc(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("forward"("model.py":154:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))
#loc62 = loc("decoder.0.ln_1.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc63 = loc("decoder.0.ln_1.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc64 = loc("decoder.0.ln_1.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc65 = loc("decoder.0.attn.proj_v.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc66 = loc("decoder.0.attn.proj_k.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc67 = loc("decoder.0.attn.proj_k.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc68 = loc(callsite("forward"("model.py":58:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc69 = loc("decoder.0.attn.proj_q.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc70 = loc("decoder.0.attn.proj_q.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc71 = loc(callsite("forward"("model.py":56:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc72 = loc(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("model.py":63:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc73 = loc(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("forward"("model.py":64:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc74 = loc(callsite("forward"("model.py":65:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc75 = loc(callsite("softmax"("torch/nn/functional.py":1843:0) at callsite("forward"("model.py":65:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc76 = loc(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("model.py":68:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc77 = loc(callsite("forward"("model.py":69:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc78 = loc("decoder.0.attn.proj_output.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc79 = loc(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc80 = loc("decoder.0.ln_2.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc81 = loc("decoder.0.ln_2.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc82 = loc("decoder.0.ln_2.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc83 = loc("decoder.0.ffn.fc.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc84 = loc(callsite("forward"("model.py":85:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc85 = loc("decoder.0.ffn.proj.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc86 = loc(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc87 = loc("decoder.1.ln_1.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc88 = loc("decoder.1.ln_1.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc89 = loc("decoder.1.ln_1.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc90 = loc("decoder.1.attn.proj_v.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc91 = loc("decoder.1.attn.proj_k.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc92 = loc("decoder.1.attn.proj_k.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc93 = loc("decoder.1.attn.proj_q.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc94 = loc("decoder.1.attn.proj_q.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc95 = loc("decoder.1.attn.proj_output.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc96 = loc("decoder.1.ln_2.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc97 = loc("decoder.1.ln_2.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc98 = loc("decoder.1.ln_2.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc99 = loc("decoder.1.ffn.fc.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc100 = loc("decoder.1.ffn.proj.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc101 = loc("decoder.2.ln_1.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc102 = loc("decoder.2.ln_1.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc103 = loc("decoder.2.ln_1.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc104 = loc("decoder.2.attn.proj_v.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc105 = loc("decoder.2.attn.proj_k.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc106 = loc("decoder.2.attn.proj_k.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc107 = loc("decoder.2.attn.proj_q.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc108 = loc("decoder.2.attn.proj_q.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc109 = loc("decoder.2.attn.proj_output.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc110 = loc("decoder.2.ln_2.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc111 = loc("decoder.2.ln_2.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc112 = loc("decoder.2.ln_2.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc113 = loc("decoder.2.ffn.fc.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc114 = loc("decoder.2.ffn.proj.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc115 = loc("decoder.3.ln_1.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc116 = loc("decoder.3.ln_1.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc117 = loc("decoder.3.ln_1.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc118 = loc("decoder.3.attn.proj_v.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc119 = loc("decoder.3.attn.proj_k.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc120 = loc("decoder.3.attn.proj_k.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc121 = loc("decoder.3.attn.proj_q.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc122 = loc("decoder.3.attn.proj_q.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc123 = loc("decoder.3.attn.proj_output.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc124 = loc("decoder.3.ln_2.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc125 = loc("decoder.3.ln_2.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc126 = loc("decoder.3.ln_2.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc127 = loc("decoder.3.ffn.fc.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc128 = loc("decoder.3.ffn.proj.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc129 = loc("decoder.4.ln_1.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc130 = loc("decoder.4.ln_1.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc131 = loc("decoder.4.ln_1.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc132 = loc("decoder.4.attn.proj_v.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc133 = loc("decoder.4.attn.proj_k.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc134 = loc("decoder.4.attn.proj_k.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc135 = loc("decoder.4.attn.proj_q.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc136 = loc("decoder.4.attn.proj_q.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc137 = loc("decoder.4.attn.proj_output.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc138 = loc("decoder.4.ln_2.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc139 = loc("decoder.4.ln_2.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc140 = loc("decoder.4.ln_2.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc141 = loc("decoder.4.ffn.fc.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc142 = loc("decoder.4.ffn.proj.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc143 = loc("decoder.5.ln_1.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc144 = loc("decoder.5.ln_1.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc145 = loc("decoder.5.ln_1.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc146 = loc("decoder.5.attn.proj_v.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc147 = loc("decoder.5.attn.proj_k.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc148 = loc("decoder.5.attn.proj_k.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc149 = loc("decoder.5.attn.proj_q.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc150 = loc("decoder.5.attn.proj_q.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc151 = loc("decoder.5.attn.proj_output.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc152 = loc("decoder.5.ln_2.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc153 = loc("decoder.5.ln_2.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc154 = loc("decoder.5.ln_2.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc155 = loc("decoder.5.ffn.fc.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc156 = loc("decoder.5.ffn.proj.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc157 = loc("decoder.6.ln_1.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc158 = loc("decoder.6.ln_1.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc159 = loc("decoder.6.ln_1.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc160 = loc("decoder.6.attn.proj_v.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc161 = loc("decoder.6.attn.proj_k.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc162 = loc("decoder.6.attn.proj_k.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc163 = loc("decoder.6.attn.proj_q.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc164 = loc("decoder.6.attn.proj_q.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc165 = loc("decoder.6.attn.proj_output.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc166 = loc("decoder.6.ln_2.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc167 = loc("decoder.6.ln_2.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc168 = loc("decoder.6.ln_2.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc169 = loc("decoder.6.ffn.fc.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc170 = loc("decoder.6.ffn.proj.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc171 = loc("decoder.7.ln_1.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc172 = loc("decoder.7.ln_1.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc173 = loc("decoder.7.ln_1.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc174 = loc("decoder.7.attn.proj_v.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc175 = loc("decoder.7.attn.proj_k.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc176 = loc("decoder.7.attn.proj_k.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc177 = loc("decoder.7.attn.proj_q.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc178 = loc("decoder.7.attn.proj_q.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc179 = loc("decoder.7.attn.proj_output.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc180 = loc("decoder.7.ln_2.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc181 = loc("decoder.7.ln_2.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc182 = loc("decoder.7.ln_2.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc183 = loc("decoder.7.ffn.fc.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc184 = loc("decoder.7.ffn.proj.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc185 = loc("decoder.8.ln_1.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc186 = loc("decoder.8.ln_1.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc187 = loc("decoder.8.ln_1.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc188 = loc("decoder.8.attn.proj_v.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc189 = loc("decoder.8.attn.proj_k.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc190 = loc("decoder.8.attn.proj_k.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc191 = loc("decoder.8.attn.proj_q.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc192 = loc("decoder.8.attn.proj_q.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc193 = loc("decoder.8.attn.proj_output.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc194 = loc("decoder.8.ln_2.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc195 = loc("decoder.8.ln_2.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc196 = loc("decoder.8.ln_2.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc197 = loc("decoder.8.ffn.fc.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc198 = loc("decoder.8.ffn.proj.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc199 = loc("decoder.9.ln_1.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc200 = loc("decoder.9.ln_1.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc201 = loc("decoder.9.ln_1.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc202 = loc("decoder.9.attn.proj_v.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":59:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc203 = loc("decoder.9.attn.proj_k.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc204 = loc("decoder.9.attn.proj_k.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":57:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc205 = loc("decoder.9.attn.proj_q.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))))))
#loc206 = loc("decoder.9.attn.proj_q.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":55:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc207 = loc("decoder.9.attn.proj_output.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":70:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":103:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc208 = loc("decoder.9.ln_2.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc209 = loc("decoder.9.ln_2.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc210 = loc("decoder.9.ln_2.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc211 = loc("decoder.9.ffn.fc.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":84:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc212 = loc("decoder.9.ffn.proj.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":86:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":104:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":168:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))))
#loc213 = loc("ln_f.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":169:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))
#loc214 = loc("ln_f.fwd"(callsite("layer_norm"("torch/nn/functional.py":2515:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":169:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc215 = loc("lm_head.fwd"(callsite("to"("cerebras_pytorch/nn/parameter.py":206:0) at callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("cached_cast"("cerebras_pytorch/amp/utils.py":194:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":55:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":170:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))))
#loc216 = loc("ln_f.fwd"(callsite("maybe_half"("cerebras_pytorch/amp/utils.py":100:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":64:0) at callsite("forward"("torch/nn/modules/normalization.py":190:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":169:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))))
#loc217 = loc("lm_head.fwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("torch/nn/modules/linear.py":114:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":170:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc218 = loc(callsite("forward"("model.py":177:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))
#loc219 = loc("CrossEntropyLoss_1.fwd"(callsite("maybe_float"("cerebras_pytorch/amp/utils.py":112:0) at callsite("casted_args"("cerebras_pytorch/amp/utils.py":120:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":61:0) at callsite("forward"("torch/nn/modules/loss.py":1174:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("model.py":176:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))))
#loc220 = loc("CrossEntropyLoss_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc221 = loc("lm_head.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc222 = loc("ln_f.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc223 = loc("wte.bwd"(callsite("norm"("torch/functional.py":1530:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("<listcomp>"("torch/nn/utils/clip_grad.py":59:0) at callsite("clip_grad_norm_"("torch/nn/utils/clip_grad.py":59:0) at callsite("training_step"("train.py":118:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))
#loc224 = loc("decoder.9.ffn.proj.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc225 = loc("decoder.9.ffn.fc.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc226 = loc("decoder.9.ln_2.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc227 = loc("decoder.9.attn.proj_output.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc228 = loc("decoder.9.attn.dropout_layer.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc229 = loc("decoder.9.attn.proj_k.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc230 = loc("decoder.9.attn.proj_q.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc231 = loc("decoder.9.attn.proj_v.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc232 = loc("decoder.9.ln_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc233 = loc("decoder.8.ffn.proj.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc234 = loc("decoder.8.ffn.fc.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc235 = loc("decoder.8.ln_2.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc236 = loc("decoder.8.attn.proj_output.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc237 = loc("decoder.8.attn.dropout_layer.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc238 = loc("decoder.8.attn.proj_k.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc239 = loc("decoder.8.attn.proj_q.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc240 = loc("decoder.8.attn.proj_v.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc241 = loc("decoder.8.ln_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc242 = loc("decoder.7.ffn.proj.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc243 = loc("decoder.7.ffn.fc.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc244 = loc("decoder.7.ln_2.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc245 = loc("decoder.7.attn.proj_output.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc246 = loc("decoder.7.attn.dropout_layer.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc247 = loc("decoder.7.attn.proj_k.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc248 = loc("decoder.7.attn.proj_q.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc249 = loc("decoder.7.attn.proj_v.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc250 = loc("decoder.7.ln_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc251 = loc("decoder.6.ffn.proj.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc252 = loc("decoder.6.ffn.fc.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc253 = loc("decoder.6.ln_2.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc254 = loc("decoder.6.attn.proj_output.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc255 = loc("decoder.6.attn.dropout_layer.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc256 = loc("decoder.6.attn.proj_k.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc257 = loc("decoder.6.attn.proj_q.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc258 = loc("decoder.6.attn.proj_v.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc259 = loc("decoder.6.ln_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc260 = loc("decoder.5.ffn.proj.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc261 = loc("decoder.5.ffn.fc.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc262 = loc("decoder.5.ln_2.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc263 = loc("decoder.5.attn.proj_output.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc264 = loc("decoder.5.attn.dropout_layer.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc265 = loc("decoder.5.attn.proj_k.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc266 = loc("decoder.5.attn.proj_q.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc267 = loc("decoder.5.attn.proj_v.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc268 = loc("decoder.5.ln_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc269 = loc("decoder.4.ffn.proj.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc270 = loc("decoder.4.ffn.fc.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc271 = loc("decoder.4.ln_2.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc272 = loc("decoder.4.attn.proj_output.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc273 = loc("decoder.4.attn.dropout_layer.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc274 = loc("decoder.4.attn.proj_k.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc275 = loc("decoder.4.attn.proj_q.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc276 = loc("decoder.4.attn.proj_v.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc277 = loc("decoder.4.ln_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc278 = loc("decoder.3.ffn.proj.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc279 = loc("decoder.3.ffn.fc.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc280 = loc("decoder.3.ln_2.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc281 = loc("decoder.3.attn.proj_output.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc282 = loc("decoder.3.attn.dropout_layer.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc283 = loc("decoder.3.attn.proj_k.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc284 = loc("decoder.3.attn.proj_q.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc285 = loc("decoder.3.attn.proj_v.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc286 = loc("decoder.3.ln_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc287 = loc("decoder.2.ffn.proj.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc288 = loc("decoder.2.ffn.fc.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc289 = loc("decoder.2.ln_2.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc290 = loc("decoder.2.attn.proj_output.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc291 = loc("decoder.2.attn.dropout_layer.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc292 = loc("decoder.2.attn.proj_k.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc293 = loc("decoder.2.attn.proj_q.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc294 = loc("decoder.2.attn.proj_v.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc295 = loc("decoder.2.ln_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc296 = loc("decoder.1.ffn.proj.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc297 = loc("decoder.1.ffn.fc.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc298 = loc("decoder.1.ln_2.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc299 = loc("decoder.1.attn.proj_output.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc300 = loc("decoder.1.attn.dropout_layer.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc301 = loc("decoder.1.attn.proj_k.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc302 = loc("decoder.1.attn.proj_q.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc303 = loc("decoder.1.attn.proj_v.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc304 = loc("decoder.1.ln_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc305 = loc("decoder.0.ffn.proj.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc306 = loc("decoder.0.ffn.fc.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc307 = loc("decoder.0.ln_2.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc308 = loc("decoder.0.attn.proj_output.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc309 = loc("decoder.0.attn.dropout_layer.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc310 = loc("decoder.0.attn.proj_k.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc311 = loc("decoder.0.attn.proj_q.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc312 = loc("decoder.0.attn.proj_v.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc313 = loc("decoder.0.ln_1.bwd"(callsite("backward"("torch/autograd/__init__.py":200:0) at callsite("backward"("torch/_tensor.py":487:0) at callsite("training_step"("train.py":117:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc314 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":124:0) at callsite("clip_grad_norm_"("torch/nn/utils/clip_grad.py":61:0) at callsite("training_step"("train.py":118:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc315 = loc("wte.bwd"(callsite("norm"("torch/functional.py":1530:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("clip_grad_norm_"("torch/nn/utils/clip_grad.py":61:0) at callsite("training_step"("train.py":118:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))
#loc316 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("clip_grad_norm_"("torch/nn/utils/clip_grad.py":69:0) at callsite("training_step"("train.py":118:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc317 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("__rdiv__"("torch/_tensor.py":852:0) at callsite("wrapped"("torch/_tensor.py":40:0) at callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("clip_grad_norm_"("torch/nn/utils/clip_grad.py":69:0) at callsite("training_step"("train.py":118:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))
#loc318 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":156:0) at callsite("clip_grad_norm_"("torch/nn/utils/clip_grad.py":82:0) at callsite("training_step"("train.py":118:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc319 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":141:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc320 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":142:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc321 = loc("optimizer"(callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":429:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":515:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("pre_optimizer_step"("cerebras_pytorch/backend/ltc_backend.py":395:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":472:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc322 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":437:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":515:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("pre_optimizer_step"("cerebras_pytorch/backend/ltc_backend.py":395:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":472:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc323 = loc("optimizer"(callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":437:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":515:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("pre_optimizer_step"("cerebras_pytorch/backend/ltc_backend.py":395:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":472:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc324 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":439:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":515:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("pre_optimizer_step"("cerebras_pytorch/backend/ltc_backend.py":395:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":472:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc325 = loc("optimizer"(callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":236:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":506:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("pre_optimizer_step"("cerebras_pytorch/backend/ltc_backend.py":395:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":472:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc326 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":236:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":506:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("pre_optimizer_step"("cerebras_pytorch/backend/ltc_backend.py":395:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":472:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc327 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":232:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":506:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("pre_optimizer_step"("cerebras_pytorch/backend/ltc_backend.py":395:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":472:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))))
#loc328 = loc("optimizer"(callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":231:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":506:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("pre_optimizer_step"("cerebras_pytorch/backend/ltc_backend.py":395:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":472:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc329 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":513:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("pre_optimizer_step"("cerebras_pytorch/backend/ltc_backend.py":395:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":472:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc330 = loc("optimizer"(callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":512:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("pre_optimizer_step"("cerebras_pytorch/backend/ltc_backend.py":395:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":472:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))
#loc331 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":136:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc332 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":137:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc333 = loc("optimizer"(callsite("step"("cerebras_pytorch/optim/AdamBase.py":138:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))
#loc334 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":138:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc335 = loc("optimizer"(callsite("step"("cerebras_pytorch/optim/AdamBase.py":128:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))
#loc336 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":130:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc337 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":139:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc338 = loc("optimizer"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("step"("cerebras_pytorch/optim/AdamBase.py":151:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc339 = loc("optimizer"(callsite("step"("cerebras_pytorch/optim/AdamBase.py":154:0) at callsite("decorate_context"("torch/utils/_contextlib.py":115:0) at callsite("wrapper"("torch/optim/optimizer.py":280:0) at callsite("wrapper"("torch/optim/lr_scheduler.py":69:0) at callsite("wrapped_optimizer_step"("cerebras_pytorch/backend/base_backend.py":473:0) at callsite("training_step"("train.py":119:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))
#loc340 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("increment_last_epoch"("cerebras_pytorch/optim/lr_scheduler.py":121:0) at callsite("increment_last_epoch"("cerebras_pytorch/optim/lr_scheduler.py":522:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":129:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))
#loc341 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("increment_last_epoch"("cerebras_pytorch/optim/lr_scheduler.py":528:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":129:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))
#loc342 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("increment_last_epoch"("cerebras_pytorch/optim/lr_scheduler.py":532:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":129:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))
#loc343 = loc("wte.bwd"(callsite("increment_last_epoch"("cerebras_pytorch/optim/lr_scheduler.py":531:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":129:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))
#loc344 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("increment_last_epoch"("cerebras_pytorch/optim/lr_scheduler.py":531:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":129:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))
#loc345 = loc("wte.bwd"(callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":429:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":515:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":138:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))
#loc346 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":437:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":515:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":138:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc347 = loc("wte.bwd"(callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":437:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":515:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":138:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))
#loc348 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":439:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":515:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":138:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc349 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":238:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":506:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":138:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc350 = loc("wte.bwd"(callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":236:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":506:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":138:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))
#loc351 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":236:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":506:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":138:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc352 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":232:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":506:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":138:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))))
#loc353 = loc("wte.bwd"(callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":231:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":506:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":138:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))
#loc354 = loc("wte.bwd"(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":513:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":138:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))))
#loc355 = loc("wte.bwd"(callsite("_get_closed_form_lr"("cerebras_pytorch/optim/lr_scheduler.py":512:0) at callsite("get_lr"("cerebras_pytorch/optim/lr_scheduler.py":77:0) at callsite("update_last_lr"("cerebras_pytorch/optim/lr_scheduler.py":143:0) at callsite("step"("cerebras_pytorch/optim/lr_scheduler.py":138:0) at callsite("training_step"("train.py":120:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))
#loc356 = loc(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":62:0) at callsite("forward"("model.py":179:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))
#loc357 = loc(callsite("wrapper"("cerebras_pytorch/amp/wrap.py":94:0) at callsite("forward"("model.py":179:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0))))))))))
#loc358 = loc(callsite("forward"("model.py":180:0) at callsite("_call_impl"("torch/nn/modules/module.py":1538:0) at callsite("forward"("cerebras_pytorch/backend/base_backend.py":412:0) at callsite("compiled_forward"("cerebras_pytorch/core/compile.py":81:0) at callsite("training_step"("train.py":116:0) at callsite("generated_trace_fn"("cerebras_pytorch/core/compile.py":139:0) at callsite("main"("train.py":161:0) at "<module>"("train.py":170:0)))))))))

